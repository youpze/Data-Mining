{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca254db0-81c6-46c4-a66e-9b7f66172755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score, roc_auc_score\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder,  minmax_scale\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "#from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GroupShuffleSplit\n",
    "import itertools\n",
    "#from torch.utils.data import DataLoader\n",
    "#import torch\n",
    "from catboost import CatBoostRanker, Pool,  cv\n",
    "import optuna\n",
    "from optuna.integration import CatBoostPruningCallback\n",
    "from catboost.utils import eval_metric\n",
    "from optuna.pruners import SuccessiveHalvingPruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f7bcaa-d6d3-49c1-b9b0-5edec2d3a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the files changes path to where the data is stored\n",
    "test = pd.read_csv(\"./test_set_VU_DM.csv\")\n",
    "train = pd.read_csv(\"./training_set_VU_DM.csv\")\n",
    "sample = pd.read_csv(\"./submission_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec8d9446-64f1-4a71-8853-5223b84bb23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['mean_pos']=train.groupby('prop_id')['position'].transform('mean')\n",
    "test['mean_pos']=test['prop_id'].map(train.groupby('prop_id')['position'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08a5d234-6885-41df-bdf7-94794f3df4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "    \"\"\"Returns a DataFrame with missing counts and percent missing for each column.\"\"\"\n",
    "    n = len(df)\n",
    "    missing_count   = df.isna().sum()\n",
    "    missing_percent = 100 * missing_count / n\n",
    "    missing_df = (\n",
    "        pd.DataFrame({\n",
    "            'missing_count':   missing_count,\n",
    "            'missing_percent': missing_percent\n",
    "        })\n",
    "        .sort_values('missing_percent', ascending=False)\n",
    "    )\n",
    "    return missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ea75187-7171-44a8-b8d1-ef210c3b2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## some beginning on the feature engineering\n",
    "def missing_values_table(df):\n",
    "    \"\"\"Returns a DataFrame with missing counts and percent missing for each column.\"\"\"\n",
    "    n = len(df)\n",
    "    missing_count   = df.isna().sum()\n",
    "    missing_percent = 100 * missing_count / n\n",
    "    missing_df = (\n",
    "        pd.DataFrame({\n",
    "            'missing_count':   missing_count,\n",
    "            'missing_percent': missing_percent\n",
    "        })\n",
    "        .sort_values('missing_percent', ascending=False)\n",
    "    )\n",
    "    return missing_df\n",
    "    \n",
    "def preprocess_missing_and_competitors(train_df, test_df):\n",
    "    # 1) Drop features with >93% missing or that leak the target\n",
    "    drop_cols = [\n",
    "        # competitor 1,4,6,7 are ~97–98% missing → too sparse to learn\n",
    "        *[f'comp{i}_{t}' for i in [1,4,6,7] for t in ['rate','inv','rate_percent_diff']],\n",
    "        'gross_bookings_usd'  # only in train, leaks booking price\n",
    "    ]\n",
    "    train_df.drop(columns=drop_cols, errors='ignore', inplace=True)\n",
    "    test_df.drop(columns=drop_cols, errors='ignore', inplace=True)\n",
    "\n",
    "    # 2) Impute & flag user history features\n",
    "    #    Missing means “no prior purchases” → keep with sentinel + flag\n",
    "    for df in (train_df, test_df):\n",
    "        # visitor_hist_starrating\n",
    "        df['hist_star_na'] = df['visitor_hist_starrating'].isna().astype(int)\n",
    "        # fill with median starrating across users\n",
    "        star_med = train_df['visitor_hist_starrating'].median()\n",
    "        df['visitor_hist_starrating'] = df['visitor_hist_starrating'].fillna(star_med)\n",
    "\n",
    "        # visitor_hist_adr_usd (avg USD spend)\n",
    "        df['hist_adr_na'] = df['visitor_hist_adr_usd'].isna().astype(int)\n",
    "        adr_med = train_df['visitor_hist_adr_usd'].median()\n",
    "        df['visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].fillna(adr_med)\n",
    "\n",
    "    # 3) Impute & flag affinity score\n",
    "    #    Null means “hotel never seen” → fill with global minimum and flag\n",
    "    affinity_min = train_df['srch_query_affinity_score'].min(skipna=True)\n",
    "    for df in (train_df, test_df):\n",
    "        df['affinity_na'] = df['srch_query_affinity_score'].isna().astype(int)\n",
    "        df['srch_query_affinity_score'] = (\n",
    "            df['srch_query_affinity_score']\n",
    "            .fillna(affinity_min)\n",
    "        )\n",
    "\n",
    "    # 4) Keep & impute competitor 2,3,5,8 features (~50–90% missing)\n",
    "    #    Null → “no data” sentinel (for categorical) or 0 (for percent diff), plus flag\n",
    "    keep_comps = [2,3,5,8]\n",
    "    for i in keep_comps:\n",
    "        # availability flag\n",
    "        inv_col = f'comp{i}_inv'\n",
    "        flag_col = f'comp{i}_inv_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[flag_col] = df[inv_col].isna().astype(int)\n",
    "            # fill null with 2 (new category: 0=no avail,1=avail,2=no data)\n",
    "            df[inv_col] = df[inv_col].fillna(2).astype(int)\n",
    "\n",
    "        # price‐compare flag\n",
    "        rate_col = f'comp{i}_rate'\n",
    "        rate_flag = f'comp{i}_rate_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[rate_flag] = df[rate_col].isna().astype(int)\n",
    "            # fill null as “no data” = 2\n",
    "            df[rate_col] = df[rate_col].fillna(2).astype(int)\n",
    "\n",
    "        # percent_diff\n",
    "        pdiff_col = f'comp{i}_rate_percent_diff'\n",
    "        pdiff_flag = f'comp{i}_pdiff_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[pdiff_flag] = df[pdiff_col].isna().astype(int)\n",
    "            # fill null as 0% diff (no info)\n",
    "            df[pdiff_col] = df[pdiff_col].fillna(0.0)\n",
    "\n",
    "    # 5) Bucket orig_destination_distance\n",
    "    #    Missing → sentinel bucket + flag\n",
    "    for df in (train_df, test_df):\n",
    "        df['dist_na'] = df['orig_destination_distance'].isna().astype(int)\n",
    "        df['orig_destination_distance'] = (\n",
    "            df['orig_destination_distance'].fillna(-1)\n",
    "        )\n",
    "        # define bins (in km)\n",
    "        bins = [-1, 0, 10, 50, 200, np.inf]\n",
    "        labels = ['missing','0-10km','10-50km','50-200km','200km+']\n",
    "        df['dist_bucket'] = pd.cut(\n",
    "            df['orig_destination_distance'],\n",
    "            bins=bins, labels=labels\n",
    "        )\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def create_base_features(df):\n",
    "    \"\"\"1) Parse datetime & basic price/historical features.\"\"\"\n",
    "    df = df.copy()\n",
    "    # --- Date/time splits ---\n",
    "    df['date_time']   = pd.to_datetime(df['date_time'])\n",
    "    df['search_year'] = df['date_time'].dt.year\n",
    "    df['search_month']= df['date_time'].dt.month\n",
    "    df['search_day']  = df['date_time'].dt.day\n",
    "    df['search_hour'] = df['date_time'].dt.hour\n",
    "\n",
    "    # --- Price per night & hist price devation ---\n",
    "    df['price_per_night'] = df['price_usd'] / df['srch_length_of_stay']\n",
    "    df['price_vs_historical'] = df['price_usd'] - df['prop_log_historical_price']\n",
    "    df['price_vs_historical'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_destination_stats(train_df, test_df):\n",
    "    \"\"\"6) Dest‑level total searches & booking rate.\"\"\"\n",
    "    dest = (\n",
    "        train_df\n",
    "        .groupby('srch_destination_id')\n",
    "        .agg(dest_searches=('srch_id','count'),\n",
    "             dest_bookings=('booking_bool','sum'))\n",
    "        .assign(dest_booking_rate=lambda x: x.dest_bookings / x.dest_searches)\n",
    "        .reset_index()\n",
    "    )\n",
    "    # Reassign merge result back to each DataFrame\n",
    "    train_df = train_df.merge(\n",
    "        dest[['srch_destination_id','dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "    test_df = test_df.merge(\n",
    "        dest[['srch_destination_id','dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "    return train_df, test_df\n",
    "\n",
    "def add_within_search_features(df):\n",
    "    \"\"\"7) Z‑scores & deltas in each search group.\"\"\"\n",
    "    grp = df.groupby('srch_id')\n",
    "    # price\n",
    "    df['price_mean_srch'] = grp['price_usd'].transform('mean')\n",
    "    df['price_std_srch']  = grp['price_usd'].transform('std').fillna(1)\n",
    "    df['price_zscore']    = (df['price_usd'] - df['price_mean_srch']) / df['price_std_srch']\n",
    "    # stars\n",
    "    df['star_mean_srch']  = grp['prop_starrating'].transform('mean')\n",
    "    df['star_delta_srch'] = df['prop_starrating'] - df['star_mean_srch']\n",
    "    # user delta\n",
    "    df['star_delta_user'] = df['prop_starrating'] - df['visitor_hist_starrating']\n",
    "    # distance\n",
    "    df['dist_mean_srch']  = grp['orig_destination_distance'].transform('mean')\n",
    "    df['dist_std_srch']   = grp['orig_destination_distance'].transform('std').fillna(1)\n",
    "    df['dist_zscore']     = (df['orig_destination_distance'] - df['dist_mean_srch']) / df['dist_std_srch']\n",
    "    return df\n",
    "\n",
    "def add_temporal_features(df):\n",
    "    \"\"\"8) Weekday/weekend & check‑in weekend flags.\"\"\"\n",
    "    # day‑of‑week for search\n",
    "    df['search_dow'] = df['date_time'].dt.weekday  # 0=Mon…6=Sun\n",
    "    df['is_search_weekend'] = df['search_dow'].isin([5,6]).astype(int)\n",
    "    # approximate check‑in day\n",
    "    checkin = df['date_time'] + pd.to_timedelta(df['srch_booking_window'], 'D')\n",
    "    df['checkin_dow'] = checkin.dt.weekday\n",
    "    df['is_checkin_weekend'] = df['checkin_dow'].isin([5,6]).astype(int)\n",
    "    return df\n",
    "\n",
    "def add_ranks(df):\n",
    "    \"\"\"9) Dense ranks of price, star & distance within each search.\"\"\"\n",
    "    df['price_rank'] = df.groupby('srch_id')['price_usd'].rank('dense', ascending=True)\n",
    "    df['star_rank']  = df.groupby('srch_id')['prop_starrating'].rank('dense', ascending=False)\n",
    "    df['dist_rank']  = df.groupby('srch_id')['orig_destination_distance'].rank('dense', ascending=True)\n",
    "    return df\n",
    "\n",
    "def one_hot_encode_columns(train_df, test_df, columns_to_encode):\n",
    "    \"\"\"\n",
    "    Converts specified string columns in train and test DataFrames to one-hot encoded features.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): The training DataFrame.\n",
    "        test_df (pd.DataFrame): The testing DataFrame.\n",
    "        columns_to_encode (list): A list of column names (strings) to be one-hot encoded.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the modified training and testing DataFrames with one-hot encoded columns.\n",
    "    \"\"\"\n",
    "    train_processed = train_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "\n",
    "    for col in columns_to_encode:\n",
    "        if col in train_processed.columns and col in test_processed.columns:\n",
    "            # Get unique values from both train and test to ensure consistent encoding\n",
    "            all_unique_values = pd.concat([train_processed[col], test_processed[col]]).unique()\n",
    "\n",
    "            for value in all_unique_values:\n",
    "                train_processed[f'{col}_{value}'] = (train_processed[col] == value).astype(int)\n",
    "                test_processed[f'{col}_{value}'] = (test_processed[col] == value).astype(int)\n",
    "\n",
    "            # Drop the original categorical column\n",
    "            train_processed.drop(columns=[col], inplace=True)\n",
    "            test_processed.drop(columns=[col], inplace=True)\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in both train and test DataFrames. Skipping one-hot encoding for this column.\")\n",
    "\n",
    "    return train_processed, test_processed\n",
    "\n",
    "def minmax(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
    "\n",
    "def ensemble_predictions(pred1, pred2, weights):\n",
    "    w1, w2 = weights\n",
    "    return w1 * minmax(pred1) + w2 * minmax(pred2)\n",
    "\n",
    "def preprocess_missing_and_competitors_fit(train_df):\n",
    "    stats = {}\n",
    "    # 1) Which cols to drop\n",
    "    stats['drop_cols'] = [\n",
    "        *[f'comp{i}_{t}' for i in [1,4,6,7] \n",
    "          for t in ['rate','inv','rate_percent_diff']],\n",
    "        'gross_bookings_usd'\n",
    "    ]\n",
    "    # 2) Medians & mins for imputation\n",
    "    stats['star_med']     = train_df['visitor_hist_starrating'].median()\n",
    "    stats['adr_med']      = train_df['visitor_hist_adr_usd'].median()\n",
    "    stats['affinity_min'] = train_df['srch_query_affinity_score'].min(skipna=True)\n",
    "    return stats\n",
    "\n",
    "def preprocess_missing_and_competitors_transform(df, stats):\n",
    "    df = df.copy()\n",
    "    df.drop(columns=stats['drop_cols'], errors='ignore', inplace=True)\n",
    "\n",
    "    # visitor history\n",
    "    df['hist_star_na'] = df['visitor_hist_starrating'].isna().astype(int)\n",
    "    df['visitor_hist_starrating'] = (\n",
    "        df['visitor_hist_starrating']\n",
    "          .fillna(stats['star_med'])\n",
    "    )\n",
    "    df['hist_adr_na'] = df['visitor_hist_adr_usd'].isna().astype(int)\n",
    "    df['visitor_hist_adr_usd'] = (\n",
    "        df['visitor_hist_adr_usd']\n",
    "          .fillna(stats['adr_med'])\n",
    "    )\n",
    "\n",
    "    # affinity\n",
    "    df['affinity_na'] = df['srch_query_affinity_score'].isna().astype(int)\n",
    "    df['srch_query_affinity_score'] = (\n",
    "        df['srch_query_affinity_score']\n",
    "          .fillna(stats['affinity_min'])\n",
    "    )\n",
    "\n",
    "    # keep comps 2,3,5,8\n",
    "    for i in [2,3,5,8]:\n",
    "        for col, fill in [\n",
    "            (f'comp{i}_inv',               2),\n",
    "            (f'comp{i}_rate',              2),\n",
    "            (f'comp{i}_rate_percent_diff', 0.0),\n",
    "        ]:\n",
    "            df[f'{col}_na'] = df[col].isna().astype(int)\n",
    "            df[col] = df[col].fillna(fill)\n",
    "\n",
    "    # distance bucket\n",
    "    df['dist_na'] = df['orig_destination_distance'].isna().astype(int)\n",
    "    df['orig_destination_distance'] = (\n",
    "        df['orig_destination_distance'].fillna(-1)\n",
    "    )\n",
    "    bins  = [-1,0,10,50,200,np.inf]\n",
    "    lbls  = ['missing','0-10km','10-50km','50-200km','200km+']\n",
    "    df['dist_bucket'] = pd.cut(\n",
    "        df['orig_destination_distance'], bins=bins, labels=lbls\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def add_destination_stats_fit(train_df):\n",
    "    dest = (\n",
    "        train_df\n",
    "        .groupby('srch_destination_id')\n",
    "        .agg(dest_searches=('srch_id','count'),\n",
    "             dest_bookings=('booking_bool','sum'))\n",
    "    )\n",
    "    dest['dest_booking_rate'] = dest['dest_bookings'] / dest['dest_searches']\n",
    "    return dest\n",
    "\n",
    "def add_destination_stats_transform(df, dest_stats):\n",
    "    df = df.copy()\n",
    "    return df.merge(\n",
    "        dest_stats[['dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "def run_pipeline_on(train_df, other_df, steps):\n",
    "    df1, df2 = train_df.copy(), other_df.copy()\n",
    "    for fn in steps:\n",
    "        df1, df2 = fn(df1, df2)\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c61caaa-a280-4550-9d46-386e8a6fe5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Define target\n",
    "y = train['booking_bool'] * 5 + train['click_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a047e5cd-ba9a-4b40-aa65-c65964f8abc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12607\\AppData\\Local\\Temp\\ipykernel_7052\\2243288486.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\12607\\AppData\\Local\\Temp\\ipykernel_7052\\2243288486.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 1) Feature‐Engineering Pipeline\n",
    "train_feat, test_feat = train.copy(), test.copy()\n",
    "steps = [\n",
    "    preprocess_missing_and_competitors,\n",
    "    add_destination_stats,\n",
    "    lambda tr, te: one_hot_encode_columns(tr, te, ['dist_bucket']),\n",
    "    lambda tr, te: (create_base_features(tr), create_base_features(te)),\n",
    "    lambda tr, te: (add_within_search_features(tr), add_within_search_features(te)),\n",
    "    lambda tr, te: (add_temporal_features(tr), add_temporal_features(te)),\n",
    "    lambda tr, te: (add_ranks(tr), add_ranks(te)),\n",
    "]\n",
    "for fn in steps:\n",
    "    train_feat, test_feat = fn(train_feat, test_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48198da9-b7e9-4f8a-9a23-a189962f4003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12607\\AppData\\Local\\Temp\\ipykernel_7052\\338084407.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "C:\\Users\\12607\\AppData\\Local\\Temp\\ipykernel_7052\\338084407.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(med, inplace=True)\n",
      "C:\\Users\\12607\\AppData\\Local\\Temp\\ipykernel_7052\\338084407.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col].fillna(med, inplace=True)\n",
      "C:\\Users\\12607\\AppData\\Local\\Temp\\ipykernel_7052\\338084407.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(med, inplace=True)\n",
      "C:\\Users\\12607\\AppData\\Local\\Temp\\ipykernel_7052\\338084407.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col].fillna(med, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 2) Train/Validation Split + Preprocessing\n",
    "\n",
    "\n",
    "# a) split on search IDs\n",
    "train_ids, valid_ids = train_test_split(\n",
    "    train_feat['srch_id'].unique(), \n",
    "    test_size=0.2, \n",
    "    random_state=22\n",
    ")\n",
    "mask_tr   = train_feat['srch_id'].isin(train_ids)\n",
    "mask_va   = ~mask_tr\n",
    "mask_full = mask_tr | mask_va  # full = all rows\n",
    "\n",
    "# b) pick your features\n",
    "drop = ['date_time','gross_bookings_usd','position',\n",
    "        'click_bool','booking_bool','srch_id','prop_id']\n",
    "features = [c for c in train_feat.columns if c not in drop]\n",
    "\n",
    "# c) pull out X, y\n",
    "X       = train_feat[features]\n",
    "X_test  = test_feat[features]\n",
    "y       = train['booking_bool'] * 5 + train['click_bool']  # as before\n",
    "\n",
    "# d) replace infinities/nans by train median\n",
    "for df in (X, X_test):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "for col in features:\n",
    "    med = X[col].median()\n",
    "    X[col].fillna(med, inplace=True)\n",
    "    X_test[col].fillna(med, inplace=True)\n",
    "\n",
    "# e) scale\n",
    "scaler = StandardScaler()\n",
    "X_tr    = scaler.fit_transform(X[mask_tr])\n",
    "X_va    = scaler.transform(X[mask_va])\n",
    "X_full  = scaler.transform(X)         # entire dataset\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "y_tr    = y[mask_tr].values\n",
    "y_va    = y[mask_va].values\n",
    "y_full  = y.values                     # entire dataset\n",
    "\n",
    "# 3) Build grouping arrays / session‐ids\n",
    "id_tr   = train_feat.loc[mask_tr, 'srch_id'].values\n",
    "id_va   = train_feat.loc[mask_va, 'srch_id'].values\n",
    "id_full = train_feat['srch_id'].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d73440b2-67ca-47db-b4b7-c52a95efb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Compute per-query group sizes\n",
    "grp_tr   = train_feat.loc[mask_tr, 'srch_id'].value_counts(sort=False).values\n",
    "grp_va   = train_feat.loc[mask_va, 'srch_id'].value_counts(sort=False).values\n",
    "grp_full = train_feat['srch_id'].value_counts(sort=False).values\n",
    "\n",
    "# 2) Build the LGB Datasets\n",
    "lgb_train = lgb.Dataset(X_tr,    label=y_tr,   group=grp_tr)\n",
    "lgb_val   = lgb.Dataset(X_va,    label=y_va,   group=grp_va)\n",
    "lgb_full  = lgb.Dataset(X_full,  label=y_full, group=grp_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7b7b589-6888-460b-ad4a-d5a2aac5aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Build grouping arrays\n",
    "\n",
    "train_pool = Pool(X_tr,   label=y_tr,   group_id=id_tr)\n",
    "val_pool   = Pool(X_va,   label=y_va,   group_id=id_va)\n",
    "full_pool  = Pool(X_full, label=y_full, group_id=id_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ec2bd5f-1730-4666-85f7-3952157d51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Define your search space\n",
    "\n",
    "param_dist = {\n",
    "    'learning_rate':    [0.03,0.05,0.08],\n",
    "    'num_leaves':       [32,64,96],\n",
    "    'min_data_in_leaf': [80,90,100],\n",
    "    'feature_fraction': [0.85,0.9, 1.0],\n",
    "    'bagging_fraction': [0.85,0.9, 1.0],\n",
    "    'bagging_freq':     [5,10,20],\n",
    "}\n",
    "\n",
    "n_iter = 35\n",
    "best_score, score = 0,0\n",
    "best_params,params = None,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "673066f0-78f5-4834-ace3-a35f4110ea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.231556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[396]\tvalid's ndcg@5: 0.39817\n",
      "    → ndcg@5 = 0.3982, rounds = 396\n",
      "2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.191514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[683]\tvalid's ndcg@5: 0.400371\n",
      "    → ndcg@5 = 0.4004, rounds = 683\n",
      "3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.206720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[413]\tvalid's ndcg@5: 0.400861\n",
      "    → ndcg@5 = 0.4009, rounds = 413\n",
      "4\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.230824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[507]\tvalid's ndcg@5: 0.399463\n",
      "    → ndcg@5 = 0.3995, rounds = 507\n",
      "5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.222586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[582]\tvalid's ndcg@5: 0.401288\n",
      "    → ndcg@5 = 0.4013, rounds = 582\n",
      "6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.450285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[729]\tvalid's ndcg@5: 0.402555\n",
      "    → ndcg@5 = 0.4026, rounds = 729\n",
      "7\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.250423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[641]\tvalid's ndcg@5: 0.399253\n",
      "    → ndcg@5 = 0.3993, rounds = 641\n",
      "8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.213622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[582]\tvalid's ndcg@5: 0.401288\n",
      "    → ndcg@5 = 0.4013, rounds = 582\n",
      "9\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.212631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[314]\tvalid's ndcg@5: 0.398291\n",
      "    → ndcg@5 = 0.3983, rounds = 314\n",
      "10\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.173881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[401]\tvalid's ndcg@5: 0.401607\n",
      "    → ndcg@5 = 0.4016, rounds = 401\n",
      "11\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.227211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[628]\tvalid's ndcg@5: 0.400871\n",
      "    → ndcg@5 = 0.4009, rounds = 628\n",
      "12\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.212630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid's ndcg@5: 0.398968\n",
      "    → ndcg@5 = 0.3990, rounds = 285\n",
      "13\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.185664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid's ndcg@5: 0.398225\n",
      "    → ndcg@5 = 0.3982, rounds = 305\n",
      "14\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.208572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[444]\tvalid's ndcg@5: 0.398834\n",
      "    → ndcg@5 = 0.3988, rounds = 444\n",
      "15\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.201999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[683]\tvalid's ndcg@5: 0.39969\n",
      "    → ndcg@5 = 0.3997, rounds = 683\n",
      "16\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.206925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[664]\tvalid's ndcg@5: 0.400125\n",
      "    → ndcg@5 = 0.4001, rounds = 664\n",
      "17\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.534560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid's ndcg@5: 0.39844\n",
      "    → ndcg@5 = 0.3984, rounds = 285\n",
      "18\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.241658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[432]\tvalid's ndcg@5: 0.398182\n",
      "    → ndcg@5 = 0.3982, rounds = 432\n",
      "19\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.220035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid's ndcg@5: 0.399075\n",
      "    → ndcg@5 = 0.3991, rounds = 213\n",
      "20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.243248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[665]\tvalid's ndcg@5: 0.400647\n",
      "    → ndcg@5 = 0.4006, rounds = 665\n",
      "21\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.186329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[768]\tvalid's ndcg@5: 0.399063\n",
      "    → ndcg@5 = 0.3991, rounds = 768\n",
      "22\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.224162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[741]\tvalid's ndcg@5: 0.400338\n",
      "    → ndcg@5 = 0.4003, rounds = 741\n",
      "23\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.205213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[466]\tvalid's ndcg@5: 0.399413\n",
      "    → ndcg@5 = 0.3994, rounds = 466\n",
      "24\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.203086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[391]\tvalid's ndcg@5: 0.400344\n",
      "    → ndcg@5 = 0.4003, rounds = 391\n",
      "25\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.561841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid's ndcg@5: 0.40022\n",
      "    → ndcg@5 = 0.4002, rounds = 254\n",
      "26\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.210639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[292]\tvalid's ndcg@5: 0.399533\n",
      "    → ndcg@5 = 0.3995, rounds = 292\n",
      "27\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.221245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[360]\tvalid's ndcg@5: 0.400383\n",
      "    → ndcg@5 = 0.4004, rounds = 360\n",
      "28\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.187800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[348]\tvalid's ndcg@5: 0.399049\n",
      "    → ndcg@5 = 0.3990, rounds = 348\n",
      "29\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.196347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[474]\tvalid's ndcg@5: 0.398173\n",
      "    → ndcg@5 = 0.3982, rounds = 474\n",
      "30\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.209112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[354]\tvalid's ndcg@5: 0.399002\n",
      "    → ndcg@5 = 0.3990, rounds = 354\n",
      "31\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.487007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[405]\tvalid's ndcg@5: 0.4006\n",
      "    → ndcg@5 = 0.4006, rounds = 405\n",
      "32\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.228477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[283]\tvalid's ndcg@5: 0.400115\n",
      "    → ndcg@5 = 0.4001, rounds = 283\n",
      "33\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.217718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[662]\tvalid's ndcg@5: 0.400836\n",
      "    → ndcg@5 = 0.4008, rounds = 662\n",
      "34\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.201067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[679]\tvalid's ndcg@5: 0.401215\n",
      "    → ndcg@5 = 0.4012, rounds = 679\n",
      "35\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.209287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7128\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[706]\tvalid's ndcg@5: 0.401962\n",
      "    → ndcg@5 = 0.4020, rounds = 706\n"
     ]
    }
   ],
   "source": [
    "# 1) Your random search stays the same…\n",
    "for i in range(1, n_iter + 1):\n",
    "    print(i)\n",
    "    params = {\n",
    "        'objective':         'lambdarank',\n",
    "        'metric':            'ndcg',\n",
    "        'ndcg_eval_at':      [5],\n",
    "        'verbose':           1,\n",
    "        'feature_pre_filter': False,      # ← disable the one-shot pre-filter\n",
    "    }\n",
    "    # 2) then overlay your random hyper‐params\n",
    "    params.update({k: np.random.choice(v) for k, v in param_dist.items()})\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set=lgb_train,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=lgb_val,\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    "    )\n",
    "    \n",
    "    score = model.best_score['valid']['ndcg@5']\n",
    "    print(f\"    → ndcg@5 = {score:.4f}, rounds = {model.best_iteration}\")\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score_ = score\n",
    "        best_params = params.copy()\n",
    "        best_iter =  model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f335fe-beb9-44c9-a698-c4a8dd99de6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.03, 'num_leaves': 96, 'min_data_in_leaf': 80, 'feature_fraction': 1.0, 'bagging_fraction': 0.9, 'bagging_freq': 10} 706\n"
     ]
    }
   ],
   "source": [
    "print(best_score, best_params, best_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bf22fe9-054d-4f3b-a757-a40119664b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.312885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7138\n",
      "[LightGBM] [Info] Number of data points in the train set: 4958347, number of used features: 80\n"
     ]
    }
   ],
   "source": [
    "# 3) Retrain on all data\n",
    "model_lgb_full = lgb.train(\n",
    "    best_params,\n",
    "    lgb_full,\n",
    "    num_boost_round=best_iter # can still be ajdusted to best best_iter\n",
    ")\n",
    "\n",
    "# 4) Predict on test\n",
    "lgb_test_preds = model_lgb_full.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c4afe9f-c8cb-46c4-a86b-c567a7e81a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 01:08:41,393] A new study created in memory with name: catboost_yetirank\n",
      "C:\\Users\\12607\\AppData\\Local\\Temp\\ipykernel_7052\\2238719826.py:22: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  pruning_callback = CatBoostPruningCallback(trial, 'NDCG:top=5;type=Base')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.3128857\tbest: 0.3128857 (0)\ttotal: 2.96s\tremaining: 19m 40s\n",
      "100:\ttest: 0.3873578\tbest: 0.3874665 (98)\ttotal: 3m 22s\tremaining: 9m 59s\n",
      "200:\ttest: 0.3933890\tbest: 0.3933890 (200)\ttotal: 6m 35s\tremaining: 6m 31s\n",
      "300:\ttest: 0.3961590\tbest: 0.3962093 (299)\ttotal: 9m 47s\tremaining: 3m 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 01:21:46,205] Trial 0 finished with value: 0.39859924419192555 and parameters: {'learning_rate': 0.08115798052942344, 'depth': 11, 'l2_leaf_reg': 4.365984979409287, 'random_strength': 1.2724461034600165, 'bagging_temperature': 0.35447016253489705, 'border_count': 39}. Best is trial 0 with value: 0.39859924419192555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399:\ttest: 0.3984495\tbest: 0.3985992 (398)\ttotal: 12m 58s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3985992442\n",
      "bestIteration = 398\n",
      "\n",
      "Shrink model to first 399 iterations.\n",
      "0:\ttest: 0.3017700\tbest: 0.3017700 (0)\ttotal: 2.37s\tremaining: 15m 43s\n",
      "100:\ttest: 0.3810750\tbest: 0.3810750 (100)\ttotal: 3m 24s\tremaining: 10m 4s\n",
      "200:\ttest: 0.3886841\tbest: 0.3886841 (200)\ttotal: 6m 42s\tremaining: 6m 38s\n",
      "300:\ttest: 0.3923123\tbest: 0.3924060 (299)\ttotal: 9m 58s\tremaining: 3m 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 01:35:02,793] Trial 1 finished with value: 0.39424577982101805 and parameters: {'learning_rate': 0.03379972948244641, 'depth': 11, 'l2_leaf_reg': 0.0016015514498101495, 'random_strength': 0.00868564899810549, 'bagging_temperature': 0.2843013196310744, 'border_count': 67}. Best is trial 0 with value: 0.39859924419192555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399:\ttest: 0.3942458\tbest: 0.3942458 (399)\ttotal: 13m 13s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3942457798\n",
      "bestIteration = 399\n",
      "\n",
      "0:\ttest: 0.2560430\tbest: 0.2560430 (0)\ttotal: 1.31s\tremaining: 8m 41s\n",
      "100:\ttest: 0.3831681\tbest: 0.3831681 (100)\ttotal: 2m 6s\tremaining: 6m 14s\n",
      "200:\ttest: 0.3893467\tbest: 0.3893467 (200)\ttotal: 4m 11s\tremaining: 4m 8s\n",
      "300:\ttest: 0.3931101\tbest: 0.3931101 (300)\ttotal: 6m 14s\tremaining: 2m 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 01:43:21,917] Trial 2 finished with value: 0.39509974658457636 and parameters: {'learning_rate': 0.09137352506412875, 'depth': 6, 'l2_leaf_reg': 0.010361546750932168, 'random_strength': 0.2619704240949627, 'bagging_temperature': 0.34682000328207396, 'border_count': 230}. Best is trial 0 with value: 0.39859924419192555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399:\ttest: 0.3950077\tbest: 0.3950997 (389)\ttotal: 8m 16s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3950997466\n",
      "bestIteration = 389\n",
      "\n",
      "Shrink model to first 390 iterations.\n",
      "0:\ttest: 0.2645525\tbest: 0.2645525 (0)\ttotal: 1.4s\tremaining: 9m 16s\n",
      "100:\ttest: 0.3842992\tbest: 0.3842992 (100)\ttotal: 2m 9s\tremaining: 6m 24s\n",
      "200:\ttest: 0.3909487\tbest: 0.3909755 (199)\ttotal: 4m 21s\tremaining: 4m 19s\n",
      "300:\ttest: 0.3942346\tbest: 0.3942453 (299)\ttotal: 6m 28s\tremaining: 2m 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 01:51:58,696] Trial 3 finished with value: 0.39648784413232696 and parameters: {'learning_rate': 0.08570310155536492, 'depth': 7, 'l2_leaf_reg': 0.013531731299897933, 'random_strength': 0.10272194993875035, 'bagging_temperature': 0.10746148003140243, 'border_count': 222}. Best is trial 0 with value: 0.39859924419192555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399:\ttest: 0.3964785\tbest: 0.3964878 (398)\ttotal: 8m 34s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3964878441\n",
      "bestIteration = 398\n",
      "\n",
      "Shrink model to first 399 iterations.\n",
      "0:\ttest: 0.3018309\tbest: 0.3018309 (0)\ttotal: 2.56s\tremaining: 17m 1s\n",
      "100:\ttest: 0.3879837\tbest: 0.3880695 (99)\ttotal: 3m 44s\tremaining: 11m 5s\n",
      "200:\ttest: 0.3936960\tbest: 0.3937362 (199)\ttotal: 7m 17s\tremaining: 7m 13s\n",
      "300:\ttest: 0.3966767\tbest: 0.3966767 (300)\ttotal: 10m 52s\tremaining: 3m 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:06:26,482] Trial 4 finished with value: 0.39874119395399443 and parameters: {'learning_rate': 0.07714031806517758, 'depth': 11, 'l2_leaf_reg': 6.283026147398587, 'random_strength': 0.3456940983125714, 'bagging_temperature': 0.28284103079597067, 'border_count': 239}. Best is trial 4 with value: 0.39874119395399443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399:\ttest: 0.3986592\tbest: 0.3987412 (393)\ttotal: 14m 25s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.398741194\n",
      "bestIteration = 393\n",
      "\n",
      "Shrink model to first 394 iterations.\n",
      "0:\ttest: 0.2965233\tbest: 0.2965233 (0)\ttotal: 2.1s\tremaining: 13m 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:06:41,126] Trial 5 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.315739417\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.3125094\tbest: 0.3125094 (0)\ttotal: 2.49s\tremaining: 16m 34s\n",
      "100:\ttest: 0.3888285\tbest: 0.3888285 (100)\ttotal: 4m 2s\tremaining: 11m 59s\n",
      "200:\ttest: 0.3944491\tbest: 0.3944491 (200)\ttotal: 7m 52s\tremaining: 7m 48s\n",
      "300:\ttest: 0.3977955\tbest: 0.3980139 (299)\ttotal: 11m 46s\tremaining: 3m 52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:22:23,480] Trial 6 finished with value: 0.40022295038525013 and parameters: {'learning_rate': 0.06838901258399085, 'depth': 12, 'l2_leaf_reg': 1.6882516888744639, 'random_strength': 0.185823675147253, 'bagging_temperature': 0.4923294314873814, 'border_count': 158}. Best is trial 6 with value: 0.40022295038525013.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399:\ttest: 0.4002230\tbest: 0.4002230 (399)\ttotal: 15m 38s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4002229504\n",
      "bestIteration = 399\n",
      "\n",
      "0:\ttest: 0.2911280\tbest: 0.2911280 (0)\ttotal: 2.01s\tremaining: 13m 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:22:37,903] Trial 7 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3347573925\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.2555037\tbest: 0.2555037 (0)\ttotal: 1.39s\tremaining: 9m 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:22:47,662] Trial 8 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3027411877\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.2733042\tbest: 0.2733042 (0)\ttotal: 1.6s\tremaining: 10m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:22:59,183] Trial 9 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3231791248\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.3062524\tbest: 0.3062524 (0)\ttotal: 2.62s\tremaining: 17m 27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:23:58,811] Trial 10 pruned. Trial was pruned at iteration 23.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3667069006\n",
      "bestIteration = 23\n",
      "\n",
      "Shrink model to first 24 iterations.\n",
      "0:\ttest: 0.3107411\tbest: 0.3107411 (0)\ttotal: 2.89s\tremaining: 19m 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:24:30,614] Trial 11 pruned. Trial was pruned at iteration 11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.35599329\n",
      "bestIteration = 11\n",
      "\n",
      "Shrink model to first 12 iterations.\n",
      "0:\ttest: 0.2829340\tbest: 0.2829340 (0)\ttotal: 1.71s\tremaining: 11m 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:24:44,139] Trial 12 pruned. Trial was pruned at iteration 7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.346320588\n",
      "bestIteration = 7\n",
      "\n",
      "Shrink model to first 8 iterations.\n",
      "0:\ttest: 0.3106512\tbest: 0.3106512 (0)\ttotal: 2.66s\tremaining: 17m 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:25:03,799] Trial 13 pruned. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3433788643\n",
      "bestIteration = 6\n",
      "\n",
      "Shrink model to first 7 iterations.\n",
      "0:\ttest: 0.3018905\tbest: 0.3018905 (0)\ttotal: 2.71s\tremaining: 18m 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:26:05,813] Trial 14 pruned. Trial was pruned at iteration 24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3674096328\n",
      "bestIteration = 24\n",
      "\n",
      "Shrink model to first 25 iterations.\n",
      "0:\ttest: 0.2999757\tbest: 0.2999757 (0)\ttotal: 2.33s\tremaining: 15m 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:27:25,873] Trial 15 pruned. Trial was pruned at iteration 37.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3742446701\n",
      "bestIteration = 37\n",
      "\n",
      "Shrink model to first 38 iterations.\n",
      "0:\ttest: 0.2810369\tbest: 0.2810369 (0)\ttotal: 1.45s\tremaining: 9m 37s\n",
      "100:\ttest: 0.3896776\tbest: 0.3896776 (100)\ttotal: 2m 18s\tremaining: 6m 49s\n",
      "200:\ttest: 0.3950736\tbest: 0.3950736 (200)\ttotal: 4m 34s\tremaining: 4m 31s\n",
      "300:\ttest: 0.3971765\tbest: 0.3974169 (299)\ttotal: 6m 49s\tremaining: 2m 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:36:06,655] Trial 16 finished with value: 0.3983432429944145 and parameters: {'learning_rate': 0.09900849563228, 'depth': 9, 'l2_leaf_reg': 0.1134025187680777, 'random_strength': 0.7351811381885495, 'bagging_temperature': 0.4274699723809353, 'border_count': 156}. Best is trial 6 with value: 0.40022295038525013.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.398343243\n",
      "bestIteration = 330\n",
      "\n",
      "Shrink model to first 331 iterations.\n",
      "0:\ttest: 0.3018065\tbest: 0.3018065 (0)\ttotal: 2.32s\tremaining: 15m 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:36:22,734] Trial 17 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3386637366\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.3063153\tbest: 0.3063153 (0)\ttotal: 2.3s\tremaining: 15m 17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:36:38,747] Trial 18 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3283572493\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.3028284\tbest: 0.3028284 (0)\ttotal: 2.21s\tremaining: 14m 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:36:53,397] Trial 19 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3445778007\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.2750139\tbest: 0.2750139 (0)\ttotal: 1.57s\tremaining: 10m 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:37:03,975] Trial 20 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3186919261\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.3031022\tbest: 0.3031022 (0)\ttotal: 2.48s\tremaining: 16m 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:37:28,369] Trial 21 pruned. Trial was pruned at iteration 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3589417465\n",
      "bestIteration = 10\n",
      "\n",
      "Shrink model to first 11 iterations.\n",
      "0:\ttest: 0.3067763\tbest: 0.3067763 (0)\ttotal: 2.27s\tremaining: 15m 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:37:42,569] Trial 22 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.340821202\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.3113857\tbest: 0.3113857 (0)\ttotal: 2.56s\tremaining: 17m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:38:43,879] Trial 23 pruned. Trial was pruned at iteration 23.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3693684689\n",
      "bestIteration = 23\n",
      "\n",
      "Shrink model to first 24 iterations.\n",
      "0:\ttest: 0.3071430\tbest: 0.3071430 (0)\ttotal: 1.97s\tremaining: 13m 5s\n",
      "100:\ttest: 0.3884330\tbest: 0.3884330 (100)\ttotal: 3m 15s\tremaining: 9m 37s\n",
      "200:\ttest: 0.3936304\tbest: 0.3936304 (200)\ttotal: 6m 26s\tremaining: 6m 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:45:27,490] Trial 24 pruned. Trial was pruned at iteration 208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3938154991\n",
      "bestIteration = 206\n",
      "\n",
      "Shrink model to first 207 iterations.\n",
      "0:\ttest: 0.2996527\tbest: 0.2996527 (0)\ttotal: 2s\tremaining: 13m 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:45:41,502] Trial 25 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3285896666\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.3153254\tbest: 0.3153254 (0)\ttotal: 2.72s\tremaining: 18m 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 02:45:59,617] Trial 26 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3441221472\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.3077845\tbest: 0.3077845 (0)\ttotal: 2.44s\tremaining: 16m 14s\n",
      "100:\ttest: 0.3884804\tbest: 0.3884804 (100)\ttotal: 3m 36s\tremaining: 10m 39s\n",
      "200:\ttest: 0.3943978\tbest: 0.3944777 (199)\ttotal: 7m 3s\tremaining: 6m 59s\n",
      "300:\ttest: 0.3972099\tbest: 0.3974172 (297)\ttotal: 10m 31s\tremaining: 3m 27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 03:00:01,900] Trial 27 finished with value: 0.39925047662254987 and parameters: {'learning_rate': 0.09537282722595875, 'depth': 11, 'l2_leaf_reg': 9.758875166860346, 'random_strength': 0.4683469350761278, 'bagging_temperature': 0.6894660735656242, 'border_count': 173}. Best is trial 6 with value: 0.40022295038525013.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399:\ttest: 0.3991691\tbest: 0.3992505 (391)\ttotal: 13m 59s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3992504766\n",
      "bestIteration = 391\n",
      "\n",
      "Shrink model to first 392 iterations.\n",
      "0:\ttest: 0.2927725\tbest: 0.2927725 (0)\ttotal: 1.4s\tremaining: 9m 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 03:00:12,211] Trial 28 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3455866123\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.3111343\tbest: 0.3111343 (0)\ttotal: 2.93s\tremaining: 19m 30s\n",
      "100:\ttest: 0.3887946\tbest: 0.3887946 (100)\ttotal: 4m 14s\tremaining: 12m 32s\n",
      "200:\ttest: 0.3948677\tbest: 0.3948677 (200)\ttotal: 8m 15s\tremaining: 8m 10s\n",
      "300:\ttest: 0.3976128\tbest: 0.3976310 (286)\ttotal: 12m 19s\tremaining: 4m 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 03:16:33,814] Trial 29 finished with value: 0.39990307103906114 and parameters: {'learning_rate': 0.07299365219549724, 'depth': 12, 'l2_leaf_reg': 1.9158609514635259, 'random_strength': 0.4774629579529207, 'bagging_temperature': 0.8541618523931782, 'border_count': 237}. Best is trial 6 with value: 0.40022295038525013.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399:\ttest: 0.3997913\tbest: 0.3999031 (397)\ttotal: 16m 18s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.399903071\n",
      "bestIteration = 397\n",
      "\n",
      "Shrink model to first 398 iterations.\n",
      "0:\ttest: 0.3133744\tbest: 0.3133744 (0)\ttotal: 2.89s\tremaining: 19m 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 03:16:52,011] Trial 30 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3402953032\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.3099347\tbest: 0.3099347 (0)\ttotal: 2.74s\tremaining: 18m 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 03:17:15,914] Trial 31 pruned. Trial was pruned at iteration 7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3511792729\n",
      "bestIteration = 7\n",
      "\n",
      "Shrink model to first 8 iterations.\n",
      "0:\ttest: 0.3013516\tbest: 0.3013516 (0)\ttotal: 2.75s\tremaining: 18m 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 03:17:32,150] Trial 32 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3414897515\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.3020611\tbest: 0.3020611 (0)\ttotal: 2.48s\tremaining: 16m 28s\n",
      "100:\ttest: 0.3896272\tbest: 0.3898336 (98)\ttotal: 3m 42s\tremaining: 10m 58s\n",
      "200:\ttest: 0.3950366\tbest: 0.3950370 (199)\ttotal: 7m 15s\tremaining: 7m 11s\n",
      "300:\ttest: 0.3976788\tbest: 0.3979828 (289)\ttotal: 10m 52s\tremaining: 3m 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 03:31:57,410] Trial 33 finished with value: 0.3998253151968382 and parameters: {'learning_rate': 0.08601842196892498, 'depth': 11, 'l2_leaf_reg': 2.2645774637097236, 'random_strength': 0.18425504171294013, 'bagging_temperature': 0.6628665776577807, 'border_count': 213}. Best is trial 6 with value: 0.40022295038525013.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399:\ttest: 0.3998253\tbest: 0.3998253 (399)\ttotal: 14m 22s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3998253152\n",
      "bestIteration = 399\n",
      "\n",
      "0:\ttest: 0.3009680\tbest: 0.3009680 (0)\ttotal: 2.81s\tremaining: 18m 40s\n",
      "100:\ttest: 0.3898163\tbest: 0.3898690 (99)\ttotal: 3m 47s\tremaining: 11m 12s\n",
      "200:\ttest: 0.3952769\tbest: 0.3957069 (191)\ttotal: 7m 20s\tremaining: 7m 16s\n",
      "300:\ttest: 0.3978623\tbest: 0.3979615 (298)\ttotal: 10m 56s\tremaining: 3m 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 03:46:31,940] Trial 34 finished with value: 0.39951492261945243 and parameters: {'learning_rate': 0.08414526842055725, 'depth': 11, 'l2_leaf_reg': 2.16803181222979, 'random_strength': 0.17161242294608234, 'bagging_temperature': 0.664501480898066, 'border_count': 222}. Best is trial 6 with value: 0.40022295038525013.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399:\ttest: 0.3994313\tbest: 0.3995149 (398)\ttotal: 14m 31s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3995149226\n",
      "bestIteration = 398\n",
      "\n",
      "Shrink model to first 399 iterations.\n",
      "0:\ttest: 0.3059095\tbest: 0.3059095 (0)\ttotal: 2.62s\tremaining: 17m 25s\n",
      "100:\ttest: 0.3904070\tbest: 0.3904967 (98)\ttotal: 4m 11s\tremaining: 12m 25s\n",
      "200:\ttest: 0.3946239\tbest: 0.3946239 (200)\ttotal: 8m 12s\tremaining: 8m 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 03:56:29,054] Trial 35 pruned. Trial was pruned at iteration 242.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3957765094\n",
      "bestIteration = 234\n",
      "\n",
      "Shrink model to first 235 iterations.\n",
      "Best PFound: 0.40022295038525013\n",
      "Best hyperparameters:\n",
      "  learning_rate: 0.06838901258399085\n",
      "  depth: 12\n",
      "  l2_leaf_reg: 1.6882516888744639\n",
      "  random_strength: 0.185823675147253\n",
      "  bagging_temperature: 0.4923294314873814\n",
      "  border_count: 158\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params_cat = {\n",
    "        'loss_function': 'YetiRank',\n",
    "        'eval_metric': 'NDCG:top=5',\n",
    "        'random_seed': 22,\n",
    "        'od_type': 'Iter',\n",
    "        'od_wait': 20,\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int(\"depth\", 6, 12),\n",
    "        'l2_leaf_reg': trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10.0, log=True),\n",
    "        'random_strength': trial.suggest_float(\"random_strength\", 1e-3, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "        'border_count': trial.suggest_int(\"border_count\", 32, 255),\n",
    "        'iterations': 400,\n",
    "        'use_best_model': True,\n",
    "        'verbose': 100,\n",
    "    }\n",
    "\n",
    "    model_cat = CatBoostRanker(**params_cat)\n",
    "\n",
    "    # Pruner callback for PFound\n",
    "    pruning_callback = CatBoostPruningCallback(trial, 'NDCG:top=5;type=Base')\n",
    "\n",
    "\n",
    "    model_cat.fit(\n",
    "        train_pool,\n",
    "        eval_set=val_pool,\n",
    "        early_stopping_rounds=50,\n",
    "        callbacks=[pruning_callback],\n",
    "    )\n",
    "\n",
    "    # Manually trigger pruning\n",
    "    pruning_callback.check_pruned()\n",
    "\n",
    "     # 5) Grab the best‐iteration score\n",
    "    hist = model_cat.get_evals_result()['validation']['NDCG:top=5;type=Base']\n",
    "    return max(hist) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"catboost_yetirank\",\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    ")\n",
    "study.optimize(objective, n_trials=50, timeout=10000)\n",
    "\n",
    "print(f\"Best PFound: {study.best_trial.value}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for k, v in study.best_trial.params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73774e92-d62b-494c-bcc4-4a71b6d2ed26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "  learning_rate: 0.06838901258399085\n",
      "  depth: 12\n",
      "  l2_leaf_reg: 1.6882516888744639\n",
      "  random_strength: 0.185823675147253\n",
      "  bagging_temperature: 0.4923294314873814\n",
      "  border_count: 158\n",
      "0:\ttotal: 3.96s\tremaining: 1h 5m 55s\n",
      "100:\ttotal: 5m 9s\tremaining: 45m 54s\n",
      "200:\ttotal: 10m 2s\tremaining: 39m 53s\n",
      "300:\ttotal: 14m 57s\tremaining: 34m 44s\n",
      "400:\ttotal: 19m 54s\tremaining: 29m 44s\n",
      "500:\ttotal: 24m 51s\tremaining: 24m 45s\n",
      "600:\ttotal: 29m 48s\tremaining: 19m 47s\n",
      "700:\ttotal: 34m 47s\tremaining: 14m 50s\n",
      "800:\ttotal: 39m 48s\tremaining: 9m 53s\n",
      "900:\ttotal: 44m 48s\tremaining: 4m 55s\n",
      "999:\ttotal: 49m 45s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x1b8eb539ac0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_params_cat = study.best_trial.params # Corrected line\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in best_params_cat.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "final_params_cat= {**best_params_cat, 'iterations': 1000, 'verbose': 100} #added verbose\n",
    "final_cat = CatBoostRanker(**final_params_cat)\n",
    "final_cat.fit(\n",
    "    full_pool,\n",
    "    early_stopping_rounds=100\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48302777-0194-4965-a7c3-e1d508ec1a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Predict on test set\n",
    "cat_test_preds = final_cat.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79ada07e-f959-4685-9006-2d37dbcd7a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv written using lgb only!\n"
     ]
    }
   ],
   "source": [
    "# 2) Put them into your submission\n",
    "\n",
    "#can use cat_test_pred or lgb_test_preds\n",
    "\n",
    "sample['score'] = lgb_test_preds\n",
    "submission = (\n",
    "    sample\n",
    "    .sort_values(['srch_id', 'score'], ascending=[True, False])\n",
    "    [['srch_id', 'prop_id']]\n",
    ")\n",
    "\n",
    "# 3) Write to CSV\n",
    "submission.to_csv('submission0.csv', index=False)\n",
    "print(\"submission.csv written using lgb only!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2acd28c4-fd34-4622-b6ef-0b93c42f8670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'params = {\\n    \\'loss_function\\':       \\'YetiRank\\',\\n    \\'eval_metric\\':         \\'NDCG:top=5\\',\\n    \\'random_seed\\':         22,\\n    \\'od_type\\':             \\'Iter\\',\\n    \\'od_wait\\':             20,\\n    \\'learning_rate\\':       0.05,\\n    \\'depth\\':               8,\\n    \\'l2_leaf_reg\\':         3.0,\\n    \\'random_strength\\':     1.0,\\n    \\'bagging_temperature\\': 0.2,\\n    \\'border_count\\':        128,\\n    \\'iterations\\':          1000,\\n    \\'use_best_model\\':      True,\\n    \\'verbose\\':             100,\\n}\\n\\n# 3) Train\\nmodel = CatBoostRanker(**params)\\nmodel.fit(\\n    train_pool,\\n    eval_set=val_pool,\\n    early_stopping_rounds=50,\\n    verbose=False,            # or True to see each iteration\\n    verbose_eval=100,         # log every 100 iters\\n)\\n\\n# 4) Best iteration\\nbest_iter = model.get_best_iteration()\\nprint(\"Best iteration:\", best_iter)\\n\\n# 5) Validation NDCG@5 history\\nndcg_history = model.get_evals_result()[\\'validation\\'][\\'NDCG:top=5;type=Base\\']\\nprint(f\"Validation NDCG@5 @ best_iter: {ndcg_history[best_iter]:.4f}\")\\n\\n# 6) Retrain on full data if desired\\n# full_pool = Pool(X_full, label=y_full, group_id=id_full)\\n# model_full = CatBoostRanker(**params)\\n# model_full.fit(full_pool, use_best_model=True)\\n\\n# 7) Predict on test\\n# test_pool = Pool(X_test)  # note: no label needed\\n# test_preds = model_full.predict(test_pool)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"params = {\n",
    "    'loss_function':       'YetiRank',\n",
    "    'eval_metric':         'NDCG:top=5',\n",
    "    'random_seed':         22,\n",
    "    'od_type':             'Iter',\n",
    "    'od_wait':             20,\n",
    "    'learning_rate':       0.05,\n",
    "    'depth':               8,\n",
    "    'l2_leaf_reg':         3.0,\n",
    "    'random_strength':     1.0,\n",
    "    'bagging_temperature': 0.2,\n",
    "    'border_count':        128,\n",
    "    'iterations':          1000,\n",
    "    'use_best_model':      True,\n",
    "    'verbose':             100,\n",
    "}\n",
    "\n",
    "# 3) Train\n",
    "model = CatBoostRanker(**params)\n",
    "model.fit(\n",
    "    train_pool,\n",
    "    eval_set=val_pool,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=False,            # or True to see each iteration\n",
    "    verbose_eval=100,         # log every 100 iters\n",
    ")\n",
    "\n",
    "# 4) Best iteration\n",
    "best_iter = model.get_best_iteration()\n",
    "print(\"Best iteration:\", best_iter)\n",
    "\n",
    "# 5) Validation NDCG@5 history\n",
    "ndcg_history = model.get_evals_result()['validation']['NDCG:top=5;type=Base']\n",
    "print(f\"Validation NDCG@5 @ best_iter: {ndcg_history[best_iter]:.4f}\")\n",
    "\n",
    "# 6) Retrain on full data if desired\n",
    "# full_pool = Pool(X_full, label=y_full, group_id=id_full)\n",
    "# model_full = CatBoostRanker(**params)\n",
    "# model_full.fit(full_pool, use_best_model=True)\n",
    "\n",
    "# 7) Predict on test\n",
    "# test_pool = Pool(X_test)  # note: no label needed\n",
    "# test_preds = model_full.predict(test_pool)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3eb20bf6-7ab7-4a2c-9572-727a7e61005d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_it' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Predict raw scores for the validation set\u001b[39;00m\n\u001b[0;32m      2\u001b[0m cat_val_preds \u001b[38;5;241m=\u001b[39m final_cat\u001b[38;5;241m.\u001b[39mpredict(X_va)\n\u001b[1;32m----> 3\u001b[0m lgb_val_preds \u001b[38;5;241m=\u001b[39m model_lgb_full\u001b[38;5;241m.\u001b[39mpredict(X_va, num_iteration\u001b[38;5;241m=\u001b[39m\u001b[43mbest_it\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 2. Compute per-session NDCG@5 manually\u001b[39;00m\n\u001b[0;32m      6\u001b[0m ndcgs_cat \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_it' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Predict raw scores for the validation set\n",
    "cat_val_preds = final_cat.predict(X_va)\n",
    "lgb_val_preds = model_lgb_full.predict(X_va, num_iteration=best_it)\n",
    "\n",
    "# 2. Compute per-session NDCG@5 manually\n",
    "ndcgs_cat = []\n",
    "ndcgs_lgb = []\n",
    "\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:  # skip sessions with only 1 result\n",
    "        true_rels = y_va[idx]\n",
    "        ndcgs_cat.append(ndcg_score([true_rels], [cat_val_preds[idx]], k=5))\n",
    "        ndcgs_lgb.append(ndcg_score([true_rels], [lgb_val_preds[idx]], k=5))\n",
    "\n",
    "# 3. Average NDCG@5 for both models\n",
    "catboost_ndcg5 = np.mean(ndcgs_cat)\n",
    "lgb_ndcg5 = np.mean(ndcgs_lgb)\n",
    "\n",
    "print(f\"\\nCatBoost Val NDCG@5: {catboost_ndcg5:.4f}\")\n",
    "print(f\"\\nLightGBM Val NDCG@5: {lgb_ndcg5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991fd44-41cb-4f3c-8643-bb5f041603a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1) Scale just your two tree-based model preds on validation\n",
    "cb_s  = minmax(cat_val_preds)   # your CatBoost val preds\n",
    "lgb_s = minmax(lgb_val_preds)   # your LightGBM val preds\n",
    "\n",
    "# 2) Sweep over blends of just CB + LGB\n",
    "best, best_w = 0, None\n",
    "for w_cb in np.linspace(0, 1, 11):\n",
    "    w_lgb = 1 - w_cb\n",
    "    sc = w_cb * cb_s + w_lgb * lgb_s\n",
    "\n",
    "    # compute NDCG@5 on val\n",
    "    ndcgs = []\n",
    "    for q in np.unique(id_va):\n",
    "        idx = np.where(id_va == q)[0]\n",
    "        if len(idx) > 1:\n",
    "            true = y_va[idx]\n",
    "            ndcgs.append(ndcg_score([true], [sc[idx]], k=5))\n",
    "    mean_ndcg = np.mean(ndcgs)\n",
    "\n",
    "    print(f\"w_cb={w_cb:.1f}, w_lgb={w_lgb:.1f} → Val NDCG@5: {mean_ndcg:.4f}\")\n",
    "    if mean_ndcg > best:\n",
    "        best, best_w = mean_ndcg, (w_cb, w_lgb)\n",
    "\n",
    "print(f\"\\n Best blend (CB+LGB): w_cb={best_w[0]:.2f}, w_lgb={best_w[1]:.2f} → NDCG@5={best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30e54659-6f48-4d9e-94ac-fecb7f8d15cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission.csv written using w_cb=0.50, w_lgb=0.50!\n"
     ]
    }
   ],
   "source": [
    "# --- Ensemble the test predictions with your optimal blend ---\n",
    "best_w = [0.5,0.5]\n",
    "\n",
    "ensemble_final_preds = ensemble_predictions(\n",
    "    cat_test_preds,\n",
    "    lgb_test_preds,\n",
    "    weights=[best_w[0], best_w[1]]\n",
    ")\n",
    "\n",
    "# Put them into submission\n",
    "sample['score'] = ensemble_final_preds\n",
    "submission = (\n",
    "    sample\n",
    "    .sort_values(['srch_id','score'], ascending=[True, False])\n",
    "    [['srch_id','prop_id']]\n",
    ")\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission.csv written using w_cb={best_w[0]:.2f}, w_lgb={best_w[1]:.2f}!\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb83c75e-269c-42e8-bb86-88459e9cb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cat_preds.pkl', 'wb') as file:\n",
    "    pickle.dump(cat_test_preds, file)\n",
    "\n",
    "with open('lgb_preds.pkl', 'wb') as file:\n",
    "    pickle.dump(lgb_test_preds, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ccd16-188e-40cc-8d80-e176c305925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# --- 1) ListNet loss (unchanged) ---\n",
    "def listnet_loss(scores, labels, group_ids):\n",
    "    loss, count = 0.0, 0\n",
    "    for q in np.unique(group_ids):\n",
    "        idx = np.where(group_ids == q)[0]\n",
    "        if len(idx) < 2:\n",
    "            continue\n",
    "        s_q, y_q = scores[idx], labels[idx].float()\n",
    "        P, P_hat = torch.softmax(y_q, 0), torch.softmax(s_q, 0)\n",
    "        loss += -torch.sum(P * torch.log(P_hat + 1e-8))\n",
    "        count += 1\n",
    "    return loss / max(count, 1)\n",
    "\n",
    "param_grid = {\n",
    "    'lr':           [1e-3, 2e-3],\n",
    "    'batch_size':   [512, 1024],\n",
    "    'dropout':      [0.1, 0.2],\n",
    "    'weight_decay': [0.0, 1e-4]\n",
    "}\n",
    "\n",
    "best = {'ndcg': 0.0, 'cfg': None}\n",
    "\n",
    "for lr, bs, drop, wd in itertools.product(*param_grid.values()):\n",
    "    tr_loader = DataLoader(ExpediaDataset(X_tr, y_tr.values),\n",
    "                           batch_size=bs, shuffle=True)\n",
    "    va_loader = DataLoader(ExpediaDataset(X_va, y_va.values),\n",
    "                           batch_size=bs, shuffle=False)\n",
    "\n",
    "    mdl = DeepRecommender(X_tr.shape[1]).to(device)\n",
    "    for m in mdl.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.p = drop\n",
    "\n",
    "    opt = torch.optim.Adam(\n",
    "        mdl.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=wd\n",
    "    )\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt,\n",
    "        max_lr=lr * 10,\n",
    "        steps_per_epoch=len(tr_loader),\n",
    "        epochs=10\n",
    "    )\n",
    "\n",
    "    best_ndcg, stale = 0.0, 0\n",
    "    for epoch in range(1, 8):\n",
    "        # — train —\n",
    "        mdl.train()\n",
    "        for Xb, yb in tr_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = listnet_loss(mdl(Xb), yb, id_tr[:len(Xb)])\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        # — validate —\n",
    "        mdl.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for Xb, _ in va_loader:\n",
    "                preds.extend(mdl(Xb.to(device)).cpu().numpy())\n",
    "        preds = np.array(preds)\n",
    "\n",
    "        # compute mean NDCG@5 using the same y_va array\n",
    "        ndcgs = []\n",
    "        for q in np.unique(id_va):\n",
    "            idx = np.where(id_va == q)[0]\n",
    "            if len(idx) > 1:\n",
    "                true = y_va.values[idx]\n",
    "                score = preds[idx]\n",
    "                ndcgs.append(ndcg_score([true], [score], k=5))\n",
    "        mean_ndcg = np.mean(ndcgs)\n",
    "        sched.step(mean_ndcg)\n",
    "\n",
    "        if mean_ndcg > best_ndcg + 1e-4:\n",
    "            best_ndcg, stale = mean_ndcg, 0\n",
    "        else:\n",
    "            stale += 1\n",
    "        if stale >= 5:\n",
    "            break\n",
    "\n",
    "    print(f\"cfg lr={lr}, bs={bs}, drop={drop} → Val NDCG@5: {best_ndcg:.4f}\")\n",
    "    if best_ndcg > best['ndcg']:\n",
    "        best.update({'ndcg': best_ndcg, 'cfg': (lr, bs, drop)})\n",
    "\n",
    "print(\"🏆 Best config:\", best)\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4855e15-4c6b-492f-a267-979ef406a160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef09feb-986f-496e-a691-8fedcee3d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# unpack your best cfg and tweak\n",
    "lr, bs, drop, wd = 1e-3, 128, 0.1, 1e-5\n",
    "\n",
    "# rebuild full-training loader\n",
    "full_loader = DataLoader(\n",
    "    ExpediaDatasetGrouped(X_full, y_full, id_full),\n",
    "    batch_size=bs, shuffle=True\n",
    ")\n",
    "\n",
    "# 1) Slightly larger network at the top\n",
    "class BiggerRecommender(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512), nn.ReLU(), nn.BatchNorm1d(512), nn.Dropout(drop),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.BatchNorm1d(256), nn.Dropout(drop),\n",
    "            nn.Linear(256, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(drop),\n",
    "            nn.Linear(128, 64),  nn.ReLU(), nn.Dropout(drop),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "final_nn = BiggerRecommender(X_full.shape[1]).to(device)\n",
    "\n",
    "# 2) Optimizer with very light weight decay\n",
    "opt = torch.optim.Adam(final_nn.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "# 3) Simpler stepLR scheduler (cuts LR by 0.5 every 10 epochs)\n",
    "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.5)\n",
    "\n",
    "# 4) Train for 30 epochs with gradient clipping\n",
    "for epoch in range(1, 31):\n",
    "    final_nn.train()\n",
    "    total_loss = 0.0\n",
    "    for Xb, yb, gb in full_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = final_nn(Xb)\n",
    "        loss   = listnet_loss(logits, yb, gb)  \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(final_nn.parameters(), 5.0)\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item() * Xb.size(0)\n",
    "\n",
    "    sched.step()\n",
    "    avg_loss = total_loss / len(full_loader.dataset)\n",
    "    print(f\"Epoch {epoch:02d}/30 — Avg ListNet Loss: {avg_loss:.4f} — LR: {opt.param_groups[0]['lr']:.1e}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f70ffb-f18d-43e7-a272-cbc58ee1c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# --- 4) Produce final test preds ---\n",
    "test_loader = DataLoader(\n",
    "    ExpediaDataset(X_test, np.zeros(len(X_test))),\n",
    "    batch_size=bs,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "nn_test_preds = []\n",
    "final_nn.eval()\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in test_loader:           # <-- unpack both X and dummy y\n",
    "        Xb = Xb.to(device)\n",
    "        nn_test_preds.extend(\n",
    "            torch.sigmoid(final_nn(Xb))\n",
    "                 .cpu()\n",
    "                 .numpy()\n",
    "        )\n",
    "nn_test_preds = np.array(nn_test_preds)\n",
    "\n",
    "print(\"NN preds:\", nn_test_preds.min(), nn_test_preds.max())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90180b4-66a8-435f-ad08-d1a9af7af2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 1) Get NN probabilities on the validation fold\n",
    "nn_val_probs = []\n",
    "final_nn.eval()\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in va_loader:\n",
    "        nn_val_probs.extend(\n",
    "            torch.sigmoid(final_nn(Xb.to(device)))\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "nn_val_probs = np.array(nn_val_probs)  # shape = (n_val,)\n",
    "\n",
    "# 2) Compute per-session NDCG@5\n",
    "ndcgs = []\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:\n",
    "        true_rels = y_val_nn[idx]\n",
    "        scores    = nn_val_probs[idx]\n",
    "        ndcgs.append(ndcg_score([true_rels], [scores], k=5))\n",
    "\n",
    "nn_val_ndcg5 = np.mean(ndcgs)\n",
    "print(f\"NN  Val NDCG@5: {nn_val_ndcg5:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af293dc-e382-4a3a-bee5-e767a32048c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# --- Ensemble the predictions ---\n",
    "ensemble_final_preds = ensemble_predictions(nn_test_preds, model_lgb_pred, weights=[0.5, 0.5]) # Adjust weights\n",
    "\n",
    "# Predict relevance scores for each test row\n",
    "preds_ens = ensemble_final_preds\n",
    "\n",
    "# Insert those scores into the sample submission DataFrame\n",
    "sample['score'] = preds_ens\n",
    "\n",
    "# Sort by search session (ascending) and score (descending)\n",
    "#   so that for each srch_id, the most relevant prop_id comes first\n",
    "submission = sample.sort_values(\n",
    "    ['srch_id', 'score'],\n",
    "    ascending=[True, False]\n",
    ")\n",
    "\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3c1e5-a601-4f56-b331-cfbce1e4753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 1) LightGBM val set predictions\n",
    "# Replace `model_lgb` with whatever variable you named your trained LightGBM model\n",
    "val_preds_lgb = model_lgb.predict(X_va)   # shape = (n_val,)\n",
    "\n",
    "# 2) NN val set predictions\n",
    "final_nn.eval()\n",
    "nn_val_preds = []\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in va_loader:  # va_loader from your NN split on X_va/y_va\n",
    "        nn_val_preds.extend(\n",
    "            torch.sigmoid(final_nn(Xb.to(device))).cpu().numpy()\n",
    "        )\n",
    "nn_val_preds = np.array(nn_val_preds)      # shape = (n_val,)\n",
    "\n",
    "# 3) Blend them\n",
    "w_nn, w_lgb = 0.4, 0.6\n",
    "ensemble_val = w_nn * nn_val_preds + w_lgb * val_preds_lgb\n",
    "\n",
    "\n",
    "ndcgs = []\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:\n",
    "        true_rel  = y_val_nn[idx]    # your val labels array\n",
    "        score_rel = ensemble_val[idx]\n",
    "        ndcgs.append(ndcg_score([true_rel], [score_rel], k=5))\n",
    "\n",
    "mean_ndcg5 = np.mean(ndcgs)\n",
    "print(f\"Ensembled Val NDCG@5: {mean_ndcg5:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35a973-a5cc-4f52-afb4-b8ae2f7b9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 1) Min–max scale each prediction array into [0,1]\n",
    "def minmax(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
    "\n",
    "nn_scaled  = minmax(nn_test_preds)\n",
    "lgb_scaled = minmax(model_lgb_pred)   # or whatever your LGB test‐preds variable is\n",
    "\n",
    "# 2) Do the two blends\n",
    "ens1 = ensemble_predictions(nn_scaled, lgb_scaled, [0.5, 0.5])\n",
    "ens2 = ensemble_predictions(nn_scaled, lgb_scaled, [0.0, 1.0])\n",
    "\n",
    "# 3) Compare their sorted‐order permutations\n",
    "order1 = np.argsort(ens1)\n",
    "order2 = np.argsort(ens2)\n",
    "\n",
    "# 4) Compute fraction of positions that differ\n",
    "fraction_changed = np.mean(order1 != order2)\n",
    "print(f\"Fraction of test‐rows whose position changes: {fraction_changed:.4%}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5d100-acc8-4754-9d9b-853cd760f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 0) Scale both NN & LGB validation predictions into [0,1]\n",
    "nn_scaled_val  = minmax_scale(nn_val_preds)      # shape = (n_val,)\n",
    "lgb_scaled_val = minmax_scale(val_preds_lgb)     # shape = (n_val,)\n",
    "\n",
    "best_w, best_score = None, 0.0\n",
    "for w_nn in np.linspace(0, 1, 11):\n",
    "    w_lgb = 1 - w_nn\n",
    "\n",
    "    # blended on the same [0,1] scale\n",
    "    blended = w_nn * nn_scaled_val + w_lgb * lgb_scaled_val\n",
    "\n",
    "    # compute NDCG@5 per session\n",
    "    ndcgs = []\n",
    "    for q in np.unique(id_va):\n",
    "        idx = np.where(id_va == q)[0]\n",
    "        if len(idx) > 1:\n",
    "            true   = y_val_nn[idx]\n",
    "            scores = blended[idx]\n",
    "            ndcgs.append(ndcg_score([true], [scores], k=5))\n",
    "    mean_ndcg = np.mean(ndcgs)\n",
    "\n",
    "    print(f\"w_nn={w_nn:.1f}, w_lgb={w_lgb:.1f} → Val NDCG@5: {mean_ndcg:.4f}\")\n",
    "    if mean_ndcg > best_score:\n",
    "        best_score, best_w = mean_ndcg, w_nn\n",
    "\n",
    "print(f\"\\n🏆 Best blend: w_nn={best_w:.2f}, w_lgb={1-best_w:.2f} → NDCG@5={best_score:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6eb97c-337e-4156-9a0c-0badb3dbabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df = sample[['srch_id']].copy()\n",
    "df['nn_rank']  = pd.DataFrame({'score': nn_test_preds,  'srch': sample['srch_id']}) \\\n",
    "                    .groupby('srch')['score'] \\\n",
    "                    .rank(method='dense', ascending=False)\n",
    "df['lgb_rank'] = pd.DataFrame({'score': model_lgb_pred,'srch': sample['srch_id']}) \\\n",
    "                    .groupby('srch')['score'] \\\n",
    "                    .rank(method='dense', ascending=False)\n",
    "\n",
    "# weighted rank\n",
    "w_nn, w_lgb = best_w, (1-best_w)\n",
    "df['ensemble_rank'] = w_nn * df['nn_rank'] + w_lgb * df['lgb_rank']\n",
    "\n",
    "# use that to sort\n",
    "submission = sample.assign(_rank=df['ensemble_rank']) \\\n",
    "    .sort_values(['srch_id','_rank'], ascending=[True,True]) \\\n",
    "    [['srch_id','prop_id']]\n",
    "\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7bccc1-01c7-405a-8e9f-913dc53fd5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df_sub = sample[['srch_id']].copy()\n",
    "df_sub['nn_rank']  = pd.Series(nn_test_preds).groupby(sample['srch_id']).rank(\"dense\", ascending=False)\n",
    "df_sub['lgb_rank'] = pd.Series(model_lgb_pred).groupby(sample['srch_id']).rank(\"dense\", ascending=False)\n",
    "\n",
    "# weighted rank blend\n",
    "df_sub['ensemble_rank'] = 0.2*df_sub['nn_rank'] + 0.8*df_sub['lgb_rank']\n",
    "\n",
    "submission = (\n",
    "    sample.assign(_rank=df_sub['ensemble_rank'])\n",
    "          .sort_values(['srch_id','_rank'], ascending=[True,True])\n",
    "          [['srch_id','prop_id']]\n",
    ")\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
