{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca254db0-81c6-46c4-a66e-9b7f66172755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score, roc_auc_score\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder,  minmax_scale\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GroupShuffleSplit\n",
    "import itertools\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from catboost import CatBoostRanker, Pool,  cv\n",
    "import optuna\n",
    "from optuna.integration import CatBoostPruningCallback\n",
    "from catboost.utils import eval_metric\n",
    "from optuna.pruners import SuccessiveHalvingPruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f7bcaa-d6d3-49c1-b9b0-5edec2d3a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the files changes path to where the data is stored\n",
    "test = pd.read_csv(r\"C:\\Users\\youpz\\Documents\\Master\\P5\\Data mining techniques\\Assignment2\\data\\dmt-2025-2nd-assignment\\test_set_VU_DM.csv\")\n",
    "train = pd.read_csv(r\"C:\\Users\\youpz\\Documents\\Master\\P5\\Data mining techniques\\Assignment2\\data\\dmt-2025-2nd-assignment\\training_set_VU_DM.csv\")\n",
    "sample = pd.read_csv(r\"C:\\Users\\youpz\\Documents\\Master\\P5\\Data mining techniques\\Assignment2\\data\\dmt-2025-2nd-assignment\\submission_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a5d234-6885-41df-bdf7-94794f3df4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "    \"\"\"Returns a DataFrame with missing counts and percent missing for each column.\"\"\"\n",
    "    n = len(df)\n",
    "    missing_count   = df.isna().sum()\n",
    "    missing_percent = 100 * missing_count / n\n",
    "    missing_df = (\n",
    "        pd.DataFrame({\n",
    "            'missing_count':   missing_count,\n",
    "            'missing_percent': missing_percent\n",
    "        })\n",
    "        .sort_values('missing_percent', ascending=False)\n",
    "    )\n",
    "    return missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0e5c47-2faf-4d18-9955-94abd8b44a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "comp3_rate                       3424059        69.056462\n",
      "comp3_inv                        3307357        66.702814\n",
      "comp8_rate                       3041693        61.344900\n",
      "comp8_inv                        2970844        59.916016\n",
      "comp2_rate                       2933675        59.166392\n",
      "comp2_inv                        2828078        57.036710\n",
      "comp5_rate                       2735974        55.179155\n",
      "comp5_inv                        2598327        52.403089\n",
      "orig_destination_distance        1607782        32.425766\n"
     ]
    }
   ],
   "source": [
    "mv = missing_values_table(train)\n",
    "print(mv.head(20))       # top 20 most‐missing columns\n",
    "# Or to filter down to “lots” of missing, say >30%:\n",
    "print(mv[mv['missing_percent'] > 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ea75187-7171-44a8-b8d1-ef210c3b2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## some beginning on the feature engineering\n",
    "def missing_values_table(df):\n",
    "    \"\"\"Returns a DataFrame with missing counts and percent missing for each column.\"\"\"\n",
    "    n = len(df)\n",
    "    missing_count   = df.isna().sum()\n",
    "    missing_percent = 100 * missing_count / n\n",
    "    missing_df = (\n",
    "        pd.DataFrame({\n",
    "            'missing_count':   missing_count,\n",
    "            'missing_percent': missing_percent\n",
    "        })\n",
    "        .sort_values('missing_percent', ascending=False)\n",
    "    )\n",
    "    return missing_df\n",
    "    \n",
    "def preprocess_missing_and_competitors(train_df, test_df):\n",
    "    # 1) Drop features with >93% missing or that leak the target\n",
    "    drop_cols = [\n",
    "        # competitor 1,4,6,7 are ~97–98% missing → too sparse to learn\n",
    "        *[f'comp{i}_{t}' for i in [1,4,6,7] for t in ['rate','inv','rate_percent_diff']],\n",
    "        'gross_bookings_usd'  # only in train, leaks booking price\n",
    "    ]\n",
    "    train_df.drop(columns=drop_cols, errors='ignore', inplace=True)\n",
    "    test_df.drop(columns=drop_cols, errors='ignore', inplace=True)\n",
    "\n",
    "    # 2) Impute & flag user history features\n",
    "    #    Missing means “no prior purchases” → keep with sentinel + flag\n",
    "    for df in (train_df, test_df):\n",
    "        # visitor_hist_starrating\n",
    "        df['hist_star_na'] = df['visitor_hist_starrating'].isna().astype(int)\n",
    "        # fill with median starrating across users\n",
    "        star_med = train_df['visitor_hist_starrating'].median()\n",
    "        df['visitor_hist_starrating'] = df['visitor_hist_starrating'].fillna(star_med)\n",
    "\n",
    "        # visitor_hist_adr_usd (avg USD spend)\n",
    "        df['hist_adr_na'] = df['visitor_hist_adr_usd'].isna().astype(int)\n",
    "        adr_med = train_df['visitor_hist_adr_usd'].median()\n",
    "        df['visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].fillna(adr_med)\n",
    "\n",
    "    # 3) Impute & flag affinity score\n",
    "    #    Null means “hotel never seen” → fill with global minimum and flag\n",
    "    affinity_min = train_df['srch_query_affinity_score'].min(skipna=True)\n",
    "    for df in (train_df, test_df):\n",
    "        df['affinity_na'] = df['srch_query_affinity_score'].isna().astype(int)\n",
    "        df['srch_query_affinity_score'] = (\n",
    "            df['srch_query_affinity_score']\n",
    "            .fillna(affinity_min)\n",
    "        )\n",
    "\n",
    "    # 4) Keep & impute competitor 2,3,5,8 features (~50–90% missing)\n",
    "    #    Null → “no data” sentinel (for categorical) or 0 (for percent diff), plus flag\n",
    "    keep_comps = [2,3,5,8]\n",
    "    for i in keep_comps:\n",
    "        # availability flag\n",
    "        inv_col = f'comp{i}_inv'\n",
    "        flag_col = f'comp{i}_inv_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[flag_col] = df[inv_col].isna().astype(int)\n",
    "            # fill null with 2 (new category: 0=no avail,1=avail,2=no data)\n",
    "            df[inv_col] = df[inv_col].fillna(2).astype(int)\n",
    "\n",
    "        # price‐compare flag\n",
    "        rate_col = f'comp{i}_rate'\n",
    "        rate_flag = f'comp{i}_rate_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[rate_flag] = df[rate_col].isna().astype(int)\n",
    "            # fill null as “no data” = 2\n",
    "            df[rate_col] = df[rate_col].fillna(2).astype(int)\n",
    "\n",
    "        # percent_diff\n",
    "        pdiff_col = f'comp{i}_rate_percent_diff'\n",
    "        pdiff_flag = f'comp{i}_pdiff_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[pdiff_flag] = df[pdiff_col].isna().astype(int)\n",
    "            # fill null as 0% diff (no info)\n",
    "            df[pdiff_col] = df[pdiff_col].fillna(0.0)\n",
    "\n",
    "    # 5) Bucket orig_destination_distance\n",
    "    #    Missing → sentinel bucket + flag\n",
    "    for df in (train_df, test_df):\n",
    "        df['dist_na'] = df['orig_destination_distance'].isna().astype(int)\n",
    "        df['orig_destination_distance'] = (\n",
    "            df['orig_destination_distance'].fillna(-1)\n",
    "        )\n",
    "        # define bins (in km)\n",
    "        bins = [-1, 0, 10, 50, 200, np.inf]\n",
    "        labels = ['missing','0-10km','10-50km','50-200km','200km+']\n",
    "        df['dist_bucket'] = pd.cut(\n",
    "            df['orig_destination_distance'],\n",
    "            bins=bins, labels=labels\n",
    "        )\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def create_base_features(df):\n",
    "    \"\"\"1) Parse datetime & basic price/historical features.\"\"\"\n",
    "    df = df.copy()\n",
    "    # --- Date/time splits ---\n",
    "    df['date_time']   = pd.to_datetime(df['date_time'])\n",
    "    df['search_year'] = df['date_time'].dt.year\n",
    "    df['search_month']= df['date_time'].dt.month\n",
    "    df['search_day']  = df['date_time'].dt.day\n",
    "    df['search_hour'] = df['date_time'].dt.hour\n",
    "\n",
    "    # --- Price per night & hist price devation ---\n",
    "    df['price_per_night'] = df['price_usd'] / df['srch_length_of_stay']\n",
    "    df['price_vs_historical'] = df['price_usd'] - df['prop_log_historical_price']\n",
    "    df['price_vs_historical'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_destination_stats(train_df, test_df):\n",
    "    \"\"\"6) Dest‑level total searches & booking rate.\"\"\"\n",
    "    dest = (\n",
    "        train_df\n",
    "        .groupby('srch_destination_id')\n",
    "        .agg(dest_searches=('srch_id','count'),\n",
    "             dest_bookings=('booking_bool','sum'))\n",
    "        .assign(dest_booking_rate=lambda x: x.dest_bookings / x.dest_searches)\n",
    "        .reset_index()\n",
    "    )\n",
    "    # Reassign merge result back to each DataFrame\n",
    "    train_df = train_df.merge(\n",
    "        dest[['srch_destination_id','dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "    test_df = test_df.merge(\n",
    "        dest[['srch_destination_id','dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "    return train_df, test_df\n",
    "\n",
    "def add_within_search_features(df):\n",
    "    \"\"\"7) Z‑scores & deltas in each search group.\"\"\"\n",
    "    grp = df.groupby('srch_id')\n",
    "    # price\n",
    "    df['price_mean_srch'] = grp['price_usd'].transform('mean')\n",
    "    df['price_std_srch']  = grp['price_usd'].transform('std').fillna(1)\n",
    "    df['price_zscore']    = (df['price_usd'] - df['price_mean_srch']) / df['price_std_srch']\n",
    "    # stars\n",
    "    df['star_mean_srch']  = grp['prop_starrating'].transform('mean')\n",
    "    df['star_delta_srch'] = df['prop_starrating'] - df['star_mean_srch']\n",
    "    # user delta\n",
    "    df['star_delta_user'] = df['prop_starrating'] - df['visitor_hist_starrating']\n",
    "    # distance\n",
    "    df['dist_mean_srch']  = grp['orig_destination_distance'].transform('mean')\n",
    "    df['dist_std_srch']   = grp['orig_destination_distance'].transform('std').fillna(1)\n",
    "    df['dist_zscore']     = (df['orig_destination_distance'] - df['dist_mean_srch']) / df['dist_std_srch']\n",
    "    return df\n",
    "\n",
    "def add_temporal_features(df):\n",
    "    \"\"\"8) Weekday/weekend & check‑in weekend flags.\"\"\"\n",
    "    # day‑of‑week for search\n",
    "    df['search_dow'] = df['date_time'].dt.weekday  # 0=Mon…6=Sun\n",
    "    df['is_search_weekend'] = df['search_dow'].isin([5,6]).astype(int)\n",
    "    # approximate check‑in day\n",
    "    checkin = df['date_time'] + pd.to_timedelta(df['srch_booking_window'], 'D')\n",
    "    df['checkin_dow'] = checkin.dt.weekday\n",
    "    df['is_checkin_weekend'] = df['checkin_dow'].isin([5,6]).astype(int)\n",
    "    return df\n",
    "\n",
    "def add_ranks(df):\n",
    "    \"\"\"9) Dense ranks of price, star & distance within each search.\"\"\"\n",
    "    df['price_rank'] = df.groupby('srch_id')['price_usd'].rank('dense', ascending=True)\n",
    "    df['star_rank']  = df.groupby('srch_id')['prop_starrating'].rank('dense', ascending=False)\n",
    "    df['dist_rank']  = df.groupby('srch_id')['orig_destination_distance'].rank('dense', ascending=True)\n",
    "    return df\n",
    "\n",
    "def one_hot_encode_columns(train_df, test_df, columns_to_encode):\n",
    "    \"\"\"\n",
    "    Converts specified string columns in train and test DataFrames to one-hot encoded features.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): The training DataFrame.\n",
    "        test_df (pd.DataFrame): The testing DataFrame.\n",
    "        columns_to_encode (list): A list of column names (strings) to be one-hot encoded.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the modified training and testing DataFrames with one-hot encoded columns.\n",
    "    \"\"\"\n",
    "    train_processed = train_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "\n",
    "    for col in columns_to_encode:\n",
    "        if col in train_processed.columns and col in test_processed.columns:\n",
    "            # Get unique values from both train and test to ensure consistent encoding\n",
    "            all_unique_values = pd.concat([train_processed[col], test_processed[col]]).unique()\n",
    "\n",
    "            for value in all_unique_values:\n",
    "                train_processed[f'{col}_{value}'] = (train_processed[col] == value).astype(int)\n",
    "                test_processed[f'{col}_{value}'] = (test_processed[col] == value).astype(int)\n",
    "\n",
    "            # Drop the original categorical column\n",
    "            train_processed.drop(columns=[col], inplace=True)\n",
    "            test_processed.drop(columns=[col], inplace=True)\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in both train and test DataFrames. Skipping one-hot encoding for this column.\")\n",
    "\n",
    "    return train_processed, test_processed\n",
    "\n",
    "def minmax(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
    "\n",
    "def ensemble_predictions(pred1, pred2, weights):\n",
    "    w1, w2 = weights\n",
    "    return w1 * minmax(pred1) + w2 * minmax(pred2)\n",
    "\n",
    "def preprocess_missing_and_competitors_fit(train_df):\n",
    "    stats = {}\n",
    "    # 1) Which cols to drop\n",
    "    stats['drop_cols'] = [\n",
    "        *[f'comp{i}_{t}' for i in [1,4,6,7] \n",
    "          for t in ['rate','inv','rate_percent_diff']],\n",
    "        'gross_bookings_usd'\n",
    "    ]\n",
    "    # 2) Medians & mins for imputation\n",
    "    stats['star_med']     = train_df['visitor_hist_starrating'].median()\n",
    "    stats['adr_med']      = train_df['visitor_hist_adr_usd'].median()\n",
    "    stats['affinity_min'] = train_df['srch_query_affinity_score'].min(skipna=True)\n",
    "    return stats\n",
    "\n",
    "def preprocess_missing_and_competitors_transform(df, stats):\n",
    "    df = df.copy()\n",
    "    df.drop(columns=stats['drop_cols'], errors='ignore', inplace=True)\n",
    "\n",
    "    # visitor history\n",
    "    df['hist_star_na'] = df['visitor_hist_starrating'].isna().astype(int)\n",
    "    df['visitor_hist_starrating'] = (\n",
    "        df['visitor_hist_starrating']\n",
    "          .fillna(stats['star_med'])\n",
    "    )\n",
    "    df['hist_adr_na'] = df['visitor_hist_adr_usd'].isna().astype(int)\n",
    "    df['visitor_hist_adr_usd'] = (\n",
    "        df['visitor_hist_adr_usd']\n",
    "          .fillna(stats['adr_med'])\n",
    "    )\n",
    "\n",
    "    # affinity\n",
    "    df['affinity_na'] = df['srch_query_affinity_score'].isna().astype(int)\n",
    "    df['srch_query_affinity_score'] = (\n",
    "        df['srch_query_affinity_score']\n",
    "          .fillna(stats['affinity_min'])\n",
    "    )\n",
    "\n",
    "    # keep comps 2,3,5,8\n",
    "    for i in [2,3,5,8]:\n",
    "        for col, fill in [\n",
    "            (f'comp{i}_inv',               2),\n",
    "            (f'comp{i}_rate',              2),\n",
    "            (f'comp{i}_rate_percent_diff', 0.0),\n",
    "        ]:\n",
    "            df[f'{col}_na'] = df[col].isna().astype(int)\n",
    "            df[col] = df[col].fillna(fill)\n",
    "\n",
    "    # distance bucket\n",
    "    df['dist_na'] = df['orig_destination_distance'].isna().astype(int)\n",
    "    df['orig_destination_distance'] = (\n",
    "        df['orig_destination_distance'].fillna(-1)\n",
    "    )\n",
    "    bins  = [-1,0,10,50,200,np.inf]\n",
    "    lbls  = ['missing','0-10km','10-50km','50-200km','200km+']\n",
    "    df['dist_bucket'] = pd.cut(\n",
    "        df['orig_destination_distance'], bins=bins, labels=lbls\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def add_destination_stats_fit(train_df):\n",
    "    dest = (\n",
    "        train_df\n",
    "        .groupby('srch_destination_id')\n",
    "        .agg(dest_searches=('srch_id','count'),\n",
    "             dest_bookings=('booking_bool','sum'))\n",
    "    )\n",
    "    dest['dest_booking_rate'] = dest['dest_bookings'] / dest['dest_searches']\n",
    "    return dest\n",
    "\n",
    "def add_destination_stats_transform(df, dest_stats):\n",
    "    df = df.copy()\n",
    "    return df.merge(\n",
    "        dest_stats[['dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "def run_pipeline_on(train_df, other_df, steps):\n",
    "    df1, df2 = train_df.copy(), other_df.copy()\n",
    "    for fn in steps:\n",
    "        df1, df2 = fn(df1, df2)\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1039db90-505b-4710-a4cc-2ac0b456f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your FE pipeline, exactly as before\n",
    "steps = [\n",
    "    preprocess_missing_and_competitors,\n",
    "    add_destination_stats,\n",
    "    lambda tr, te: one_hot_encode_columns(tr, te, ['dist_bucket']),\n",
    "    lambda tr, te: (create_base_features(tr),     create_base_features(te)),\n",
    "    lambda tr, te: (add_within_search_features(tr), add_within_search_features(te)),\n",
    "    lambda tr, te: (add_temporal_features(tr),    add_temporal_features(te)),\n",
    "    lambda tr, te: (add_ranks(tr),                add_ranks(te)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb187d0-fb92-49dc-8060-582ebf758368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "comp3_rate                       3424059        69.056462\n",
      "comp3_inv                        3307357        66.702814\n",
      "comp8_rate                       3041693        61.344900\n",
      "comp8_inv                        2970844        59.916016\n",
      "comp2_rate                       2933675        59.166392\n",
      "comp2_inv                        2828078        57.036710\n",
      "comp5_rate                       2735974        55.179155\n",
      "comp5_inv                        2598327        52.403089\n",
      "orig_destination_distance        1607782        32.425766\n"
     ]
    }
   ],
   "source": [
    "mv = missing_values_table(train)\n",
    "print(mv.head(20))       # top 20 most‐missing columns\n",
    "# Or to filter down to “lots” of missing, say >30%:\n",
    "print(mv[mv['missing_percent'] > 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48198da9-b7e9-4f8a-9a23-a189962f4003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_6572\\227212721.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_6572\\227212721.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_6572\\227212721.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_6572\\227212721.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_6572\\1934780430.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_6572\\1934780430.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X     .fillna(medians, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_6572\\1934780430.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_va_all.fillna(medians, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_6572\\1934780430.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test .fillna(medians, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#0) define target\n",
    "y = train['booking_bool'] * 5 + train['click_bool']\n",
    "\n",
    "# 1) Split out search-IDs into train vs. valid (never touching test until after FE)\n",
    "train_ids, valid_ids = train_test_split(\n",
    "    train['srch_id'].unique(),\n",
    "    test_size=0.2,\n",
    "    random_state=22\n",
    ")\n",
    "train_raw = train[ train['srch_id'].isin(train_ids) ].reset_index(drop=True)\n",
    "valid_raw = train[ train['srch_id'].isin(valid_ids) ].reset_index(drop=True)\n",
    "test_raw  = test.copy()\n",
    "\n",
    "\n",
    "# 3) “Fit” FE on train_raw + test_raw\n",
    "train_feat, test_feat = run_pipeline_on(train_raw, test_raw, steps)\n",
    "\n",
    "# 4) “Apply” identical FE to valid_raw by feeding in the already-fitted train_feat\n",
    "_, valid_feat = run_pipeline_on(train_feat, valid_raw, steps)\n",
    "\n",
    "# 5) Select feature columns\n",
    "drop_cols = ['date_time','gross_bookings_usd','position',\n",
    "             'click_bool','booking_bool','srch_id','prop_id']\n",
    "features = [c for c in train_feat.columns if c not in drop_cols]\n",
    "\n",
    "X        = train_feat[features]\n",
    "X_va_all = valid_feat[features]\n",
    "X_test   = test_feat[features]\n",
    "\n",
    "# 6) Replace infinities and NaNs using only TRAIN medians\n",
    "for df in (X, X_va_all, X_test):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "medians = X.median()\n",
    "X     .fillna(medians, inplace=True)\n",
    "X_va_all.fillna(medians, inplace=True)\n",
    "X_test .fillna(medians, inplace=True)\n",
    "\n",
    "# 7) Scale\n",
    "scaler = StandardScaler()\n",
    "X_tr   = scaler.fit_transform(X)                       # train only\n",
    "X_va   = scaler.transform(X_va_all)                    # valid\n",
    "X_full = scaler.transform(pd.concat([X, X_va_all]))    # full\n",
    "X_test = scaler.transform(X_test)                      # test\n",
    "\n",
    "# 8) Build y arrays\n",
    "y_tr   = (train_raw['booking_bool'] * 5 + train_raw['click_bool']).values\n",
    "y_va   = (valid_raw['booking_bool'] * 5 + valid_raw['click_bool']).values\n",
    "y_full = np.concatenate([y_tr, y_va])\n",
    "\n",
    "# 9) Session‐IDs and group‐sizes\n",
    "id_tr   = train_raw['srch_id'].values\n",
    "id_va   = valid_raw['srch_id'].values\n",
    "id_full = np.concatenate([id_tr, id_va])\n",
    "\n",
    "grp_tr   = train_raw['srch_id'].value_counts(sort=False).values\n",
    "grp_va   = valid_raw['srch_id'].value_counts(sort=False).values\n",
    "grp_full = np.concatenate([grp_tr, grp_va])\n",
    "\n",
    "# 10) Make LightGBM & CatBoost datasets\n",
    "lgb_train = lgb.Dataset(X_tr,   label=y_tr,   group=grp_tr)\n",
    "lgb_val   = lgb.Dataset(X_va,   label=y_va,   group=grp_va)\n",
    "lgb_full  = lgb.Dataset(X_full, label=y_full, group=grp_full)\n",
    "\n",
    "train_pool = Pool(X_tr,   label=y_tr,   group_id=id_tr)\n",
    "val_pool   = Pool(X_va,   label=y_va,   group_id=id_va)\n",
    "full_pool  = Pool(X_full, label=y_full, group_id=id_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ec2bd5f-1730-4666-85f7-3952157d51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Define your search space\n",
    "\n",
    "param_dist = {\n",
    "  'learning_rate':    [0.01,0.015,0.02,0.025],\n",
    "  'num_leaves':       [128,192,256,320],\n",
    "  'min_data_in_leaf': [5,10,15,20],\n",
    "  'feature_fraction': [0.5,0.6,0.7],\n",
    "  'bagging_fraction': [0.8,1.0],\n",
    "  'bagging_freq':     [0,5],\n",
    "  'lambda_l1':        [0,0.1,0.5],\n",
    "  'lambda_l2':        [0,0.1,0.5],\n",
    "  'min_gain_to_split':[0,0.1,0.2]\n",
    "}\n",
    "\n",
    "n_iter = 30\n",
    "best_score, score = 0,0\n",
    "best_params,params = None,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "673066f0-78f5-4834-ace3-a35f4110ea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.015, 'num_leaves': 320, 'min_data_in_leaf': 15, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.5, 'lambda_l2': 0.0, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.231763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[599]\tvalid's ndcg@5: 0.39209\n",
      "    → ndcg@5 = 0.3921, rounds = 599\n",
      "2\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.015, 'num_leaves': 128, 'min_data_in_leaf': 5, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.205946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[567]\tvalid's ndcg@5: 0.384646\n",
      "    → ndcg@5 = 0.3846, rounds = 567\n",
      "3\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 320, 'min_data_in_leaf': 10, 'feature_fraction': 0.7, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.577138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[530]\tvalid's ndcg@5: 0.388252\n",
      "    → ndcg@5 = 0.3883, rounds = 530\n",
      "4\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 192, 'min_data_in_leaf': 5, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.259019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[590]\tvalid's ndcg@5: 0.386641\n",
      "    → ndcg@5 = 0.3866, rounds = 590\n",
      "5\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.015, 'num_leaves': 192, 'min_data_in_leaf': 20, 'feature_fraction': 0.7, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.668966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\tvalid's ndcg@5: 0.386209\n",
      "    → ndcg@5 = 0.3862, rounds = 600\n",
      "6\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 256, 'min_data_in_leaf': 20, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.220892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\tvalid's ndcg@5: 0.389087\n",
      "    → ndcg@5 = 0.3891, rounds = 600\n",
      "7\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.015, 'num_leaves': 192, 'min_data_in_leaf': 15, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.291818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[565]\tvalid's ndcg@5: 0.385856\n",
      "    → ndcg@5 = 0.3859, rounds = 565\n",
      "8\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 128, 'min_data_in_leaf': 5, 'feature_fraction': 0.7, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.647960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[596]\tvalid's ndcg@5: 0.381437\n",
      "    → ndcg@5 = 0.3814, rounds = 596\n",
      "9\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 320, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.251967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[580]\tvalid's ndcg@5: 0.38739\n",
      "    → ndcg@5 = 0.3874, rounds = 580\n",
      "10\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 192, 'min_data_in_leaf': 15, 'feature_fraction': 0.7, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.719202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[596]\tvalid's ndcg@5: 0.383041\n",
      "    → ndcg@5 = 0.3830, rounds = 596\n",
      "11\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 192, 'min_data_in_leaf': 10, 'feature_fraction': 0.5, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.5, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.244605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[582]\tvalid's ndcg@5: 0.391892\n",
      "    → ndcg@5 = 0.3919, rounds = 582\n",
      "12\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 128, 'min_data_in_leaf': 20, 'feature_fraction': 0.5, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.5, 'lambda_l2': 0.5, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.254953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\tvalid's ndcg@5: 0.387054\n",
      "    → ndcg@5 = 0.3871, rounds = 600\n",
      "13\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 192, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.243333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[594]\tvalid's ndcg@5: 0.386674\n",
      "    → ndcg@5 = 0.3867, rounds = 594\n",
      "14\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 128, 'min_data_in_leaf': 5, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.270187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[589]\tvalid's ndcg@5: 0.381958\n",
      "    → ndcg@5 = 0.3820, rounds = 589\n",
      "15\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 128, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.5, 'lambda_l2': 0.1, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.255666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[595]\tvalid's ndcg@5: 0.390439\n",
      "    → ndcg@5 = 0.3904, rounds = 595\n",
      "16\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.015, 'num_leaves': 192, 'min_data_in_leaf': 20, 'feature_fraction': 0.7, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.5, 'lambda_l2': 0.0, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.680965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[598]\tvalid's ndcg@5: 0.385677\n",
      "    → ndcg@5 = 0.3857, rounds = 598\n",
      "17\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 256, 'min_data_in_leaf': 5, 'feature_fraction': 0.5, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.5, 'lambda_l2': 0.0, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.262407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid's ndcg@5: 0.378435\n",
      "    → ndcg@5 = 0.3784, rounds = 82\n",
      "18\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 256, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.5, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.259411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\tvalid's ndcg@5: 0.384619\n",
      "    → ndcg@5 = 0.3846, rounds = 600\n",
      "19\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 256, 'min_data_in_leaf': 20, 'feature_fraction': 0.7, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.5, 'lambda_l2': 0.1, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.656183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[584]\tvalid's ndcg@5: 0.387327\n",
      "    → ndcg@5 = 0.3873, rounds = 584\n",
      "20\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 128, 'min_data_in_leaf': 15, 'feature_fraction': 0.7, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.759335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\tvalid's ndcg@5: 0.390193\n",
      "    → ndcg@5 = 0.3902, rounds = 600\n",
      "21\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 256, 'min_data_in_leaf': 10, 'feature_fraction': 0.5, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.5, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.246540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[587]\tvalid's ndcg@5: 0.388144\n",
      "    → ndcg@5 = 0.3881, rounds = 587\n",
      "22\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 320, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.5, 'lambda_l2': 0.1, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.251461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[447]\tvalid's ndcg@5: 0.387655\n",
      "    → ndcg@5 = 0.3877, rounds = 447\n",
      "23\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.015, 'num_leaves': 320, 'min_data_in_leaf': 10, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.5, 'lambda_l2': 0.5, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.271483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[584]\tvalid's ndcg@5: 0.387239\n",
      "    → ndcg@5 = 0.3872, rounds = 584\n",
      "24\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.015, 'num_leaves': 320, 'min_data_in_leaf': 20, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.5, 'lambda_l2': 0.0, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.255908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\tvalid's ndcg@5: 0.387718\n",
      "    → ndcg@5 = 0.3877, rounds = 600\n",
      "25\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 320, 'min_data_in_leaf': 10, 'feature_fraction': 0.5, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.5, 'lambda_l2': 0.1, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.244323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[570]\tvalid's ndcg@5: 0.389059\n",
      "    → ndcg@5 = 0.3891, rounds = 570\n",
      "26\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 192, 'min_data_in_leaf': 15, 'feature_fraction': 0.5, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.5, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.231352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[597]\tvalid's ndcg@5: 0.388815\n",
      "    → ndcg@5 = 0.3888, rounds = 597\n",
      "27\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 192, 'min_data_in_leaf': 5, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.5, 'lambda_l2': 0.0, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.193072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[558]\tvalid's ndcg@5: 0.387729\n",
      "    → ndcg@5 = 0.3877, rounds = 558\n",
      "28\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 320, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.219195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[598]\tvalid's ndcg@5: 0.385425\n",
      "    → ndcg@5 = 0.3854, rounds = 598\n",
      "29\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 192, 'min_data_in_leaf': 20, 'feature_fraction': 0.5, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.5, 'lambda_l2': 0.5, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.261571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[560]\tvalid's ndcg@5: 0.38935\n",
      "    → ndcg@5 = 0.3894, rounds = 560\n",
      "30\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 192, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.256071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[511]\tvalid's ndcg@5: 0.390925\n",
      "    → ndcg@5 = 0.3909, rounds = 511\n"
     ]
    }
   ],
   "source": [
    "# 1) Your random search stays the same…\n",
    "for i in range(1, n_iter + 1):\n",
    "    print(i)\n",
    "    params = {\n",
    "        'objective':         'lambdarank',\n",
    "        'metric':            'ndcg',\n",
    "        'ndcg_eval_at':      [5],\n",
    "        'verbose':           1,\n",
    "        'feature_pre_filter': False,      # ← disable the one-shot pre-filter\n",
    "    }\n",
    "    # 2) then overlay your random hyper‐params\n",
    "    params.update({k: np.random.choice(v) for k, v in param_dist.items()})\n",
    "    print(params)\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set=lgb_train,\n",
    "        num_boost_round=600,\n",
    "        valid_sets=lgb_val,\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    "    )\n",
    "    \n",
    "    score = model.best_score['valid']['ndcg@5']\n",
    "    print(f\"    → ndcg@5 = {score:.4f}, rounds = {model.best_iteration}\")\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score_ = score\n",
    "        best_params = params.copy()\n",
    "        best_iter =  model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06f335fe-beb9-44c9-a698-c4a8dd99de6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 192, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'min_gain_to_split': 0.0} 511\n"
     ]
    }
   ],
   "source": [
    "print(best_score, best_params, best_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bf22fe9-054d-4f3b-a757-a40119664b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.423288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6892\n",
      "[LightGBM] [Info] Number of data points in the train set: 4958347, number of used features: 79\n"
     ]
    }
   ],
   "source": [
    "# 3) Retrain on all data\n",
    "model_lgb_full = lgb.train(\n",
    "    best_params,\n",
    "    lgb_full,\n",
    "    num_boost_round=best_iter # can still be ajdusted to best best_iter\n",
    ")\n",
    "\n",
    "# 4) Predict on test\n",
    "lgb_test_preds = model_lgb_full.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c4afe9f-c8cb-46c4-a86b-c567a7e81a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:04:59,547] A new study created in memory with name: catboost_yetirank\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_6572\\1916531565.py:22: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  pruning_callback = CatBoostPruningCallback(trial, 'NDCG:top=5;type=Base')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.2737375\tbest: 0.2737375 (0)\ttotal: 2.06s\tremaining: 20m 35s\n",
      "100:\ttest: 0.3656543\tbest: 0.3656543 (100)\ttotal: 3m 25s\tremaining: 16m 57s\n",
      "200:\ttest: 0.3729270\tbest: 0.3729607 (195)\ttotal: 6m 29s\tremaining: 12m 52s\n",
      "300:\ttest: 0.3767713\tbest: 0.3767713 (300)\ttotal: 8m 45s\tremaining: 8m 41s\n",
      "400:\ttest: 0.3786513\tbest: 0.3786666 (399)\ttotal: 11m 2s\tremaining: 5m 28s\n",
      "500:\ttest: 0.3802330\tbest: 0.3802714 (495)\ttotal: 13m 17s\tremaining: 2m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:20:35,388] Trial 0 finished with value: 0.38174025809791046 and parameters: {'learning_rate': 0.04342808426146904, 'depth': 7, 'l2_leaf_reg': 0.023500321607835283, 'random_strength': 2.1941741481158905, 'bagging_temperature': 0.6082278641126276, 'border_count': 101}. Best is trial 0 with value: 0.38174025809791046.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\ttest: 0.3817105\tbest: 0.3817403 (592)\ttotal: 15m 32s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3817402581\n",
      "bestIteration = 592\n",
      "\n",
      "Shrink model to first 593 iterations.\n",
      "0:\ttest: 0.2740788\tbest: 0.2740788 (0)\ttotal: 1.54s\tremaining: 15m 23s\n",
      "100:\ttest: 0.3618343\tbest: 0.3618343 (100)\ttotal: 2m 23s\tremaining: 11m 47s\n",
      "200:\ttest: 0.3694227\tbest: 0.3694398 (196)\ttotal: 4m 40s\tremaining: 9m 17s\n",
      "300:\ttest: 0.3736560\tbest: 0.3736560 (300)\ttotal: 7m\tremaining: 6m 57s\n",
      "400:\ttest: 0.3763994\tbest: 0.3763994 (400)\ttotal: 9m 15s\tremaining: 4m 35s\n",
      "500:\ttest: 0.3778578\tbest: 0.3780190 (498)\ttotal: 11m 32s\tremaining: 2m 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:34:23,522] Trial 1 finished with value: 0.37964035216889236 and parameters: {'learning_rate': 0.030692101658412366, 'depth': 7, 'l2_leaf_reg': 0.00653660019939535, 'random_strength': 0.026125063661446377, 'bagging_temperature': 0.9244255378586388, 'border_count': 222}. Best is trial 0 with value: 0.38174025809791046.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\ttest: 0.3795945\tbest: 0.3796404 (598)\ttotal: 13m 45s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3796403522\n",
      "bestIteration = 598\n",
      "\n",
      "Shrink model to first 599 iterations.\n",
      "0:\ttest: 0.2747222\tbest: 0.2747222 (0)\ttotal: 1.54s\tremaining: 15m 24s\n",
      "100:\ttest: 0.3737047\tbest: 0.3737152 (98)\ttotal: 2m 19s\tremaining: 11m 29s\n",
      "200:\ttest: 0.3793607\tbest: 0.3793866 (199)\ttotal: 4m 34s\tremaining: 9m 4s\n",
      "300:\ttest: 0.3823667\tbest: 0.3823706 (298)\ttotal: 6m 49s\tremaining: 6m 47s\n",
      "400:\ttest: 0.3838445\tbest: 0.3839935 (398)\ttotal: 9m 4s\tremaining: 4m 30s\n",
      "500:\ttest: 0.3854844\tbest: 0.3855013 (499)\ttotal: 11m 20s\tremaining: 2m 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 23:48:00,736] Trial 2 finished with value: 0.38681528153016664 and parameters: {'learning_rate': 0.09096069812026357, 'depth': 7, 'l2_leaf_reg': 0.239273708391843, 'random_strength': 0.030071210551587915, 'bagging_temperature': 0.1303063989889015, 'border_count': 143}. Best is trial 2 with value: 0.38681528153016664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\ttest: 0.3867490\tbest: 0.3868153 (597)\ttotal: 13m 34s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3868152815\n",
      "bestIteration = 597\n",
      "\n",
      "Shrink model to first 598 iterations.\n",
      "0:\ttest: 0.2914714\tbest: 0.2914714 (0)\ttotal: 2.34s\tremaining: 23m 20s\n",
      "100:\ttest: 0.3620071\tbest: 0.3620071 (100)\ttotal: 3m 49s\tremaining: 18m 52s\n",
      "200:\ttest: 0.3703740\tbest: 0.3704036 (197)\ttotal: 7m 34s\tremaining: 15m 1s\n",
      "300:\ttest: 0.3748912\tbest: 0.3749841 (296)\ttotal: 11m 18s\tremaining: 11m 14s\n",
      "400:\ttest: 0.3779115\tbest: 0.3779458 (399)\ttotal: 15m 2s\tremaining: 7m 28s\n",
      "500:\ttest: 0.3799437\tbest: 0.3799437 (500)\ttotal: 18m 45s\tremaining: 3m 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 00:10:26,023] Trial 3 finished with value: 0.3818600970002314 and parameters: {'learning_rate': 0.019485440735920553, 'depth': 11, 'l2_leaf_reg': 0.003811413309618069, 'random_strength': 0.5407086343164754, 'bagging_temperature': 0.23355707047363228, 'border_count': 139}. Best is trial 2 with value: 0.38681528153016664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\ttest: 0.3817758\tbest: 0.3818601 (596)\ttotal: 22m 25s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.381860097\n",
      "bestIteration = 596\n",
      "\n",
      "Shrink model to first 597 iterations.\n",
      "0:\ttest: 0.2844376\tbest: 0.2844376 (0)\ttotal: 1.57s\tremaining: 15m 42s\n",
      "100:\ttest: 0.3757361\tbest: 0.3757361 (100)\ttotal: 2m 28s\tremaining: 12m 14s\n",
      "200:\ttest: 0.3819461\tbest: 0.3819461 (200)\ttotal: 4m 52s\tremaining: 9m 40s\n",
      "300:\ttest: 0.3841200\tbest: 0.3841243 (289)\ttotal: 7m 17s\tremaining: 7m 14s\n",
      "400:\ttest: 0.3858606\tbest: 0.3859261 (385)\ttotal: 9m 41s\tremaining: 4m 48s\n",
      "500:\ttest: 0.3874434\tbest: 0.3874712 (494)\ttotal: 12m 4s\tremaining: 2m 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 00:24:54,619] Trial 4 finished with value: 0.38848251696097624 and parameters: {'learning_rate': 0.09515705698611983, 'depth': 9, 'l2_leaf_reg': 0.6947324643801653, 'random_strength': 2.608675094800671, 'bagging_temperature': 0.6429616492483743, 'border_count': 250}. Best is trial 4 with value: 0.38848251696097624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\ttest: 0.3884484\tbest: 0.3884825 (597)\ttotal: 14m 26s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.388482517\n",
      "bestIteration = 597\n",
      "\n",
      "Shrink model to first 598 iterations.\n",
      "0:\ttest: 0.2767344\tbest: 0.2767344 (0)\ttotal: 1.51s\tremaining: 15m 2s\n",
      "100:\ttest: 0.3711903\tbest: 0.3711903 (100)\ttotal: 2m 24s\tremaining: 11m 53s\n",
      "200:\ttest: 0.3771649\tbest: 0.3771649 (200)\ttotal: 4m 42s\tremaining: 9m 20s\n",
      "300:\ttest: 0.3808901\tbest: 0.3808901 (300)\ttotal: 7m 1s\tremaining: 6m 58s\n",
      "400:\ttest: 0.3829715\tbest: 0.3831101 (398)\ttotal: 9m 20s\tremaining: 4m 37s\n",
      "500:\ttest: 0.3847934\tbest: 0.3848031 (499)\ttotal: 11m 38s\tremaining: 2m 18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 00:38:52,784] Trial 5 finished with value: 0.385647291717598 and parameters: {'learning_rate': 0.06515775288579236, 'depth': 8, 'l2_leaf_reg': 3.410768059516165, 'random_strength': 0.0019779759434243684, 'bagging_temperature': 0.7477370888765622, 'border_count': 217}. Best is trial 4 with value: 0.38848251696097624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\ttest: 0.3856473\tbest: 0.3856473 (599)\ttotal: 13m 55s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3856472917\n",
      "bestIteration = 599\n",
      "\n",
      "0:\ttest: 0.3019112\tbest: 0.3019112 (0)\ttotal: 2.41s\tremaining: 24m 6s\n",
      "100:\ttest: 0.3697290\tbest: 0.3697909 (99)\ttotal: 4m 6s\tremaining: 20m 16s\n",
      "200:\ttest: 0.3777585\tbest: 0.3777585 (200)\ttotal: 8m 6s\tremaining: 16m 5s\n",
      "300:\ttest: 0.3821362\tbest: 0.3821362 (300)\ttotal: 12m 6s\tremaining: 12m 1s\n",
      "400:\ttest: 0.3840216\tbest: 0.3840479 (395)\ttotal: 16m 6s\tremaining: 7m 59s\n",
      "500:\ttest: 0.3858060\tbest: 0.3859016 (499)\ttotal: 20m 6s\tremaining: 3m 58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 01:03:00,639] Trial 6 finished with value: 0.38722154166987166 and parameters: {'learning_rate': 0.032884661214305604, 'depth': 12, 'l2_leaf_reg': 0.1635574771936811, 'random_strength': 0.7389513936070797, 'bagging_temperature': 0.03499564451001247, 'border_count': 136}. Best is trial 4 with value: 0.38848251696097624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\ttest: 0.3872215\tbest: 0.3872215 (599)\ttotal: 24m 5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3872215417\n",
      "bestIteration = 599\n",
      "\n",
      "0:\ttest: 0.2636341\tbest: 0.2636341 (0)\ttotal: 1.6s\tremaining: 15m 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 01:03:11,241] Trial 7 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.289164347\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.2942665\tbest: 0.2942665 (0)\ttotal: 2.32s\tremaining: 23m 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 01:03:26,850] Trial 8 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3232359623\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.2869184\tbest: 0.2869184 (0)\ttotal: 2.44s\tremaining: 24m 23s\n",
      "100:\ttest: 0.3735251\tbest: 0.3735251 (100)\ttotal: 3m 59s\tremaining: 19m 43s\n",
      "200:\ttest: 0.3782880\tbest: 0.3782880 (200)\ttotal: 7m 52s\tremaining: 15m 38s\n",
      "300:\ttest: 0.3828303\tbest: 0.3829524 (299)\ttotal: 11m 47s\tremaining: 11m 42s\n",
      "400:\ttest: 0.3843198\tbest: 0.3844697 (391)\ttotal: 15m 45s\tremaining: 7m 49s\n",
      "500:\ttest: 0.3854783\tbest: 0.3857583 (498)\ttotal: 19m 42s\tremaining: 3m 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 01:26:50,640] Trial 9 finished with value: 0.3862178421739308 and parameters: {'learning_rate': 0.06357340379483874, 'depth': 12, 'l2_leaf_reg': 0.007661024957395861, 'random_strength': 7.686573664667392, 'bagging_temperature': 0.2043937457253162, 'border_count': 83}. Best is trial 4 with value: 0.38848251696097624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3862178422\n",
      "bestIteration = 542\n",
      "\n",
      "Shrink model to first 543 iterations.\n",
      "Best PFound: 0.38848251696097624\n",
      "Best hyperparameters:\n",
      "  learning_rate: 0.09515705698611983\n",
      "  depth: 9\n",
      "  l2_leaf_reg: 0.6947324643801653\n",
      "  random_strength: 2.608675094800671\n",
      "  bagging_temperature: 0.6429616492483743\n",
      "  border_count: 250\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params_cat = {\n",
    "        'loss_function': 'YetiRank',\n",
    "        'eval_metric': 'NDCG:top=5',\n",
    "        'random_seed': 5,\n",
    "        'od_type': 'Iter',\n",
    "        'od_wait': 20,\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int(\"depth\", 6, 12),\n",
    "        'l2_leaf_reg': trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10.0, log=True),\n",
    "        'random_strength': trial.suggest_float(\"random_strength\", 1e-3, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "        'border_count': trial.suggest_int(\"border_count\", 32, 255),\n",
    "        'iterations': 600,\n",
    "        'use_best_model': True,\n",
    "        'verbose': 100,\n",
    "    }\n",
    "\n",
    "    model_cat = CatBoostRanker(**params_cat)\n",
    "\n",
    "    # Pruner callback for PFound\n",
    "    pruning_callback = CatBoostPruningCallback(trial, 'NDCG:top=5;type=Base')\n",
    "\n",
    "\n",
    "    model_cat.fit(\n",
    "        train_pool,\n",
    "        eval_set=val_pool,\n",
    "        early_stopping_rounds=50,\n",
    "        callbacks=[pruning_callback],\n",
    "    )\n",
    "\n",
    "    # Manually trigger pruning\n",
    "    pruning_callback.check_pruned()\n",
    "\n",
    "     # 5) Grab the best‐iteration score\n",
    "    hist = model_cat.get_evals_result()['validation']['NDCG:top=5;type=Base']\n",
    "    return max(hist) \n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"catboost_yetirank\",\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    ")\n",
    "study.optimize(objective, n_trials=60, timeout=7200)\n",
    "\n",
    "print(f\"Best PFound: {study.best_trial.value}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for k, v in study.best_trial.params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fff8cf2-1c00-4142-963c-7814bd9db8be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'study' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1) Grab your best config & best score from Optuna\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_params_cat \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams\n\u001b[0;32m      3\u001b[0m best_ndcg5      \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest validation NDCG@5 (Optuna): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_ndcg5\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'study' is not defined"
     ]
    }
   ],
   "source": [
    "# 1) Grab your best config & best score from Optuna\n",
    "best_params_cat = study.best_trial.params\n",
    "best_ndcg5      = study.best_trial.value\n",
    "\n",
    "print(f\"Best validation NDCG@5 (Optuna): {best_ndcg5:.4f}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in best_params_cat.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# 2) Re-instantiate your CatBoostRanker with a very large `iterations` …\n",
    "final_params_cat = {\n",
    "    **best_params_cat,\n",
    "    'loss_function':   'YetiRank',\n",
    "    'eval_metric':     'NDCG:top=5',\n",
    "    'random_seed':     22,\n",
    "    'use_best_model':  True,\n",
    "    'verbose':         100,\n",
    "    'iterations':      2000,            # start with something big …\n",
    "}\n",
    "full_model = CatBoostRanker(**final_params_cat)\n",
    "\n",
    "# 3) Fit on the full training+validation Pool, using early stopping\n",
    "#    to discover the optimum number of trees\n",
    "full_model.fit(\n",
    "    full_pool,\n",
    "    early_stopping_rounds=100,\n",
    ")\n",
    "\n",
    "# 4) Pull out the “best iteration” we actually used\n",
    "best_iter_full = full_model.get_best_iteration()\n",
    "print(f\"➡️  Full‐data training stopped at iteration {best_iter_full}\")\n",
    "\n",
    "# 5) Now **freeze** your model to exactly that number of trees:\n",
    "#    re-build with iterations=best_iter_full (no early stopping)\n",
    "final_params_cat['iterations'] = best_iter_full\n",
    "final_model = CatBoostRanker(**final_params_cat)\n",
    "final_model.fit(full_pool, verbose=False)\n",
    "\n",
    "# 6) Predict on your test set\n",
    "cat_test_preds = final_model.predict(\n",
    "    X_test, \n",
    "    prediction_type='RawFormulaVal'  # this is the default return for a ranker\n",
    ")\n",
    "\n",
    "# 7) (Optional) If you want to blend with LightGBM…\n",
    "# ensemble_preds = 0.4*minmax(cat_test_preds) + 0.6*minmax(lgb_test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48302777-0194-4965-a7c3-e1d508ec1a96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_cat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 4) Predict on test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cat_test_preds \u001b[38;5;241m=\u001b[39m final_cat\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_cat' is not defined"
     ]
    }
   ],
   "source": [
    "# 4) Predict on test set\n",
    "cat_test_preds = final_cat.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79ada07e-f959-4685-9006-2d37dbcd7a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv written using lgb only!\n"
     ]
    }
   ],
   "source": [
    "# 2) Put them into your submission\n",
    "\n",
    "#can use cat_test_pred or lgb_test_preds\n",
    "\n",
    "sample['score'] = lgb_test_preds\n",
    "submission = (\n",
    "    sample\n",
    "    .sort_values(['srch_id', 'score'], ascending=[True, False])\n",
    "    [['srch_id', 'prop_id']]\n",
    ")\n",
    "\n",
    "# 3) Write to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission.csv written using lgb only!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb20bf6-7ab7-4a2c-9572-727a7e61005d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_cat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Predict raw scores for the validation set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cat_val_preds \u001b[38;5;241m=\u001b[39m final_cat\u001b[38;5;241m.\u001b[39mpredict(X_va)\n\u001b[0;32m      3\u001b[0m lgb_val_preds \u001b[38;5;241m=\u001b[39m model_lgb_full\u001b[38;5;241m.\u001b[39mpredict(X_va)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 2. Compute per-session NDCG@5 manually\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_cat' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Predict raw scores for the validation set\n",
    "cat_val_preds = final_cat.predict(X_va)\n",
    "lgb_val_preds = model_lgb_full.predict(X_va)\n",
    "\n",
    "# 2. Compute per-session NDCG@5 manually\n",
    "ndcgs_cat = []\n",
    "ndcgs_lgb = []\n",
    "\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:  # skip sessions with only 1 result\n",
    "        true_rels = y_va[idx]\n",
    "        ndcgs_cat.append(ndcg_score([true_rels], [cat_val_preds[idx]], k=5))\n",
    "        ndcgs_lgb.append(ndcg_score([true_rels], [lgb_val_preds[idx]], k=5))\n",
    "\n",
    "# 3. Average NDCG@5 for both models\n",
    "catboost_ndcg5 = np.mean(ndcgs_cat)\n",
    "lgb_ndcg5 = np.mean(ndcgs_lgb)\n",
    "\n",
    "print(f\"\\nCatBoost Val NDCG@5: {catboost_ndcg5:.4f}\")\n",
    "print(f\"\\nLightGBM Val NDCG@5: {lgb_ndcg5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991fd44-41cb-4f3c-8643-bb5f041603a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1) Scale just your two tree-based model preds on validation\n",
    "cb_s  = minmax(cat_val_preds)   # your CatBoost val preds\n",
    "lgb_s = minmax(lgb_val_preds)   # your LightGBM val preds\n",
    "\n",
    "# 2) Sweep over blends of just CB + LGB\n",
    "best, best_w = 0, None\n",
    "for w_cb in np.linspace(0, 1, 11):\n",
    "    w_lgb = 1 - w_cb\n",
    "    sc = w_cb * cb_s + w_lgb * lgb_s\n",
    "\n",
    "    # compute NDCG@5 on val\n",
    "    ndcgs = []\n",
    "    for q in np.unique(id_va):\n",
    "        idx = np.where(id_va == q)[0]\n",
    "        if len(idx) > 1:\n",
    "            true = y_va[idx]\n",
    "            ndcgs.append(ndcg_score([true], [sc[idx]], k=5))\n",
    "    mean_ndcg = np.mean(ndcgs)\n",
    "\n",
    "    print(f\"w_cb={w_cb:.1f}, w_lgb={w_lgb:.1f} → Val NDCG@5: {mean_ndcg:.4f}\")\n",
    "    if mean_ndcg > best:\n",
    "        best, best_w = mean_ndcg, (w_cb, w_lgb)\n",
    "\n",
    "print(f\"\\n Best blend (CB+LGB): w_cb={best_w[0]:.2f}, w_lgb={best_w[1]:.2f} → NDCG@5={best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e54659-6f48-4d9e-94ac-fecb7f8d15cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ensemble the test predictions with your optimal blend ---\n",
    "best_w = [0.5,0.5]\n",
    "\n",
    "ensemble_final_preds = ensemble_predictions(\n",
    "    cat_test_preds,\n",
    "    lgb_test_preds,\n",
    "    weights=[best_w[0], best_w[1]]\n",
    ")\n",
    "\n",
    "# Put them into submission\n",
    "sample['score'] = ensemble_final_preds\n",
    "submission = (\n",
    "    sample\n",
    "    .sort_values(['srch_id','score'], ascending=[True, False])\n",
    "    [['srch_id','prop_id']]\n",
    ")\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission.csv written using w_cb={best_w[0]:.2f}, w_lgb={best_w[1]:.2f}!\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ccd16-188e-40cc-8d80-e176c305925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# --- 1) ListNet loss (unchanged) ---\n",
    "def listnet_loss(scores, labels, group_ids):\n",
    "    loss, count = 0.0, 0\n",
    "    for q in np.unique(group_ids):\n",
    "        idx = np.where(group_ids == q)[0]\n",
    "        if len(idx) < 2:\n",
    "            continue\n",
    "        s_q, y_q = scores[idx], labels[idx].float()\n",
    "        P, P_hat = torch.softmax(y_q, 0), torch.softmax(s_q, 0)\n",
    "        loss += -torch.sum(P * torch.log(P_hat + 1e-8))\n",
    "        count += 1\n",
    "    return loss / max(count, 1)\n",
    "\n",
    "param_grid = {\n",
    "    'lr':           [1e-3, 2e-3],\n",
    "    'batch_size':   [512, 1024],\n",
    "    'dropout':      [0.1, 0.2],\n",
    "    'weight_decay': [0.0, 1e-4]\n",
    "}\n",
    "\n",
    "best = {'ndcg': 0.0, 'cfg': None}\n",
    "\n",
    "for lr, bs, drop, wd in itertools.product(*param_grid.values()):\n",
    "    tr_loader = DataLoader(ExpediaDataset(X_tr, y_tr.values),\n",
    "                           batch_size=bs, shuffle=True)\n",
    "    va_loader = DataLoader(ExpediaDataset(X_va, y_va.values),\n",
    "                           batch_size=bs, shuffle=False)\n",
    "\n",
    "    mdl = DeepRecommender(X_tr.shape[1]).to(device)\n",
    "    for m in mdl.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.p = drop\n",
    "\n",
    "    opt = torch.optim.Adam(\n",
    "        mdl.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=wd\n",
    "    )\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt,\n",
    "        max_lr=lr * 10,\n",
    "        steps_per_epoch=len(tr_loader),\n",
    "        epochs=10\n",
    "    )\n",
    "\n",
    "    best_ndcg, stale = 0.0, 0\n",
    "    for epoch in range(1, 8):\n",
    "        # — train —\n",
    "        mdl.train()\n",
    "        for Xb, yb in tr_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = listnet_loss(mdl(Xb), yb, id_tr[:len(Xb)])\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        # — validate —\n",
    "        mdl.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for Xb, _ in va_loader:\n",
    "                preds.extend(mdl(Xb.to(device)).cpu().numpy())\n",
    "        preds = np.array(preds)\n",
    "\n",
    "        # compute mean NDCG@5 using the same y_va array\n",
    "        ndcgs = []\n",
    "        for q in np.unique(id_va):\n",
    "            idx = np.where(id_va == q)[0]\n",
    "            if len(idx) > 1:\n",
    "                true = y_va.values[idx]\n",
    "                score = preds[idx]\n",
    "                ndcgs.append(ndcg_score([true], [score], k=5))\n",
    "        mean_ndcg = np.mean(ndcgs)\n",
    "        sched.step(mean_ndcg)\n",
    "\n",
    "        if mean_ndcg > best_ndcg + 1e-4:\n",
    "            best_ndcg, stale = mean_ndcg, 0\n",
    "        else:\n",
    "            stale += 1\n",
    "        if stale >= 5:\n",
    "            break\n",
    "\n",
    "    print(f\"cfg lr={lr}, bs={bs}, drop={drop} → Val NDCG@5: {best_ndcg:.4f}\")\n",
    "    if best_ndcg > best['ndcg']:\n",
    "        best.update({'ndcg': best_ndcg, 'cfg': (lr, bs, drop)})\n",
    "\n",
    "print(\"🏆 Best config:\", best)\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4855e15-4c6b-492f-a267-979ef406a160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef09feb-986f-496e-a691-8fedcee3d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# unpack your best cfg and tweak\n",
    "lr, bs, drop, wd = 1e-3, 128, 0.1, 1e-5\n",
    "\n",
    "# rebuild full-training loader\n",
    "full_loader = DataLoader(\n",
    "    ExpediaDatasetGrouped(X_full, y_full, id_full),\n",
    "    batch_size=bs, shuffle=True\n",
    ")\n",
    "\n",
    "# 1) Slightly larger network at the top\n",
    "class BiggerRecommender(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512), nn.ReLU(), nn.BatchNorm1d(512), nn.Dropout(drop),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.BatchNorm1d(256), nn.Dropout(drop),\n",
    "            nn.Linear(256, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(drop),\n",
    "            nn.Linear(128, 64),  nn.ReLU(), nn.Dropout(drop),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "final_nn = BiggerRecommender(X_full.shape[1]).to(device)\n",
    "\n",
    "# 2) Optimizer with very light weight decay\n",
    "opt = torch.optim.Adam(final_nn.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "# 3) Simpler stepLR scheduler (cuts LR by 0.5 every 10 epochs)\n",
    "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.5)\n",
    "\n",
    "# 4) Train for 30 epochs with gradient clipping\n",
    "for epoch in range(1, 31):\n",
    "    final_nn.train()\n",
    "    total_loss = 0.0\n",
    "    for Xb, yb, gb in full_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = final_nn(Xb)\n",
    "        loss   = listnet_loss(logits, yb, gb)  \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(final_nn.parameters(), 5.0)\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item() * Xb.size(0)\n",
    "\n",
    "    sched.step()\n",
    "    avg_loss = total_loss / len(full_loader.dataset)\n",
    "    print(f\"Epoch {epoch:02d}/30 — Avg ListNet Loss: {avg_loss:.4f} — LR: {opt.param_groups[0]['lr']:.1e}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f70ffb-f18d-43e7-a272-cbc58ee1c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# --- 4) Produce final test preds ---\n",
    "test_loader = DataLoader(\n",
    "    ExpediaDataset(X_test, np.zeros(len(X_test))),\n",
    "    batch_size=bs,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "nn_test_preds = []\n",
    "final_nn.eval()\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in test_loader:           # <-- unpack both X and dummy y\n",
    "        Xb = Xb.to(device)\n",
    "        nn_test_preds.extend(\n",
    "            torch.sigmoid(final_nn(Xb))\n",
    "                 .cpu()\n",
    "                 .numpy()\n",
    "        )\n",
    "nn_test_preds = np.array(nn_test_preds)\n",
    "\n",
    "print(\"NN preds:\", nn_test_preds.min(), nn_test_preds.max())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90180b4-66a8-435f-ad08-d1a9af7af2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 1) Get NN probabilities on the validation fold\n",
    "nn_val_probs = []\n",
    "final_nn.eval()\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in va_loader:\n",
    "        nn_val_probs.extend(\n",
    "            torch.sigmoid(final_nn(Xb.to(device)))\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "nn_val_probs = np.array(nn_val_probs)  # shape = (n_val,)\n",
    "\n",
    "# 2) Compute per-session NDCG@5\n",
    "ndcgs = []\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:\n",
    "        true_rels = y_val_nn[idx]\n",
    "        scores    = nn_val_probs[idx]\n",
    "        ndcgs.append(ndcg_score([true_rels], [scores], k=5))\n",
    "\n",
    "nn_val_ndcg5 = np.mean(ndcgs)\n",
    "print(f\"NN  Val NDCG@5: {nn_val_ndcg5:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af293dc-e382-4a3a-bee5-e767a32048c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# --- Ensemble the predictions ---\n",
    "ensemble_final_preds = ensemble_predictions(nn_test_preds, model_lgb_pred, weights=[0.5, 0.5]) # Adjust weights\n",
    "\n",
    "# Predict relevance scores for each test row\n",
    "preds_ens = ensemble_final_preds\n",
    "\n",
    "# Insert those scores into the sample submission DataFrame\n",
    "sample['score'] = preds_ens\n",
    "\n",
    "# Sort by search session (ascending) and score (descending)\n",
    "#   so that for each srch_id, the most relevant prop_id comes first\n",
    "submission = sample.sort_values(\n",
    "    ['srch_id', 'score'],\n",
    "    ascending=[True, False]\n",
    ")\n",
    "\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3c1e5-a601-4f56-b331-cfbce1e4753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 1) LightGBM val set predictions\n",
    "# Replace `model_lgb` with whatever variable you named your trained LightGBM model\n",
    "val_preds_lgb = model_lgb.predict(X_va)   # shape = (n_val,)\n",
    "\n",
    "# 2) NN val set predictions\n",
    "final_nn.eval()\n",
    "nn_val_preds = []\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in va_loader:  # va_loader from your NN split on X_va/y_va\n",
    "        nn_val_preds.extend(\n",
    "            torch.sigmoid(final_nn(Xb.to(device))).cpu().numpy()\n",
    "        )\n",
    "nn_val_preds = np.array(nn_val_preds)      # shape = (n_val,)\n",
    "\n",
    "# 3) Blend them\n",
    "w_nn, w_lgb = 0.4, 0.6\n",
    "ensemble_val = w_nn * nn_val_preds + w_lgb * val_preds_lgb\n",
    "\n",
    "\n",
    "ndcgs = []\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:\n",
    "        true_rel  = y_val_nn[idx]    # your val labels array\n",
    "        score_rel = ensemble_val[idx]\n",
    "        ndcgs.append(ndcg_score([true_rel], [score_rel], k=5))\n",
    "\n",
    "mean_ndcg5 = np.mean(ndcgs)\n",
    "print(f\"Ensembled Val NDCG@5: {mean_ndcg5:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35a973-a5cc-4f52-afb4-b8ae2f7b9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 1) Min–max scale each prediction array into [0,1]\n",
    "def minmax(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
    "\n",
    "nn_scaled  = minmax(nn_test_preds)\n",
    "lgb_scaled = minmax(model_lgb_pred)   # or whatever your LGB test‐preds variable is\n",
    "\n",
    "# 2) Do the two blends\n",
    "ens1 = ensemble_predictions(nn_scaled, lgb_scaled, [0.5, 0.5])\n",
    "ens2 = ensemble_predictions(nn_scaled, lgb_scaled, [0.0, 1.0])\n",
    "\n",
    "# 3) Compare their sorted‐order permutations\n",
    "order1 = np.argsort(ens1)\n",
    "order2 = np.argsort(ens2)\n",
    "\n",
    "# 4) Compute fraction of positions that differ\n",
    "fraction_changed = np.mean(order1 != order2)\n",
    "print(f\"Fraction of test‐rows whose position changes: {fraction_changed:.4%}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5d100-acc8-4754-9d9b-853cd760f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 0) Scale both NN & LGB validation predictions into [0,1]\n",
    "nn_scaled_val  = minmax_scale(nn_val_preds)      # shape = (n_val,)\n",
    "lgb_scaled_val = minmax_scale(val_preds_lgb)     # shape = (n_val,)\n",
    "\n",
    "best_w, best_score = None, 0.0\n",
    "for w_nn in np.linspace(0, 1, 11):\n",
    "    w_lgb = 1 - w_nn\n",
    "\n",
    "    # blended on the same [0,1] scale\n",
    "    blended = w_nn * nn_scaled_val + w_lgb * lgb_scaled_val\n",
    "\n",
    "    # compute NDCG@5 per session\n",
    "    ndcgs = []\n",
    "    for q in np.unique(id_va):\n",
    "        idx = np.where(id_va == q)[0]\n",
    "        if len(idx) > 1:\n",
    "            true   = y_val_nn[idx]\n",
    "            scores = blended[idx]\n",
    "            ndcgs.append(ndcg_score([true], [scores], k=5))\n",
    "    mean_ndcg = np.mean(ndcgs)\n",
    "\n",
    "    print(f\"w_nn={w_nn:.1f}, w_lgb={w_lgb:.1f} → Val NDCG@5: {mean_ndcg:.4f}\")\n",
    "    if mean_ndcg > best_score:\n",
    "        best_score, best_w = mean_ndcg, w_nn\n",
    "\n",
    "print(f\"\\n🏆 Best blend: w_nn={best_w:.2f}, w_lgb={1-best_w:.2f} → NDCG@5={best_score:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6eb97c-337e-4156-9a0c-0badb3dbabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df = sample[['srch_id']].copy()\n",
    "df['nn_rank']  = pd.DataFrame({'score': nn_test_preds,  'srch': sample['srch_id']}) \\\n",
    "                    .groupby('srch')['score'] \\\n",
    "                    .rank(method='dense', ascending=False)\n",
    "df['lgb_rank'] = pd.DataFrame({'score': model_lgb_pred,'srch': sample['srch_id']}) \\\n",
    "                    .groupby('srch')['score'] \\\n",
    "                    .rank(method='dense', ascending=False)\n",
    "\n",
    "# weighted rank\n",
    "w_nn, w_lgb = best_w, (1-best_w)\n",
    "df['ensemble_rank'] = w_nn * df['nn_rank'] + w_lgb * df['lgb_rank']\n",
    "\n",
    "# use that to sort\n",
    "submission = sample.assign(_rank=df['ensemble_rank']) \\\n",
    "    .sort_values(['srch_id','_rank'], ascending=[True,True]) \\\n",
    "    [['srch_id','prop_id']]\n",
    "\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7bccc1-01c7-405a-8e9f-913dc53fd5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df_sub = sample[['srch_id']].copy()\n",
    "df_sub['nn_rank']  = pd.Series(nn_test_preds).groupby(sample['srch_id']).rank(\"dense\", ascending=False)\n",
    "df_sub['lgb_rank'] = pd.Series(model_lgb_pred).groupby(sample['srch_id']).rank(\"dense\", ascending=False)\n",
    "\n",
    "# weighted rank blend\n",
    "df_sub['ensemble_rank'] = 0.2*df_sub['nn_rank'] + 0.8*df_sub['lgb_rank']\n",
    "\n",
    "submission = (\n",
    "    sample.assign(_rank=df_sub['ensemble_rank'])\n",
    "          .sort_values(['srch_id','_rank'], ascending=[True,True])\n",
    "          [['srch_id','prop_id']]\n",
    ")\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
