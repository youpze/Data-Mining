{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca254db0-81c6-46c4-a66e-9b7f66172755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score, roc_auc_score\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder,  minmax_scale\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GroupShuffleSplit\n",
    "import itertools\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from catboost import CatBoostRanker, Pool,  cv\n",
    "import optuna\n",
    "from optuna.integration import CatBoostPruningCallback\n",
    "from catboost.utils import eval_metric\n",
    "from optuna.pruners import SuccessiveHalvingPruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f7bcaa-d6d3-49c1-b9b0-5edec2d3a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the files changes path to where the data is stored\n",
    "test = pd.read_csv(r\"C:\\Users\\youpz\\Documents\\Master\\P5\\Data mining techniques\\Assignment2\\data\\dmt-2025-2nd-assignment\\test_set_VU_DM.csv\")\n",
    "train = pd.read_csv(r\"C:\\Users\\youpz\\Documents\\Master\\P5\\Data mining techniques\\Assignment2\\data\\dmt-2025-2nd-assignment\\training_set_VU_DM.csv\")\n",
    "sample = pd.read_csv(r\"C:\\Users\\youpz\\Documents\\Master\\P5\\Data mining techniques\\Assignment2\\data\\dmt-2025-2nd-assignment\\submission_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a5d234-6885-41df-bdf7-94794f3df4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "    \"\"\"Returns a DataFrame with missing counts and percent missing for each column.\"\"\"\n",
    "    n = len(df)\n",
    "    missing_count   = df.isna().sum()\n",
    "    missing_percent = 100 * missing_count / n\n",
    "    missing_df = (\n",
    "        pd.DataFrame({\n",
    "            'missing_count':   missing_count,\n",
    "            'missing_percent': missing_percent\n",
    "        })\n",
    "        .sort_values('missing_percent', ascending=False)\n",
    "    )\n",
    "    return missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0e5c47-2faf-4d18-9955-94abd8b44a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "comp3_rate                       3424059        69.056462\n",
      "comp3_inv                        3307357        66.702814\n",
      "comp8_rate                       3041693        61.344900\n",
      "comp8_inv                        2970844        59.916016\n",
      "comp2_rate                       2933675        59.166392\n",
      "comp2_inv                        2828078        57.036710\n",
      "comp5_rate                       2735974        55.179155\n",
      "comp5_inv                        2598327        52.403089\n",
      "orig_destination_distance        1607782        32.425766\n"
     ]
    }
   ],
   "source": [
    "mv = missing_values_table(train)\n",
    "print(mv.head(20))       # top 20 most‐missing columns\n",
    "# Or to filter down to “lots” of missing, say >30%:\n",
    "print(mv[mv['missing_percent'] > 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ea75187-7171-44a8-b8d1-ef210c3b2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## some beginning on the feature engineering\n",
    "def missing_values_table(df):\n",
    "    \"\"\"Returns a DataFrame with missing counts and percent missing for each column.\"\"\"\n",
    "    n = len(df)\n",
    "    missing_count   = df.isna().sum()\n",
    "    missing_percent = 100 * missing_count / n\n",
    "    missing_df = (\n",
    "        pd.DataFrame({\n",
    "            'missing_count':   missing_count,\n",
    "            'missing_percent': missing_percent\n",
    "        })\n",
    "        .sort_values('missing_percent', ascending=False)\n",
    "    )\n",
    "    return missing_df\n",
    "    \n",
    "def preprocess_missing_and_competitors(train_df, test_df):\n",
    "    # 1) Drop features with >93% missing or that leak the target\n",
    "    drop_cols = [\n",
    "        # competitor 1,4,6,7 are ~97–98% missing → too sparse to learn\n",
    "        *[f'comp{i}_{t}' for i in [1,4,6,7] for t in ['rate','inv','rate_percent_diff']],\n",
    "        'gross_bookings_usd'  # only in train, leaks booking price\n",
    "    ]\n",
    "    train_df.drop(columns=drop_cols, errors='ignore', inplace=True)\n",
    "    test_df.drop(columns=drop_cols, errors='ignore', inplace=True)\n",
    "\n",
    "    # 2) Impute & flag user history features\n",
    "    #    Missing means “no prior purchases” → keep with sentinel + flag\n",
    "    for df in (train_df, test_df):\n",
    "        # visitor_hist_starrating\n",
    "        df['hist_star_na'] = df['visitor_hist_starrating'].isna().astype(int)\n",
    "        # fill with median starrating across users\n",
    "        star_med = train_df['visitor_hist_starrating'].median()\n",
    "        df['visitor_hist_starrating'] = df['visitor_hist_starrating'].fillna(star_med)\n",
    "\n",
    "        # visitor_hist_adr_usd (avg USD spend)\n",
    "        df['hist_adr_na'] = df['visitor_hist_adr_usd'].isna().astype(int)\n",
    "        adr_med = train_df['visitor_hist_adr_usd'].median()\n",
    "        df['visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].fillna(adr_med)\n",
    "\n",
    "    # 3) Impute & flag affinity score\n",
    "    #    Null means “hotel never seen” → fill with global minimum and flag\n",
    "    affinity_min = train_df['srch_query_affinity_score'].min(skipna=True)\n",
    "    for df in (train_df, test_df):\n",
    "        df['affinity_na'] = df['srch_query_affinity_score'].isna().astype(int)\n",
    "        df['srch_query_affinity_score'] = (\n",
    "            df['srch_query_affinity_score']\n",
    "            .fillna(affinity_min)\n",
    "        )\n",
    "\n",
    "    # 4) Keep & impute competitor 2,3,5,8 features (~50–90% missing)\n",
    "    #    Null → “no data” sentinel (for categorical) or 0 (for percent diff), plus flag\n",
    "    keep_comps = [2,3,5,8]\n",
    "    for i in keep_comps:\n",
    "        # availability flag\n",
    "        inv_col = f'comp{i}_inv'\n",
    "        flag_col = f'comp{i}_inv_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[flag_col] = df[inv_col].isna().astype(int)\n",
    "            # fill null with 2 (new category: 0=no avail,1=avail,2=no data)\n",
    "            df[inv_col] = df[inv_col].fillna(2).astype(int)\n",
    "\n",
    "        # price‐compare flag\n",
    "        rate_col = f'comp{i}_rate'\n",
    "        rate_flag = f'comp{i}_rate_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[rate_flag] = df[rate_col].isna().astype(int)\n",
    "            # fill null as “no data” = 2\n",
    "            df[rate_col] = df[rate_col].fillna(2).astype(int)\n",
    "\n",
    "        # percent_diff\n",
    "        pdiff_col = f'comp{i}_rate_percent_diff'\n",
    "        pdiff_flag = f'comp{i}_pdiff_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[pdiff_flag] = df[pdiff_col].isna().astype(int)\n",
    "            # fill null as 0% diff (no info)\n",
    "            df[pdiff_col] = df[pdiff_col].fillna(0.0)\n",
    "\n",
    "    # 5) Bucket orig_destination_distance\n",
    "    #    Missing → sentinel bucket + flag\n",
    "    for df in (train_df, test_df):\n",
    "        df['dist_na'] = df['orig_destination_distance'].isna().astype(int)\n",
    "        df['orig_destination_distance'] = (\n",
    "            df['orig_destination_distance'].fillna(-1)\n",
    "        )\n",
    "        # define bins (in km)\n",
    "        bins = [-1, 0, 10, 50, 200, np.inf]\n",
    "        labels = ['missing','0-10km','10-50km','50-200km','200km+']\n",
    "        df['dist_bucket'] = pd.cut(\n",
    "            df['orig_destination_distance'],\n",
    "            bins=bins, labels=labels\n",
    "        )\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def create_base_features(df):\n",
    "    \"\"\"1) Parse datetime & basic price/historical features.\"\"\"\n",
    "    df = df.copy()\n",
    "    # --- Date/time splits ---\n",
    "    df['date_time']   = pd.to_datetime(df['date_time'])\n",
    "    df['search_year'] = df['date_time'].dt.year\n",
    "    df['search_month']= df['date_time'].dt.month\n",
    "    df['search_day']  = df['date_time'].dt.day\n",
    "    df['search_hour'] = df['date_time'].dt.hour\n",
    "\n",
    "    # --- Price per night & hist price devation ---\n",
    "    df['price_per_night'] = df['price_usd'] / df['srch_length_of_stay']\n",
    "    df['price_vs_historical'] = df['price_usd'] - df['prop_log_historical_price']\n",
    "    df['price_vs_historical'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_destination_stats(train_df, test_df):\n",
    "    \"\"\"6) Dest‑level total searches & booking rate.\"\"\"\n",
    "    dest = (\n",
    "        train_df\n",
    "        .groupby('srch_destination_id')\n",
    "        .agg(dest_searches=('srch_id','count'),\n",
    "             dest_bookings=('booking_bool','sum'))\n",
    "        .assign(dest_booking_rate=lambda x: x.dest_bookings / x.dest_searches)\n",
    "        .reset_index()\n",
    "    )\n",
    "    # Reassign merge result back to each DataFrame\n",
    "    train_df = train_df.merge(\n",
    "        dest[['srch_destination_id','dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "    test_df = test_df.merge(\n",
    "        dest[['srch_destination_id','dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "    return train_df, test_df\n",
    "\n",
    "def add_within_search_features(df):\n",
    "    \"\"\"7) Z‑scores & deltas in each search group.\"\"\"\n",
    "    grp = df.groupby('srch_id')\n",
    "    # price\n",
    "    df['price_mean_srch'] = grp['price_usd'].transform('mean')\n",
    "    df['price_std_srch']  = grp['price_usd'].transform('std').fillna(1)\n",
    "    df['price_zscore']    = (df['price_usd'] - df['price_mean_srch']) / df['price_std_srch']\n",
    "    # stars\n",
    "    df['star_mean_srch']  = grp['prop_starrating'].transform('mean')\n",
    "    df['star_delta_srch'] = df['prop_starrating'] - df['star_mean_srch']\n",
    "    # user delta\n",
    "    df['star_delta_user'] = df['prop_starrating'] - df['visitor_hist_starrating']\n",
    "    # distance\n",
    "    df['dist_mean_srch']  = grp['orig_destination_distance'].transform('mean')\n",
    "    df['dist_std_srch']   = grp['orig_destination_distance'].transform('std').fillna(1)\n",
    "    df['dist_zscore']     = (df['orig_destination_distance'] - df['dist_mean_srch']) / df['dist_std_srch']\n",
    "    return df\n",
    "\n",
    "def add_temporal_features(df):\n",
    "    \"\"\"8) Weekday/weekend & check‑in weekend flags.\"\"\"\n",
    "    # day‑of‑week for search\n",
    "    df['search_dow'] = df['date_time'].dt.weekday  # 0=Mon…6=Sun\n",
    "    df['is_search_weekend'] = df['search_dow'].isin([5,6]).astype(int)\n",
    "    # approximate check‑in day\n",
    "    checkin = df['date_time'] + pd.to_timedelta(df['srch_booking_window'], 'D')\n",
    "    df['checkin_dow'] = checkin.dt.weekday\n",
    "    df['is_checkin_weekend'] = df['checkin_dow'].isin([5,6]).astype(int)\n",
    "    return df\n",
    "\n",
    "def add_ranks(df):\n",
    "    \"\"\"9) Dense ranks of price, star & distance within each search.\"\"\"\n",
    "    df['price_rank'] = df.groupby('srch_id')['price_usd'].rank('dense', ascending=True)\n",
    "    df['star_rank']  = df.groupby('srch_id')['prop_starrating'].rank('dense', ascending=False)\n",
    "    df['dist_rank']  = df.groupby('srch_id')['orig_destination_distance'].rank('dense', ascending=True)\n",
    "    return df\n",
    "\n",
    "def one_hot_encode_columns(train_df, test_df, columns_to_encode):\n",
    "    \"\"\"\n",
    "    Converts specified string columns in train and test DataFrames to one-hot encoded features.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): The training DataFrame.\n",
    "        test_df (pd.DataFrame): The testing DataFrame.\n",
    "        columns_to_encode (list): A list of column names (strings) to be one-hot encoded.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the modified training and testing DataFrames with one-hot encoded columns.\n",
    "    \"\"\"\n",
    "    train_processed = train_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "\n",
    "    for col in columns_to_encode:\n",
    "        if col in train_processed.columns and col in test_processed.columns:\n",
    "            # Get unique values from both train and test to ensure consistent encoding\n",
    "            all_unique_values = pd.concat([train_processed[col], test_processed[col]]).unique()\n",
    "\n",
    "            for value in all_unique_values:\n",
    "                train_processed[f'{col}_{value}'] = (train_processed[col] == value).astype(int)\n",
    "                test_processed[f'{col}_{value}'] = (test_processed[col] == value).astype(int)\n",
    "\n",
    "            # Drop the original categorical column\n",
    "            train_processed.drop(columns=[col], inplace=True)\n",
    "            test_processed.drop(columns=[col], inplace=True)\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in both train and test DataFrames. Skipping one-hot encoding for this column.\")\n",
    "\n",
    "    return train_processed, test_processed\n",
    "\n",
    "def minmax(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
    "\n",
    "def ensemble_predictions(pred1, pred2, weights):\n",
    "    w1, w2 = weights\n",
    "    return w1 * minmax(pred1) + w2 * minmax(pred2)\n",
    "\n",
    "def preprocess_missing_and_competitors_fit(train_df):\n",
    "    stats = {}\n",
    "    # 1) Which cols to drop\n",
    "    stats['drop_cols'] = [\n",
    "        *[f'comp{i}_{t}' for i in [1,4,6,7] \n",
    "          for t in ['rate','inv','rate_percent_diff']],\n",
    "        'gross_bookings_usd'\n",
    "    ]\n",
    "    # 2) Medians & mins for imputation\n",
    "    stats['star_med']     = train_df['visitor_hist_starrating'].median()\n",
    "    stats['adr_med']      = train_df['visitor_hist_adr_usd'].median()\n",
    "    stats['affinity_min'] = train_df['srch_query_affinity_score'].min(skipna=True)\n",
    "    return stats\n",
    "\n",
    "def preprocess_missing_and_competitors_transform(df, stats):\n",
    "    df = df.copy()\n",
    "    df.drop(columns=stats['drop_cols'], errors='ignore', inplace=True)\n",
    "\n",
    "    # visitor history\n",
    "    df['hist_star_na'] = df['visitor_hist_starrating'].isna().astype(int)\n",
    "    df['visitor_hist_starrating'] = (\n",
    "        df['visitor_hist_starrating']\n",
    "          .fillna(stats['star_med'])\n",
    "    )\n",
    "    df['hist_adr_na'] = df['visitor_hist_adr_usd'].isna().astype(int)\n",
    "    df['visitor_hist_adr_usd'] = (\n",
    "        df['visitor_hist_adr_usd']\n",
    "          .fillna(stats['adr_med'])\n",
    "    )\n",
    "\n",
    "    # affinity\n",
    "    df['affinity_na'] = df['srch_query_affinity_score'].isna().astype(int)\n",
    "    df['srch_query_affinity_score'] = (\n",
    "        df['srch_query_affinity_score']\n",
    "          .fillna(stats['affinity_min'])\n",
    "    )\n",
    "\n",
    "    # keep comps 2,3,5,8\n",
    "    for i in [2,3,5,8]:\n",
    "        for col, fill in [\n",
    "            (f'comp{i}_inv',               2),\n",
    "            (f'comp{i}_rate',              2),\n",
    "            (f'comp{i}_rate_percent_diff', 0.0),\n",
    "        ]:\n",
    "            df[f'{col}_na'] = df[col].isna().astype(int)\n",
    "            df[col] = df[col].fillna(fill)\n",
    "\n",
    "    # distance bucket\n",
    "    df['dist_na'] = df['orig_destination_distance'].isna().astype(int)\n",
    "    df['orig_destination_distance'] = (\n",
    "        df['orig_destination_distance'].fillna(-1)\n",
    "    )\n",
    "    bins  = [-1,0,10,50,200,np.inf]\n",
    "    lbls  = ['missing','0-10km','10-50km','50-200km','200km+']\n",
    "    df['dist_bucket'] = pd.cut(\n",
    "        df['orig_destination_distance'], bins=bins, labels=lbls\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def add_destination_stats_fit(train_df):\n",
    "    dest = (\n",
    "        train_df\n",
    "        .groupby('srch_destination_id')\n",
    "        .agg(dest_searches=('srch_id','count'),\n",
    "             dest_bookings=('booking_bool','sum'))\n",
    "    )\n",
    "    dest['dest_booking_rate'] = dest['dest_bookings'] / dest['dest_searches']\n",
    "    return dest\n",
    "\n",
    "def add_destination_stats_transform(df, dest_stats):\n",
    "    df = df.copy()\n",
    "    return df.merge(\n",
    "        dest_stats[['dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "def run_pipeline_on(train_df, other_df, steps):\n",
    "    df1, df2 = train_df.copy(), other_df.copy()\n",
    "    for fn in steps:\n",
    "        df1, df2 = fn(df1, df2)\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1039db90-505b-4710-a4cc-2ac0b456f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your FE pipeline, exactly as before\n",
    "steps = [\n",
    "    preprocess_missing_and_competitors,\n",
    "    add_destination_stats,\n",
    "    lambda tr, te: one_hot_encode_columns(tr, te, ['dist_bucket']),\n",
    "    lambda tr, te: (create_base_features(tr),     create_base_features(te)),\n",
    "    lambda tr, te: (add_within_search_features(tr), add_within_search_features(te)),\n",
    "    lambda tr, te: (add_temporal_features(tr),    add_temporal_features(te)),\n",
    "    lambda tr, te: (add_ranks(tr),                add_ranks(te)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb187d0-fb92-49dc-8060-582ebf758368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "comp3_rate                       3424059        69.056462\n",
      "comp3_inv                        3307357        66.702814\n",
      "comp8_rate                       3041693        61.344900\n",
      "comp8_inv                        2970844        59.916016\n",
      "comp2_rate                       2933675        59.166392\n",
      "comp2_inv                        2828078        57.036710\n",
      "comp5_rate                       2735974        55.179155\n",
      "comp5_inv                        2598327        52.403089\n",
      "orig_destination_distance        1607782        32.425766\n"
     ]
    }
   ],
   "source": [
    "mv = missing_values_table(train)\n",
    "print(mv.head(20))       # top 20 most‐missing columns\n",
    "# Or to filter down to “lots” of missing, say >30%:\n",
    "print(mv[mv['missing_percent'] > 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48198da9-b7e9-4f8a-9a23-a189962f4003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_15720\\2243288486.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_15720\\2243288486.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_15720\\2243288486.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_15720\\2243288486.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_15720\\1934780430.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_15720\\1934780430.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X     .fillna(medians, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_15720\\1934780430.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_va_all.fillna(medians, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_15720\\1934780430.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test .fillna(medians, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#0) define target\n",
    "y = train['booking_bool'] * 5 + train['click_bool']\n",
    "\n",
    "# 1) Split out search-IDs into train vs. valid (never touching test until after FE)\n",
    "train_ids, valid_ids = train_test_split(\n",
    "    train['srch_id'].unique(),\n",
    "    test_size=0.2,\n",
    "    random_state=22\n",
    ")\n",
    "train_raw = train[ train['srch_id'].isin(train_ids) ].reset_index(drop=True)\n",
    "valid_raw = train[ train['srch_id'].isin(valid_ids) ].reset_index(drop=True)\n",
    "test_raw  = test.copy()\n",
    "\n",
    "\n",
    "# 3) “Fit” FE on train_raw + test_raw\n",
    "train_feat, test_feat = run_pipeline_on(train_raw, test_raw, steps)\n",
    "\n",
    "# 4) “Apply” identical FE to valid_raw by feeding in the already-fitted train_feat\n",
    "_, valid_feat = run_pipeline_on(train_feat, valid_raw, steps)\n",
    "\n",
    "# 5) Select feature columns\n",
    "drop_cols = ['date_time','gross_bookings_usd','position',\n",
    "             'click_bool','booking_bool','srch_id','prop_id']\n",
    "features = [c for c in train_feat.columns if c not in drop_cols]\n",
    "\n",
    "X        = train_feat[features]\n",
    "X_va_all = valid_feat[features]\n",
    "X_test   = test_feat[features]\n",
    "\n",
    "# 6) Replace infinities and NaNs using only TRAIN medians\n",
    "for df in (X, X_va_all, X_test):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "medians = X.median()\n",
    "X     .fillna(medians, inplace=True)\n",
    "X_va_all.fillna(medians, inplace=True)\n",
    "X_test .fillna(medians, inplace=True)\n",
    "\n",
    "# 7) Scale\n",
    "scaler = StandardScaler()\n",
    "X_tr   = scaler.fit_transform(X)                       # train only\n",
    "X_va   = scaler.transform(X_va_all)                    # valid\n",
    "X_full = scaler.transform(pd.concat([X, X_va_all]))    # full\n",
    "X_test = scaler.transform(X_test)                      # test\n",
    "\n",
    "# 8) Build y arrays\n",
    "y_tr   = (train_raw['booking_bool'] * 5 + train_raw['click_bool']).values\n",
    "y_va   = (valid_raw['booking_bool'] * 5 + valid_raw['click_bool']).values\n",
    "y_full = np.concatenate([y_tr, y_va])\n",
    "\n",
    "# 9) Session‐IDs and group‐sizes\n",
    "id_tr   = train_raw['srch_id'].values\n",
    "id_va   = valid_raw['srch_id'].values\n",
    "id_full = np.concatenate([id_tr, id_va])\n",
    "\n",
    "grp_tr   = train_raw['srch_id'].value_counts(sort=False).values\n",
    "grp_va   = valid_raw['srch_id'].value_counts(sort=False).values\n",
    "grp_full = np.concatenate([grp_tr, grp_va])\n",
    "\n",
    "# 10) Make LightGBM & CatBoost datasets\n",
    "lgb_train = lgb.Dataset(X_tr,   label=y_tr,   group=grp_tr)\n",
    "lgb_val   = lgb.Dataset(X_va,   label=y_va,   group=grp_va)\n",
    "lgb_full  = lgb.Dataset(X_full, label=y_full, group=grp_full)\n",
    "\n",
    "train_pool = Pool(X_tr,   label=y_tr,   group_id=id_tr)\n",
    "val_pool   = Pool(X_va,   label=y_va,   group_id=id_va)\n",
    "full_pool  = Pool(X_full, label=y_full, group_id=id_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ec2bd5f-1730-4666-85f7-3952157d51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Define your search space\n",
    "\n",
    "param_dist = {\n",
    "    'learning_rate':    [0.005, 0.01, 0.02, 0.05],\n",
    "    'num_leaves':       [64, 128, 256],\n",
    "    'min_data_in_leaf': [10, 30, 50, 100],\n",
    "    'feature_fraction': [0.6, 0.8, 1.0],\n",
    "    'bagging_fraction': [0.6, 0.8, 1.0],\n",
    "    'bagging_freq':     [0, 5, 10]\n",
    "}\n",
    "\n",
    "n_iter = 30\n",
    "best_score, score = 0,0\n",
    "best_params,params = None,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "673066f0-78f5-4834-ace3-a35f4110ea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 256, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.5, 'lambda_l2': 0.0, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[588]\tvalid's ndcg@5: 0.385216\n",
      "    → ndcg@5 = 0.3852, rounds = 588\n",
      "2\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 128, 'min_data_in_leaf': 10, 'feature_fraction': 0.5, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.5, 'lambda_l2': 0.0, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[582]\tvalid's ndcg@5: 0.39076\n",
      "    → ndcg@5 = 0.3908, rounds = 582\n",
      "3\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.015, 'num_leaves': 128, 'min_data_in_leaf': 10, 'feature_fraction': 0.7, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.5, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.548231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[590]\tvalid's ndcg@5: 0.384518\n",
      "    → ndcg@5 = 0.3845, rounds = 590\n",
      "4\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.015, 'num_leaves': 320, 'min_data_in_leaf': 15, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.216590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[495]\tvalid's ndcg@5: 0.387138\n",
      "    → ndcg@5 = 0.3871, rounds = 495\n",
      "5\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.015, 'num_leaves': 320, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.5, 'lambda_l2': 0.0, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.229705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[592]\tvalid's ndcg@5: 0.390827\n",
      "    → ndcg@5 = 0.3908, rounds = 592\n",
      "6\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 320, 'min_data_in_leaf': 5, 'feature_fraction': 0.7, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.5, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.531820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[450]\tvalid's ndcg@5: 0.387614\n",
      "    → ndcg@5 = 0.3876, rounds = 450\n",
      "7\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.015, 'num_leaves': 256, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.5, 'lambda_l2': 0.1, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.204073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[589]\tvalid's ndcg@5: 0.387059\n",
      "    → ndcg@5 = 0.3871, rounds = 589\n",
      "8\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 256, 'min_data_in_leaf': 20, 'feature_fraction': 0.7, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.626713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\tvalid's ndcg@5: 0.384489\n",
      "    → ndcg@5 = 0.3845, rounds = 600\n",
      "9\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 192, 'min_data_in_leaf': 5, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.222604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[404]\tvalid's ndcg@5: 0.38568\n",
      "    → ndcg@5 = 0.3857, rounds = 404\n",
      "10\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 128, 'min_data_in_leaf': 10, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.5, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.193874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[548]\tvalid's ndcg@5: 0.390854\n",
      "    → ndcg@5 = 0.3909, rounds = 548\n",
      "11\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 192, 'min_data_in_leaf': 15, 'feature_fraction': 0.7, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.5, 'lambda_l2': 0.0, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.530344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\tvalid's ndcg@5: 0.387111\n",
      "    → ndcg@5 = 0.3871, rounds = 600\n",
      "12\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 128, 'min_data_in_leaf': 10, 'feature_fraction': 0.7, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.5, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.522903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[598]\tvalid's ndcg@5: 0.389936\n",
      "    → ndcg@5 = 0.3899, rounds = 598\n",
      "13\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 192, 'min_data_in_leaf': 5, 'feature_fraction': 0.5, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.203169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[435]\tvalid's ndcg@5: 0.389705\n",
      "    → ndcg@5 = 0.3897, rounds = 435\n",
      "14\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 192, 'min_data_in_leaf': 5, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.217494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[599]\tvalid's ndcg@5: 0.391015\n",
      "    → ndcg@5 = 0.3910, rounds = 599\n",
      "15\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 320, 'min_data_in_leaf': 15, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.5, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.211179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[583]\tvalid's ndcg@5: 0.390123\n",
      "    → ndcg@5 = 0.3901, rounds = 583\n",
      "16\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 192, 'min_data_in_leaf': 5, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.214591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[546]\tvalid's ndcg@5: 0.391352\n",
      "    → ndcg@5 = 0.3914, rounds = 546\n",
      "17\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 128, 'min_data_in_leaf': 20, 'feature_fraction': 0.7, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.5, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.590212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[548]\tvalid's ndcg@5: 0.390703\n",
      "    → ndcg@5 = 0.3907, rounds = 548\n",
      "18\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 256, 'min_data_in_leaf': 5, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.5, 'lambda_l2': 0.1, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.206963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[455]\tvalid's ndcg@5: 0.387404\n",
      "    → ndcg@5 = 0.3874, rounds = 455\n",
      "19\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 320, 'min_data_in_leaf': 10, 'feature_fraction': 0.5, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.216321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[486]\tvalid's ndcg@5: 0.388076\n",
      "    → ndcg@5 = 0.3881, rounds = 486\n",
      "20\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 128, 'min_data_in_leaf': 10, 'feature_fraction': 0.7, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.5, 'lambda_l2': 0.5, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.529779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\tvalid's ndcg@5: 0.390522\n",
      "    → ndcg@5 = 0.3905, rounds = 600\n",
      "21\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 192, 'min_data_in_leaf': 5, 'feature_fraction': 0.5, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.211723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[585]\tvalid's ndcg@5: 0.390663\n",
      "    → ndcg@5 = 0.3907, rounds = 585\n",
      "22\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 128, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.5, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.183332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[597]\tvalid's ndcg@5: 0.385876\n",
      "    → ndcg@5 = 0.3859, rounds = 597\n",
      "23\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 256, 'min_data_in_leaf': 5, 'feature_fraction': 0.5, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.212097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\tvalid's ndcg@5: 0.385299\n",
      "    → ndcg@5 = 0.3853, rounds = 600\n",
      "24\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 192, 'min_data_in_leaf': 5, 'feature_fraction': 0.7, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.5, 'lambda_l2': 0.0, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.588804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[588]\tvalid's ndcg@5: 0.38709\n",
      "    → ndcg@5 = 0.3871, rounds = 588\n",
      "25\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.015, 'num_leaves': 192, 'min_data_in_leaf': 20, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.231659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[507]\tvalid's ndcg@5: 0.385029\n",
      "    → ndcg@5 = 0.3850, rounds = 507\n",
      "26\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 192, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.5, 'lambda_l2': 0.0, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.206778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[599]\tvalid's ndcg@5: 0.391493\n",
      "    → ndcg@5 = 0.3915, rounds = 599\n",
      "27\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.025, 'num_leaves': 256, 'min_data_in_leaf': 15, 'feature_fraction': 0.7, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.5, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.535883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[599]\tvalid's ndcg@5: 0.392084\n",
      "    → ndcg@5 = 0.3921, rounds = 599\n",
      "28\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 128, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.5, 'min_gain_to_split': 0.2}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.209913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[585]\tvalid's ndcg@5: 0.389738\n",
      "    → ndcg@5 = 0.3897, rounds = 585\n",
      "29\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.015, 'num_leaves': 320, 'min_data_in_leaf': 5, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'min_gain_to_split': 0.0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.234644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[593]\tvalid's ndcg@5: 0.387355\n",
      "    → ndcg@5 = 0.3874, rounds = 593\n",
      "30\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 256, 'min_data_in_leaf': 5, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.5, 'lambda_l2': 0.0, 'min_gain_to_split': 0.1}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.216371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6874\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[585]\tvalid's ndcg@5: 0.385433\n",
      "    → ndcg@5 = 0.3854, rounds = 585\n"
     ]
    }
   ],
   "source": [
    "# 1) Your random search stays the same…\n",
    "for i in range(1, n_iter + 1):\n",
    "    print(i)\n",
    "    params = {\n",
    "        'objective':         'lambdarank',\n",
    "        'metric':            'ndcg',\n",
    "        'ndcg_eval_at':      [5],\n",
    "        'verbose':           1,\n",
    "        'feature_pre_filter': False,      # ← disable the one-shot pre-filter\n",
    "    }\n",
    "    # 2) then overlay your random hyper‐params\n",
    "    params.update({k: np.random.choice(v) for k, v in param_dist.items()})\n",
    "    print(params)\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set=lgb_train,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=lgb_val,\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    "    )\n",
    "    \n",
    "    score = model.best_score['valid']['ndcg@5']\n",
    "    print(f\"    → ndcg@5 = {score:.4f}, rounds = {model.best_iteration}\")\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score_ = score\n",
    "        best_params = params.copy()\n",
    "        best_iter =  model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06f335fe-beb9-44c9-a698-c4a8dd99de6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 256, 'min_data_in_leaf': 5, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.5, 'lambda_l2': 0.0, 'min_gain_to_split': 0.1} 585\n"
     ]
    }
   ],
   "source": [
    "print(best_score, best_params, best_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf22fe9-054d-4f3b-a757-a40119664b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.246080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6892\n",
      "[LightGBM] [Info] Number of data points in the train set: 4958347, number of used features: 79\n"
     ]
    }
   ],
   "source": [
    "# 3) Retrain on all data\n",
    "model_lgb_full = lgb.train(\n",
    "    best_params,\n",
    "    lgb_full,\n",
    "    num_boost_round=best_iter # can still be ajdusted to best best_iter\n",
    ")\n",
    "\n",
    "# 4) Predict on test\n",
    "lgb_test_preds = model_lgb_full.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c4afe9f-c8cb-46c4-a86b-c567a7e81a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 23:36:15,377] A new study created in memory with name: catboost_yetirank\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_15720\\1916531565.py:22: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  pruning_callback = CatBoostPruningCallback(trial, 'NDCG:top=5;type=Base')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.2645303\tbest: 0.2645303 (0)\ttotal: 1.58s\tremaining: 15m 45s\n",
      "100:\ttest: 0.3698547\tbest: 0.3698969 (99)\ttotal: 2m 15s\tremaining: 11m 7s\n",
      "200:\ttest: 0.3759859\tbest: 0.3760309 (197)\ttotal: 4m 22s\tremaining: 8m 41s\n",
      "300:\ttest: 0.3788210\tbest: 0.3789672 (290)\ttotal: 6m 30s\tremaining: 6m 27s\n",
      "400:\ttest: 0.3817460\tbest: 0.3817460 (400)\ttotal: 8m 38s\tremaining: 4m 17s\n",
      "500:\ttest: 0.3832971\tbest: 0.3834231 (490)\ttotal: 10m 46s\tremaining: 2m 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 23:49:10,903] Trial 0 finished with value: 0.3843269206710692 and parameters: {'learning_rate': 0.07680345887880288, 'depth': 6, 'l2_leaf_reg': 0.07628296500561162, 'random_strength': 0.001647314946540589, 'bagging_temperature': 0.6558738088482978, 'border_count': 134}. Best is trial 0 with value: 0.3843269206710692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\ttest: 0.3842487\tbest: 0.3843269 (588)\ttotal: 12m 53s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3843269207\n",
      "bestIteration = 588\n",
      "\n",
      "Shrink model to first 589 iterations.\n",
      "0:\ttest: 0.2934517\tbest: 0.2934517 (0)\ttotal: 2.25s\tremaining: 22m 28s\n",
      "100:\ttest: 0.3555482\tbest: 0.3555482 (100)\ttotal: 3m 40s\tremaining: 18m 8s\n",
      "200:\ttest: 0.3634770\tbest: 0.3634770 (200)\ttotal: 7m 17s\tremaining: 14m 27s\n",
      "300:\ttest: 0.3685407\tbest: 0.3685531 (298)\ttotal: 10m 51s\tremaining: 10m 47s\n",
      "400:\ttest: 0.3720404\tbest: 0.3720404 (400)\ttotal: 14m 25s\tremaining: 7m 9s\n",
      "500:\ttest: 0.3742149\tbest: 0.3742149 (500)\ttotal: 17m 57s\tremaining: 3m 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 00:10:40,700] Trial 1 finished with value: 0.37584756441232703 and parameters: {'learning_rate': 0.011167355616826094, 'depth': 11, 'l2_leaf_reg': 0.09808074045984329, 'random_strength': 2.122209693658469, 'bagging_temperature': 0.8829169966991586, 'border_count': 176}. Best is trial 0 with value: 0.3843269206710692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\ttest: 0.3757844\tbest: 0.3758476 (598)\ttotal: 21m 27s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3758475644\n",
      "bestIteration = 598\n",
      "\n",
      "Shrink model to first 599 iterations.\n",
      "0:\ttest: 0.2950476\tbest: 0.2950476 (0)\ttotal: 2.35s\tremaining: 23m 29s\n",
      "100:\ttest: 0.3740978\tbest: 0.3740978 (100)\ttotal: 3m 49s\tremaining: 18m 53s\n",
      "200:\ttest: 0.3809219\tbest: 0.3809219 (200)\ttotal: 7m 32s\tremaining: 14m 58s\n",
      "300:\ttest: 0.3845315\tbest: 0.3845315 (300)\ttotal: 11m 15s\tremaining: 11m 10s\n",
      "400:\ttest: 0.3863359\tbest: 0.3865870 (376)\ttotal: 14m 58s\tremaining: 7m 26s\n",
      "500:\ttest: 0.3879607\tbest: 0.3880914 (497)\ttotal: 18m 42s\tremaining: 3m 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 00:33:01,945] Trial 2 finished with value: 0.38914047871703333 and parameters: {'learning_rate': 0.05583711975310588, 'depth': 12, 'l2_leaf_reg': 2.1942428836136942, 'random_strength': 0.3226597031829645, 'bagging_temperature': 0.8517323674322966, 'border_count': 121}. Best is trial 2 with value: 0.38914047871703333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\ttest: 0.3890955\tbest: 0.3891405 (588)\ttotal: 22m 23s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3891404787\n",
      "bestIteration = 588\n",
      "\n",
      "Shrink model to first 589 iterations.\n",
      "0:\ttest: 0.2922256\tbest: 0.2922256 (0)\ttotal: 2.03s\tremaining: 20m 16s\n",
      "100:\ttest: 0.3620895\tbest: 0.3620895 (100)\ttotal: 3m 14s\tremaining: 15m 59s\n",
      "200:\ttest: 0.3693962\tbest: 0.3693962 (200)\ttotal: 6m 24s\tremaining: 12m 43s\n",
      "300:\ttest: 0.3735794\tbest: 0.3735794 (300)\ttotal: 9m 34s\tremaining: 9m 30s\n",
      "400:\ttest: 0.3765652\tbest: 0.3766076 (396)\ttotal: 12m 42s\tremaining: 6m 18s\n",
      "500:\ttest: 0.3782943\tbest: 0.3783204 (499)\ttotal: 15m 49s\tremaining: 3m 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 00:51:59,686] Trial 3 finished with value: 0.37964594659103007 and parameters: {'learning_rate': 0.0221650513368399, 'depth': 10, 'l2_leaf_reg': 1.3408460733528769, 'random_strength': 1.9392502972903585, 'bagging_temperature': 0.894834861581947, 'border_count': 41}. Best is trial 2 with value: 0.38914047871703333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\ttest: 0.3795260\tbest: 0.3796459 (594)\ttotal: 18m 55s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3796459466\n",
      "bestIteration = 594\n",
      "\n",
      "Shrink model to first 595 iterations.\n",
      "0:\ttest: 0.2744307\tbest: 0.2744307 (0)\ttotal: 1.47s\tremaining: 14m 40s\n",
      "100:\ttest: 0.3635203\tbest: 0.3635203 (100)\ttotal: 2m 15s\tremaining: 11m 11s\n",
      "200:\ttest: 0.3713953\tbest: 0.3713953 (200)\ttotal: 4m 26s\tremaining: 8m 48s\n",
      "300:\ttest: 0.3752343\tbest: 0.3752695 (296)\ttotal: 6m 34s\tremaining: 6m 31s\n",
      "400:\ttest: 0.3771594\tbest: 0.3772259 (398)\ttotal: 8m 42s\tremaining: 4m 19s\n",
      "500:\ttest: 0.3790873\tbest: 0.3791452 (499)\ttotal: 10m 48s\tremaining: 2m 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 01:04:57,772] Trial 4 finished with value: 0.3804593856020207 and parameters: {'learning_rate': 0.036599839166436145, 'depth': 7, 'l2_leaf_reg': 0.5072226712750647, 'random_strength': 0.001580493912733827, 'bagging_temperature': 0.8023193517322994, 'border_count': 178}. Best is trial 2 with value: 0.38914047871703333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\ttest: 0.3803082\tbest: 0.3804594 (595)\ttotal: 12m 55s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3804593856\n",
      "bestIteration = 595\n",
      "\n",
      "Shrink model to first 596 iterations.\n",
      "0:\ttest: 0.3029919\tbest: 0.3029919 (0)\ttotal: 2.58s\tremaining: 25m 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 01:06:08,824] Trial 5 pruned. Trial was pruned at iteration 28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3460790257\n",
      "bestIteration = 28\n",
      "\n",
      "Shrink model to first 29 iterations.\n",
      "0:\ttest: 0.2853895\tbest: 0.2853895 (0)\ttotal: 1.54s\tremaining: 15m 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 01:06:19,514] Trial 6 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3130836112\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.2768252\tbest: 0.2768252 (0)\ttotal: 1.57s\tremaining: 15m 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 01:06:29,889] Trial 7 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3141865212\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.2923172\tbest: 0.2923172 (0)\ttotal: 2.25s\tremaining: 22m 27s\n",
      "100:\ttest: 0.3779574\tbest: 0.3779574 (100)\ttotal: 3m 40s\tremaining: 18m 10s\n",
      "200:\ttest: 0.3838826\tbest: 0.3840137 (198)\ttotal: 7m 16s\tremaining: 14m 26s\n",
      "300:\ttest: 0.3867409\tbest: 0.3871957 (291)\ttotal: 10m 53s\tremaining: 10m 49s\n",
      "400:\ttest: 0.3884351\tbest: 0.3885322 (395)\ttotal: 14m 31s\tremaining: 7m 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 01:23:55,939] Trial 8 finished with value: 0.38894657015559864 and parameters: {'learning_rate': 0.07708386205116058, 'depth': 12, 'l2_leaf_reg': 0.391820118608448, 'random_strength': 0.7991889727982652, 'bagging_temperature': 0.05917032540639744, 'border_count': 68}. Best is trial 2 with value: 0.38914047871703333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3889465702\n",
      "bestIteration = 430\n",
      "\n",
      "Shrink model to first 431 iterations.\n",
      "0:\ttest: 0.2645303\tbest: 0.2645303 (0)\ttotal: 1.41s\tremaining: 14m 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 01:24:05,693] Trial 9 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.2795842598\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "0:\ttest: 0.2904193\tbest: 0.2904193 (0)\ttotal: 2.04s\tremaining: 20m 24s\n",
      "100:\ttest: 0.3708653\tbest: 0.3708653 (100)\ttotal: 3m 21s\tremaining: 16m 35s\n",
      "200:\ttest: 0.3774433\tbest: 0.3774433 (200)\ttotal: 6m 36s\tremaining: 13m 6s\n",
      "300:\ttest: 0.3812094\tbest: 0.3812094 (300)\ttotal: 9m 50s\tremaining: 9m 46s\n",
      "400:\ttest: 0.3837406\tbest: 0.3837737 (398)\ttotal: 13m 2s\tremaining: 6m 28s\n",
      "500:\ttest: 0.3851377\tbest: 0.3852111 (499)\ttotal: 16m 18s\tremaining: 3m 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 01:43:38,193] Trial 10 finished with value: 0.3864566872164699 and parameters: {'learning_rate': 0.05401593049234929, 'depth': 10, 'l2_leaf_reg': 7.455315199229415, 'random_strength': 0.2391088083608152, 'bagging_temperature': 0.30539214481929766, 'border_count': 252}. Best is trial 2 with value: 0.38914047871703333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599:\ttest: 0.3862424\tbest: 0.3864567 (597)\ttotal: 19m 30s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3864566872\n",
      "bestIteration = 597\n",
      "\n",
      "Shrink model to first 598 iterations.\n",
      "Best PFound: 0.38914047871703333\n",
      "Best hyperparameters:\n",
      "  learning_rate: 0.05583711975310588\n",
      "  depth: 12\n",
      "  l2_leaf_reg: 2.1942428836136942\n",
      "  random_strength: 0.3226597031829645\n",
      "  bagging_temperature: 0.8517323674322966\n",
      "  border_count: 121\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params_cat = {\n",
    "        'loss_function': 'YetiRank',\n",
    "        'eval_metric': 'NDCG:top=5',\n",
    "        'random_seed': 5,\n",
    "        'od_type': 'Iter',\n",
    "        'od_wait': 20,\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int(\"depth\", 6, 12),\n",
    "        'l2_leaf_reg': trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10.0, log=True),\n",
    "        'random_strength': trial.suggest_float(\"random_strength\", 1e-3, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "        'border_count': trial.suggest_int(\"border_count\", 32, 255),\n",
    "        'iterations': 1000,\n",
    "        'use_best_model': True,\n",
    "        'verbose': 100,\n",
    "    }\n",
    "\n",
    "    model_cat = CatBoostRanker(**params_cat)\n",
    "\n",
    "    # Pruner callback for PFound\n",
    "    pruning_callback = CatBoostPruningCallback(trial, 'NDCG:top=5;type=Base')\n",
    "\n",
    "\n",
    "    model_cat.fit(\n",
    "        train_pool,\n",
    "        eval_set=val_pool,\n",
    "        early_stopping_rounds=30,\n",
    "        callbacks=[pruning_callback],\n",
    "    )\n",
    "\n",
    "    # Manually trigger pruning\n",
    "    pruning_callback.check_pruned()\n",
    "\n",
    "     # 5) Grab the best‐iteration score\n",
    "    hist = model_cat.get_evals_result()['validation']['NDCG:top=5;type=Base']\n",
    "    return max(hist) \n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"catboost_yetirank\",\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=100)\n",
    ")\n",
    "study.optimize(objective, n_trials=60, timeout=9800)\n",
    "\n",
    "print(f\"Best PFound: {study.best_trial.value}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for k, v in study.best_trial.params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5fff8cf2-1c00-4142-963c-7814bd9db8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV NDCG@5 (Optuna): 0.3891\n",
      "Best hyperparameters:\n",
      "  learning_rate: 0.05583711975310588\n",
      "  depth: 12\n",
      "  l2_leaf_reg: 2.1942428836136942\n",
      "  random_strength: 0.3226597031829645\n",
      "  bagging_temperature: 0.8517323674322966\n",
      "  border_count: 121\n",
      "▶️  Early stopping picked 599 iterations\n",
      "0:\ttotal: 3.22s\tremaining: 32m 7s\n",
      "100:\ttotal: 5m 33s\tremaining: 27m 23s\n",
      "200:\ttotal: 10m 39s\tremaining: 21m 6s\n",
      "300:\ttotal: 15m 34s\tremaining: 15m 25s\n",
      "400:\ttotal: 20m 33s\tremaining: 10m 8s\n",
      "500:\ttotal: 25m 34s\tremaining: 5m\n",
      "598:\ttotal: 30m 35s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# 1) Print your Optuna CV results\n",
    "best_params_cat = study.best_trial.params\n",
    "best_ndcg5      = study.best_trial.value\n",
    "print(f\"Best CV NDCG@5 (Optuna): {best_ndcg5:.4f}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for k, v in best_params_cat.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# 4) Immediately pull out that best_iteration\n",
    "\n",
    "best_iter = full_model.get_best_iteration()\n",
    "print(f\"▶️  Early stopping picked {best_iter} iterations\")\n",
    "\n",
    "\n",
    "# 2) Build final model stub\n",
    "final_model = CatBoostRanker(\n",
    "    loss_function    = 'YetiRank',\n",
    "    eval_metric      = 'NDCG:top=5',\n",
    "    random_seed      = 22,\n",
    "    use_best_model   = False,     # we’re fixing the tree count manually\n",
    "    iterations       = best_iter,\n",
    "    verbose          = 100,\n",
    "    **best_params_cat\n",
    ")\n",
    "\n",
    "# 3) Fit on the full Pool, with no early stopping or eval_set\n",
    "final_model.fit(full_pool)  \n",
    "\n",
    "# 4) Predict on your test set\n",
    "cat_test_preds = final_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c6ad64-5139-4b3f-9cf7-c28213d1a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) After Optuna, get your best‐found params and CV score\n",
    "best_params_cat = study.best_trial.params\n",
    "best_ndcg5      = study.best_trial.value\n",
    "print(f\"Best CV NDCG@5 (Optuna): {best_ndcg5:.4f}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for k, v in best_params_cat.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# 2) Build a “big” model stub on full data with early stopping\n",
    "full_model = CatBoostRanker(\n",
    "    loss_function  = 'YetiRank',\n",
    "    eval_metric    = 'NDCG:top=5',\n",
    "    random_seed    = 22,\n",
    "    use_best_model = True,      # enable early stopping\n",
    "    iterations     = 1000,      # generous upper bound\n",
    "    verbose        = 100,\n",
    "    **best_params_cat           # your Optuna‐tuned hyperparams\n",
    ")\n",
    "# 3) Fit on the FULL pool as its own eval_set\n",
    "full_model.fit(\n",
    "    full_pool,\n",
    "    eval_set=full_pool,\n",
    "    early_stopping_rounds=30,\n",
    ")\n",
    "best_iter = full_model.get_best_iteration()\n",
    "print(f\"▶️  Early stopping picked {best_iter} iterations\")\n",
    "\n",
    "# 4) Now re‐instantiate EXACTLY that many trees (no early stopping)\n",
    "final_model_big = CatBoostRanker(\n",
    "    loss_function  = 'YetiRank',\n",
    "    eval_metric    = 'NDCG:top=5',\n",
    "    random_seed    = 22,\n",
    "    iterations     = best_iter, # freeze at the optimal point\n",
    "    use_best_model = False,     # no more early stopping\n",
    "    verbose        = 100,\n",
    "    **best_params_cat\n",
    ")\n",
    "final_model_big.fit(full_pool)\n",
    "\n",
    "# 5) Finally predict on test\n",
    "cat_test_preds_big = final_model_big.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79ada07e-f959-4685-9006-2d37dbcd7a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv written using lgb only!\n"
     ]
    }
   ],
   "source": [
    "# 2) Put them into your submission\n",
    "\n",
    "#can use cat_test_pred or lgb_test_preds\n",
    "\n",
    "sample['score'] = cat_test_preds_big\n",
    "submission = (\n",
    "    sample\n",
    "    .sort_values(['srch_id', 'score'], ascending=[True, False])\n",
    "    [['srch_id', 'prop_id']]\n",
    ")\n",
    "\n",
    "# 3) Write to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission.csv written using lgb only!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3eb20bf6-7ab7-4a2c-9572-727a7e61005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost Val NDCG@5: 0.4313\n",
      "\n",
      "LightGBM Val NDCG@5: 0.4369\n"
     ]
    }
   ],
   "source": [
    "# 1. Predict raw scores for the validation set\n",
    "cat_val_preds = final_model_big.predict(X_va)\n",
    "lgb_val_preds = model_lgb_full.predict(X_va)\n",
    "\n",
    "# 2. Compute per-session NDCG@5 manually\n",
    "ndcgs_cat = []\n",
    "ndcgs_lgb = []\n",
    "\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:  # skip sessions with only 1 result\n",
    "        true_rels = y_va[idx]\n",
    "        ndcgs_cat.append(ndcg_score([true_rels], [cat_val_preds[idx]], k=5))\n",
    "        ndcgs_lgb.append(ndcg_score([true_rels], [lgb_val_preds[idx]], k=5))\n",
    "\n",
    "# 3. Average NDCG@5 for both models\n",
    "catboost_ndcg5 = np.mean(ndcgs_cat)\n",
    "lgb_ndcg5 = np.mean(ndcgs_lgb)\n",
    "\n",
    "print(f\"\\nCatBoost Val NDCG@5: {catboost_ndcg5:.4f}\")\n",
    "print(f\"\\nLightGBM Val NDCG@5: {lgb_ndcg5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6991fd44-41cb-4f3c-8643-bb5f041603a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_cb=0.0, w_lgb=1.0 → Val NDCG@5: 0.4369\n",
      "w_cb=0.1, w_lgb=0.9 → Val NDCG@5: 0.4367\n",
      "w_cb=0.2, w_lgb=0.8 → Val NDCG@5: 0.4360\n",
      "w_cb=0.3, w_lgb=0.7 → Val NDCG@5: 0.4356\n",
      "w_cb=0.4, w_lgb=0.6 → Val NDCG@5: 0.4357\n",
      "w_cb=0.5, w_lgb=0.5 → Val NDCG@5: 0.4349\n",
      "w_cb=0.6, w_lgb=0.4 → Val NDCG@5: 0.4340\n",
      "w_cb=0.7, w_lgb=0.3 → Val NDCG@5: 0.4327\n",
      "w_cb=0.8, w_lgb=0.2 → Val NDCG@5: 0.4326\n",
      "w_cb=0.9, w_lgb=0.1 → Val NDCG@5: 0.4318\n",
      "w_cb=1.0, w_lgb=0.0 → Val NDCG@5: 0.4313\n",
      "\n",
      " Best blend (CB+LGB): w_cb=0.00, w_lgb=1.00 → NDCG@5=0.4369\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1) Scale just your two tree-based model preds on validation\n",
    "cb_s  = minmax(cat_val_preds)   # your CatBoost val preds\n",
    "lgb_s = minmax(lgb_val_preds)   # your LightGBM val preds\n",
    "\n",
    "# 2) Sweep over blends of just CB + LGB\n",
    "best, best_w = 0, None\n",
    "for w_cb in np.linspace(0, 1, 11):\n",
    "    w_lgb = 1 - w_cb\n",
    "    sc = w_cb * cb_s + w_lgb * lgb_s\n",
    "\n",
    "    # compute NDCG@5 on val\n",
    "    ndcgs = []\n",
    "    for q in np.unique(id_va):\n",
    "        idx = np.where(id_va == q)[0]\n",
    "        if len(idx) > 1:\n",
    "            true = y_va[idx]\n",
    "            ndcgs.append(ndcg_score([true], [sc[idx]], k=5))\n",
    "    mean_ndcg = np.mean(ndcgs)\n",
    "\n",
    "    print(f\"w_cb={w_cb:.1f}, w_lgb={w_lgb:.1f} → Val NDCG@5: {mean_ndcg:.4f}\")\n",
    "    if mean_ndcg > best:\n",
    "        best, best_w = mean_ndcg, (w_cb, w_lgb)\n",
    "\n",
    "print(f\"\\n Best blend (CB+LGB): w_cb={best_w[0]:.2f}, w_lgb={best_w[1]:.2f} → NDCG@5={best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30e54659-6f48-4d9e-94ac-fecb7f8d15cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission.csv written using w_cb=0.50, w_lgb=0.50!\n"
     ]
    }
   ],
   "source": [
    "# --- Ensemble the test predictions with your optimal blend ---\n",
    "best_w = [0.5,0.5]\n",
    "\n",
    "ensemble_final_preds = ensemble_predictions(\n",
    "    cat_test_preds,\n",
    "    lgb_test_preds,\n",
    "    weights=[best_w[0], best_w[1]]\n",
    ")\n",
    "\n",
    "# Put them into submission\n",
    "sample['score'] = ensemble_final_preds\n",
    "submission = (\n",
    "    sample\n",
    "    .sort_values(['srch_id','score'], ascending=[True, False])\n",
    "    [['srch_id','prop_id']]\n",
    ")\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission.csv written using w_cb={best_w[0]:.2f}, w_lgb={best_w[1]:.2f}!\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ccd16-188e-40cc-8d80-e176c305925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# --- 1) ListNet loss (unchanged) ---\n",
    "def listnet_loss(scores, labels, group_ids):\n",
    "    loss, count = 0.0, 0\n",
    "    for q in np.unique(group_ids):\n",
    "        idx = np.where(group_ids == q)[0]\n",
    "        if len(idx) < 2:\n",
    "            continue\n",
    "        s_q, y_q = scores[idx], labels[idx].float()\n",
    "        P, P_hat = torch.softmax(y_q, 0), torch.softmax(s_q, 0)\n",
    "        loss += -torch.sum(P * torch.log(P_hat + 1e-8))\n",
    "        count += 1\n",
    "    return loss / max(count, 1)\n",
    "\n",
    "param_grid = {\n",
    "    'lr':           [1e-3, 2e-3],\n",
    "    'batch_size':   [512, 1024],\n",
    "    'dropout':      [0.1, 0.2],\n",
    "    'weight_decay': [0.0, 1e-4]\n",
    "}\n",
    "\n",
    "best = {'ndcg': 0.0, 'cfg': None}\n",
    "\n",
    "for lr, bs, drop, wd in itertools.product(*param_grid.values()):\n",
    "    tr_loader = DataLoader(ExpediaDataset(X_tr, y_tr.values),\n",
    "                           batch_size=bs, shuffle=True)\n",
    "    va_loader = DataLoader(ExpediaDataset(X_va, y_va.values),\n",
    "                           batch_size=bs, shuffle=False)\n",
    "\n",
    "    mdl = DeepRecommender(X_tr.shape[1]).to(device)\n",
    "    for m in mdl.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.p = drop\n",
    "\n",
    "    opt = torch.optim.Adam(\n",
    "        mdl.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=wd\n",
    "    )\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt,\n",
    "        max_lr=lr * 10,\n",
    "        steps_per_epoch=len(tr_loader),\n",
    "        epochs=10\n",
    "    )\n",
    "\n",
    "    best_ndcg, stale = 0.0, 0\n",
    "    for epoch in range(1, 8):\n",
    "        # — train —\n",
    "        mdl.train()\n",
    "        for Xb, yb in tr_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = listnet_loss(mdl(Xb), yb, id_tr[:len(Xb)])\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        # — validate —\n",
    "        mdl.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for Xb, _ in va_loader:\n",
    "                preds.extend(mdl(Xb.to(device)).cpu().numpy())\n",
    "        preds = np.array(preds)\n",
    "\n",
    "        # compute mean NDCG@5 using the same y_va array\n",
    "        ndcgs = []\n",
    "        for q in np.unique(id_va):\n",
    "            idx = np.where(id_va == q)[0]\n",
    "            if len(idx) > 1:\n",
    "                true = y_va.values[idx]\n",
    "                score = preds[idx]\n",
    "                ndcgs.append(ndcg_score([true], [score], k=5))\n",
    "        mean_ndcg = np.mean(ndcgs)\n",
    "        sched.step(mean_ndcg)\n",
    "\n",
    "        if mean_ndcg > best_ndcg + 1e-4:\n",
    "            best_ndcg, stale = mean_ndcg, 0\n",
    "        else:\n",
    "            stale += 1\n",
    "        if stale >= 5:\n",
    "            break\n",
    "\n",
    "    print(f\"cfg lr={lr}, bs={bs}, drop={drop} → Val NDCG@5: {best_ndcg:.4f}\")\n",
    "    if best_ndcg > best['ndcg']:\n",
    "        best.update({'ndcg': best_ndcg, 'cfg': (lr, bs, drop)})\n",
    "\n",
    "print(\"🏆 Best config:\", best)\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4855e15-4c6b-492f-a267-979ef406a160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef09feb-986f-496e-a691-8fedcee3d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# unpack your best cfg and tweak\n",
    "lr, bs, drop, wd = 1e-3, 128, 0.1, 1e-5\n",
    "\n",
    "# rebuild full-training loader\n",
    "full_loader = DataLoader(\n",
    "    ExpediaDatasetGrouped(X_full, y_full, id_full),\n",
    "    batch_size=bs, shuffle=True\n",
    ")\n",
    "\n",
    "# 1) Slightly larger network at the top\n",
    "class BiggerRecommender(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512), nn.ReLU(), nn.BatchNorm1d(512), nn.Dropout(drop),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.BatchNorm1d(256), nn.Dropout(drop),\n",
    "            nn.Linear(256, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(drop),\n",
    "            nn.Linear(128, 64),  nn.ReLU(), nn.Dropout(drop),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "final_nn = BiggerRecommender(X_full.shape[1]).to(device)\n",
    "\n",
    "# 2) Optimizer with very light weight decay\n",
    "opt = torch.optim.Adam(final_nn.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "# 3) Simpler stepLR scheduler (cuts LR by 0.5 every 10 epochs)\n",
    "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.5)\n",
    "\n",
    "# 4) Train for 30 epochs with gradient clipping\n",
    "for epoch in range(1, 31):\n",
    "    final_nn.train()\n",
    "    total_loss = 0.0\n",
    "    for Xb, yb, gb in full_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = final_nn(Xb)\n",
    "        loss   = listnet_loss(logits, yb, gb)  \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(final_nn.parameters(), 5.0)\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item() * Xb.size(0)\n",
    "\n",
    "    sched.step()\n",
    "    avg_loss = total_loss / len(full_loader.dataset)\n",
    "    print(f\"Epoch {epoch:02d}/30 — Avg ListNet Loss: {avg_loss:.4f} — LR: {opt.param_groups[0]['lr']:.1e}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f70ffb-f18d-43e7-a272-cbc58ee1c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# --- 4) Produce final test preds ---\n",
    "test_loader = DataLoader(\n",
    "    ExpediaDataset(X_test, np.zeros(len(X_test))),\n",
    "    batch_size=bs,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "nn_test_preds = []\n",
    "final_nn.eval()\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in test_loader:           # <-- unpack both X and dummy y\n",
    "        Xb = Xb.to(device)\n",
    "        nn_test_preds.extend(\n",
    "            torch.sigmoid(final_nn(Xb))\n",
    "                 .cpu()\n",
    "                 .numpy()\n",
    "        )\n",
    "nn_test_preds = np.array(nn_test_preds)\n",
    "\n",
    "print(\"NN preds:\", nn_test_preds.min(), nn_test_preds.max())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90180b4-66a8-435f-ad08-d1a9af7af2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 1) Get NN probabilities on the validation fold\n",
    "nn_val_probs = []\n",
    "final_nn.eval()\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in va_loader:\n",
    "        nn_val_probs.extend(\n",
    "            torch.sigmoid(final_nn(Xb.to(device)))\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "nn_val_probs = np.array(nn_val_probs)  # shape = (n_val,)\n",
    "\n",
    "# 2) Compute per-session NDCG@5\n",
    "ndcgs = []\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:\n",
    "        true_rels = y_val_nn[idx]\n",
    "        scores    = nn_val_probs[idx]\n",
    "        ndcgs.append(ndcg_score([true_rels], [scores], k=5))\n",
    "\n",
    "nn_val_ndcg5 = np.mean(ndcgs)\n",
    "print(f\"NN  Val NDCG@5: {nn_val_ndcg5:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af293dc-e382-4a3a-bee5-e767a32048c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# --- Ensemble the predictions ---\n",
    "ensemble_final_preds = ensemble_predictions(nn_test_preds, model_lgb_pred, weights=[0.5, 0.5]) # Adjust weights\n",
    "\n",
    "# Predict relevance scores for each test row\n",
    "preds_ens = ensemble_final_preds\n",
    "\n",
    "# Insert those scores into the sample submission DataFrame\n",
    "sample['score'] = preds_ens\n",
    "\n",
    "# Sort by search session (ascending) and score (descending)\n",
    "#   so that for each srch_id, the most relevant prop_id comes first\n",
    "submission = sample.sort_values(\n",
    "    ['srch_id', 'score'],\n",
    "    ascending=[True, False]\n",
    ")\n",
    "\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3c1e5-a601-4f56-b331-cfbce1e4753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 1) LightGBM val set predictions\n",
    "# Replace `model_lgb` with whatever variable you named your trained LightGBM model\n",
    "val_preds_lgb = model_lgb.predict(X_va)   # shape = (n_val,)\n",
    "\n",
    "# 2) NN val set predictions\n",
    "final_nn.eval()\n",
    "nn_val_preds = []\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in va_loader:  # va_loader from your NN split on X_va/y_va\n",
    "        nn_val_preds.extend(\n",
    "            torch.sigmoid(final_nn(Xb.to(device))).cpu().numpy()\n",
    "        )\n",
    "nn_val_preds = np.array(nn_val_preds)      # shape = (n_val,)\n",
    "\n",
    "# 3) Blend them\n",
    "w_nn, w_lgb = 0.4, 0.6\n",
    "ensemble_val = w_nn * nn_val_preds + w_lgb * val_preds_lgb\n",
    "\n",
    "\n",
    "ndcgs = []\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:\n",
    "        true_rel  = y_val_nn[idx]    # your val labels array\n",
    "        score_rel = ensemble_val[idx]\n",
    "        ndcgs.append(ndcg_score([true_rel], [score_rel], k=5))\n",
    "\n",
    "mean_ndcg5 = np.mean(ndcgs)\n",
    "print(f\"Ensembled Val NDCG@5: {mean_ndcg5:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35a973-a5cc-4f52-afb4-b8ae2f7b9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 1) Min–max scale each prediction array into [0,1]\n",
    "def minmax(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
    "\n",
    "nn_scaled  = minmax(nn_test_preds)\n",
    "lgb_scaled = minmax(model_lgb_pred)   # or whatever your LGB test‐preds variable is\n",
    "\n",
    "# 2) Do the two blends\n",
    "ens1 = ensemble_predictions(nn_scaled, lgb_scaled, [0.5, 0.5])\n",
    "ens2 = ensemble_predictions(nn_scaled, lgb_scaled, [0.0, 1.0])\n",
    "\n",
    "# 3) Compare their sorted‐order permutations\n",
    "order1 = np.argsort(ens1)\n",
    "order2 = np.argsort(ens2)\n",
    "\n",
    "# 4) Compute fraction of positions that differ\n",
    "fraction_changed = np.mean(order1 != order2)\n",
    "print(f\"Fraction of test‐rows whose position changes: {fraction_changed:.4%}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5d100-acc8-4754-9d9b-853cd760f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 0) Scale both NN & LGB validation predictions into [0,1]\n",
    "nn_scaled_val  = minmax_scale(nn_val_preds)      # shape = (n_val,)\n",
    "lgb_scaled_val = minmax_scale(val_preds_lgb)     # shape = (n_val,)\n",
    "\n",
    "best_w, best_score = None, 0.0\n",
    "for w_nn in np.linspace(0, 1, 11):\n",
    "    w_lgb = 1 - w_nn\n",
    "\n",
    "    # blended on the same [0,1] scale\n",
    "    blended = w_nn * nn_scaled_val + w_lgb * lgb_scaled_val\n",
    "\n",
    "    # compute NDCG@5 per session\n",
    "    ndcgs = []\n",
    "    for q in np.unique(id_va):\n",
    "        idx = np.where(id_va == q)[0]\n",
    "        if len(idx) > 1:\n",
    "            true   = y_val_nn[idx]\n",
    "            scores = blended[idx]\n",
    "            ndcgs.append(ndcg_score([true], [scores], k=5))\n",
    "    mean_ndcg = np.mean(ndcgs)\n",
    "\n",
    "    print(f\"w_nn={w_nn:.1f}, w_lgb={w_lgb:.1f} → Val NDCG@5: {mean_ndcg:.4f}\")\n",
    "    if mean_ndcg > best_score:\n",
    "        best_score, best_w = mean_ndcg, w_nn\n",
    "\n",
    "print(f\"\\n🏆 Best blend: w_nn={best_w:.2f}, w_lgb={1-best_w:.2f} → NDCG@5={best_score:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6eb97c-337e-4156-9a0c-0badb3dbabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df = sample[['srch_id']].copy()\n",
    "df['nn_rank']  = pd.DataFrame({'score': nn_test_preds,  'srch': sample['srch_id']}) \\\n",
    "                    .groupby('srch')['score'] \\\n",
    "                    .rank(method='dense', ascending=False)\n",
    "df['lgb_rank'] = pd.DataFrame({'score': model_lgb_pred,'srch': sample['srch_id']}) \\\n",
    "                    .groupby('srch')['score'] \\\n",
    "                    .rank(method='dense', ascending=False)\n",
    "\n",
    "# weighted rank\n",
    "w_nn, w_lgb = best_w, (1-best_w)\n",
    "df['ensemble_rank'] = w_nn * df['nn_rank'] + w_lgb * df['lgb_rank']\n",
    "\n",
    "# use that to sort\n",
    "submission = sample.assign(_rank=df['ensemble_rank']) \\\n",
    "    .sort_values(['srch_id','_rank'], ascending=[True,True]) \\\n",
    "    [['srch_id','prop_id']]\n",
    "\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7bccc1-01c7-405a-8e9f-913dc53fd5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df_sub = sample[['srch_id']].copy()\n",
    "df_sub['nn_rank']  = pd.Series(nn_test_preds).groupby(sample['srch_id']).rank(\"dense\", ascending=False)\n",
    "df_sub['lgb_rank'] = pd.Series(model_lgb_pred).groupby(sample['srch_id']).rank(\"dense\", ascending=False)\n",
    "\n",
    "# weighted rank blend\n",
    "df_sub['ensemble_rank'] = 0.2*df_sub['nn_rank'] + 0.8*df_sub['lgb_rank']\n",
    "\n",
    "submission = (\n",
    "    sample.assign(_rank=df_sub['ensemble_rank'])\n",
    "          .sort_values(['srch_id','_rank'], ascending=[True,True])\n",
    "          [['srch_id','prop_id']]\n",
    ")\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
