{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "ca254db0-81c6-46c4-a66e-9b7f66172755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score, roc_auc_score\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder,  minmax_scale\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GroupShuffleSplit\n",
    "import itertools\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from catboost import CatBoostRanker, Pool,  cv\n",
    "import optuna\n",
    "from optuna.integration import CatBoostPruningCallback\n",
    "from catboost.utils import eval_metric\n",
    "from optuna.pruners import SuccessiveHalvingPruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f7bcaa-d6d3-49c1-b9b0-5edec2d3a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the files changes path to where the data is stored\n",
    "test = pd.read_csv(r\"C:\\Users\\youpz\\Documents\\Master\\P5\\Data mining techniques\\Assignment2\\data\\dmt-2025-2nd-assignment\\test_set_VU_DM.csv\")\n",
    "train = pd.read_csv(r\"C:\\Users\\youpz\\Documents\\Master\\P5\\Data mining techniques\\Assignment2\\data\\dmt-2025-2nd-assignment\\training_set_VU_DM.csv\")\n",
    "sample = pd.read_csv(r\"C:\\Users\\youpz\\Documents\\Master\\P5\\Data mining techniques\\Assignment2\\data\\dmt-2025-2nd-assignment\\submission_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a5d234-6885-41df-bdf7-94794f3df4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "    \"\"\"Returns a DataFrame with missing counts and percent missing for each column.\"\"\"\n",
    "    n = len(df)\n",
    "    missing_count   = df.isna().sum()\n",
    "    missing_percent = 100 * missing_count / n\n",
    "    missing_df = (\n",
    "        pd.DataFrame({\n",
    "            'missing_count':   missing_count,\n",
    "            'missing_percent': missing_percent\n",
    "        })\n",
    "        .sort_values('missing_percent', ascending=False)\n",
    "    )\n",
    "    return missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0e5c47-2faf-4d18-9955-94abd8b44a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "comp3_rate                       3424059        69.056462\n",
      "comp3_inv                        3307357        66.702814\n",
      "comp8_rate                       3041693        61.344900\n",
      "comp8_inv                        2970844        59.916016\n",
      "comp2_rate                       2933675        59.166392\n",
      "comp2_inv                        2828078        57.036710\n",
      "comp5_rate                       2735974        55.179155\n",
      "comp5_inv                        2598327        52.403089\n",
      "orig_destination_distance        1607782        32.425766\n"
     ]
    }
   ],
   "source": [
    "mv = missing_values_table(train)\n",
    "print(mv.head(20))       # top 20 most‐missing columns\n",
    "# Or to filter down to “lots” of missing, say >30%:\n",
    "print(mv[mv['missing_percent'] > 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ea75187-7171-44a8-b8d1-ef210c3b2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## some beginning on the feature engineering\n",
    "def missing_values_table(df):\n",
    "    \"\"\"Returns a DataFrame with missing counts and percent missing for each column.\"\"\"\n",
    "    n = len(df)\n",
    "    missing_count   = df.isna().sum()\n",
    "    missing_percent = 100 * missing_count / n\n",
    "    missing_df = (\n",
    "        pd.DataFrame({\n",
    "            'missing_count':   missing_count,\n",
    "            'missing_percent': missing_percent\n",
    "        })\n",
    "        .sort_values('missing_percent', ascending=False)\n",
    "    )\n",
    "    return missing_df\n",
    "    \n",
    "def preprocess_missing_and_competitors(train_df, test_df):\n",
    "    # 1) Drop features with >93% missing or that leak the target\n",
    "    drop_cols = [\n",
    "        # competitor 1,4,6,7 are ~97–98% missing → too sparse to learn\n",
    "        *[f'comp{i}_{t}' for i in [1,4,6,7] for t in ['rate','inv','rate_percent_diff']],\n",
    "        'gross_bookings_usd'  # only in train, leaks booking price\n",
    "    ]\n",
    "    train_df.drop(columns=drop_cols, errors='ignore', inplace=True)\n",
    "    test_df.drop(columns=drop_cols, errors='ignore', inplace=True)\n",
    "\n",
    "    # 2) Impute & flag user history features\n",
    "    #    Missing means “no prior purchases” → keep with sentinel + flag\n",
    "    for df in (train_df, test_df):\n",
    "        # visitor_hist_starrating\n",
    "        df['hist_star_na'] = df['visitor_hist_starrating'].isna().astype(int)\n",
    "        # fill with median starrating across users\n",
    "        star_med = train_df['visitor_hist_starrating'].median()\n",
    "        df['visitor_hist_starrating'] = df['visitor_hist_starrating'].fillna(star_med)\n",
    "\n",
    "        # visitor_hist_adr_usd (avg USD spend)\n",
    "        df['hist_adr_na'] = df['visitor_hist_adr_usd'].isna().astype(int)\n",
    "        adr_med = train_df['visitor_hist_adr_usd'].median()\n",
    "        df['visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].fillna(adr_med)\n",
    "\n",
    "    # 3) Impute & flag affinity score\n",
    "    #    Null means “hotel never seen” → fill with global minimum and flag\n",
    "    affinity_min = train_df['srch_query_affinity_score'].min(skipna=True)\n",
    "    for df in (train_df, test_df):\n",
    "        df['affinity_na'] = df['srch_query_affinity_score'].isna().astype(int)\n",
    "        df['srch_query_affinity_score'] = (\n",
    "            df['srch_query_affinity_score']\n",
    "            .fillna(affinity_min)\n",
    "        )\n",
    "\n",
    "    # 4) Keep & impute competitor 2,3,5,8 features (~50–90% missing)\n",
    "    #    Null → “no data” sentinel (for categorical) or 0 (for percent diff), plus flag\n",
    "    keep_comps = [2,3,5,8]\n",
    "    for i in keep_comps:\n",
    "        # availability flag\n",
    "        inv_col = f'comp{i}_inv'\n",
    "        flag_col = f'comp{i}_inv_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[flag_col] = df[inv_col].isna().astype(int)\n",
    "            # fill null with 2 (new category: 0=no avail,1=avail,2=no data)\n",
    "            df[inv_col] = df[inv_col].fillna(2).astype(int)\n",
    "\n",
    "        # price‐compare flag\n",
    "        rate_col = f'comp{i}_rate'\n",
    "        rate_flag = f'comp{i}_rate_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[rate_flag] = df[rate_col].isna().astype(int)\n",
    "            # fill null as “no data” = 2\n",
    "            df[rate_col] = df[rate_col].fillna(2).astype(int)\n",
    "\n",
    "        # percent_diff\n",
    "        pdiff_col = f'comp{i}_rate_percent_diff'\n",
    "        pdiff_flag = f'comp{i}_pdiff_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[pdiff_flag] = df[pdiff_col].isna().astype(int)\n",
    "            # fill null as 0% diff (no info)\n",
    "            df[pdiff_col] = df[pdiff_col].fillna(0.0)\n",
    "\n",
    "    # 5) Bucket orig_destination_distance\n",
    "    #    Missing → sentinel bucket + flag\n",
    "    for df in (train_df, test_df):\n",
    "        df['dist_na'] = df['orig_destination_distance'].isna().astype(int)\n",
    "        df['orig_destination_distance'] = (\n",
    "            df['orig_destination_distance'].fillna(-1)\n",
    "        )\n",
    "        # define bins (in km)\n",
    "        bins = [-1, 0, 10, 50, 200, np.inf]\n",
    "        labels = ['missing','0-10km','10-50km','50-200km','200km+']\n",
    "        df['dist_bucket'] = pd.cut(\n",
    "            df['orig_destination_distance'],\n",
    "            bins=bins, labels=labels\n",
    "        )\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def create_base_features(df):\n",
    "    \"\"\"1) Parse datetime & basic price/historical features.\"\"\"\n",
    "    df = df.copy()\n",
    "    # --- Date/time splits ---\n",
    "    df['date_time']   = pd.to_datetime(df['date_time'])\n",
    "    df['search_year'] = df['date_time'].dt.year\n",
    "    df['search_month']= df['date_time'].dt.month\n",
    "    df['search_day']  = df['date_time'].dt.day\n",
    "    df['search_hour'] = df['date_time'].dt.hour\n",
    "\n",
    "    # --- Price per night & hist price devation ---\n",
    "    df['price_per_night'] = df['price_usd'] / df['srch_length_of_stay']\n",
    "    df['price_vs_historical'] = df['price_usd'] - df['prop_log_historical_price']\n",
    "    df['price_vs_historical'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_destination_stats(train_df, test_df):\n",
    "    \"\"\"6) Dest‑level total searches & booking rate.\"\"\"\n",
    "    dest = (\n",
    "        train_df\n",
    "        .groupby('srch_destination_id')\n",
    "        .agg(dest_searches=('srch_id','count'),\n",
    "             dest_bookings=('booking_bool','sum'))\n",
    "        .assign(dest_booking_rate=lambda x: x.dest_bookings / x.dest_searches)\n",
    "        .reset_index()\n",
    "    )\n",
    "    # Reassign merge result back to each DataFrame\n",
    "    train_df = train_df.merge(\n",
    "        dest[['srch_destination_id','dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "    test_df = test_df.merge(\n",
    "        dest[['srch_destination_id','dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "    return train_df, test_df\n",
    "\n",
    "def add_within_search_features(df):\n",
    "    \"\"\"7) Z‑scores & deltas in each search group.\"\"\"\n",
    "    grp = df.groupby('srch_id')\n",
    "    # price\n",
    "    df['price_mean_srch'] = grp['price_usd'].transform('mean')\n",
    "    df['price_std_srch']  = grp['price_usd'].transform('std').fillna(1)\n",
    "    df['price_zscore']    = (df['price_usd'] - df['price_mean_srch']) / df['price_std_srch']\n",
    "    # stars\n",
    "    df['star_mean_srch']  = grp['prop_starrating'].transform('mean')\n",
    "    df['star_delta_srch'] = df['prop_starrating'] - df['star_mean_srch']\n",
    "    # user delta\n",
    "    df['star_delta_user'] = df['prop_starrating'] - df['visitor_hist_starrating']\n",
    "    # distance\n",
    "    df['dist_mean_srch']  = grp['orig_destination_distance'].transform('mean')\n",
    "    df['dist_std_srch']   = grp['orig_destination_distance'].transform('std').fillna(1)\n",
    "    df['dist_zscore']     = (df['orig_destination_distance'] - df['dist_mean_srch']) / df['dist_std_srch']\n",
    "    return df\n",
    "\n",
    "def add_temporal_features(df):\n",
    "    \"\"\"8) Weekday/weekend & check‑in weekend flags.\"\"\"\n",
    "    # day‑of‑week for search\n",
    "    df['search_dow'] = df['date_time'].dt.weekday  # 0=Mon…6=Sun\n",
    "    df['is_search_weekend'] = df['search_dow'].isin([5,6]).astype(int)\n",
    "    # approximate check‑in day\n",
    "    checkin = df['date_time'] + pd.to_timedelta(df['srch_booking_window'], 'D')\n",
    "    df['checkin_dow'] = checkin.dt.weekday\n",
    "    df['is_checkin_weekend'] = df['checkin_dow'].isin([5,6]).astype(int)\n",
    "    return df\n",
    "\n",
    "def add_ranks(df):\n",
    "    \"\"\"9) Dense ranks of price, star & distance within each search.\"\"\"\n",
    "    df['price_rank'] = df.groupby('srch_id')['price_usd'].rank('dense', ascending=True)\n",
    "    df['star_rank']  = df.groupby('srch_id')['prop_starrating'].rank('dense', ascending=False)\n",
    "    df['dist_rank']  = df.groupby('srch_id')['orig_destination_distance'].rank('dense', ascending=True)\n",
    "    return df\n",
    "\n",
    "def one_hot_encode_columns(train_df, test_df, columns_to_encode):\n",
    "    \"\"\"\n",
    "    Converts specified string columns in train and test DataFrames to one-hot encoded features.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): The training DataFrame.\n",
    "        test_df (pd.DataFrame): The testing DataFrame.\n",
    "        columns_to_encode (list): A list of column names (strings) to be one-hot encoded.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the modified training and testing DataFrames with one-hot encoded columns.\n",
    "    \"\"\"\n",
    "    train_processed = train_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "\n",
    "    for col in columns_to_encode:\n",
    "        if col in train_processed.columns and col in test_processed.columns:\n",
    "            # Get unique values from both train and test to ensure consistent encoding\n",
    "            all_unique_values = pd.concat([train_processed[col], test_processed[col]]).unique()\n",
    "\n",
    "            for value in all_unique_values:\n",
    "                train_processed[f'{col}_{value}'] = (train_processed[col] == value).astype(int)\n",
    "                test_processed[f'{col}_{value}'] = (test_processed[col] == value).astype(int)\n",
    "\n",
    "            # Drop the original categorical column\n",
    "            train_processed.drop(columns=[col], inplace=True)\n",
    "            test_processed.drop(columns=[col], inplace=True)\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in both train and test DataFrames. Skipping one-hot encoding for this column.\")\n",
    "\n",
    "    return train_processed, test_processed\n",
    "\n",
    "def minmax(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
    "\n",
    "def ensemble_predictions(pred1, pred2, weights):\n",
    "    w1, w2 = weights\n",
    "    return w1 * minmax(pred1) + w2 * minmax(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fb187d0-fb92-49dc-8060-582ebf758368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "comp3_rate                       3424059        69.056462\n",
      "comp3_inv                        3307357        66.702814\n",
      "comp8_rate                       3041693        61.344900\n",
      "comp8_inv                        2970844        59.916016\n",
      "comp2_rate                       2933675        59.166392\n",
      "comp2_inv                        2828078        57.036710\n",
      "comp5_rate                       2735974        55.179155\n",
      "comp5_inv                        2598327        52.403089\n",
      "orig_destination_distance        1607782        32.425766\n"
     ]
    }
   ],
   "source": [
    "mv = missing_values_table(train)\n",
    "print(mv.head(20))       # top 20 most‐missing columns\n",
    "# Or to filter down to “lots” of missing, say >30%:\n",
    "print(mv[mv['missing_percent'] > 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c61caaa-a280-4550-9d46-386e8a6fe5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Define target\n",
    "y = train['booking_bool'] * 5 + train['click_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a047e5cd-ba9a-4b40-aa65-c65964f8abc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_38332\\274394517.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_38332\\274394517.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 1) Feature‐Engineering Pipeline\n",
    "train_feat, test_feat = train.copy(), test.copy()\n",
    "steps = [\n",
    "    preprocess_missing_and_competitors,\n",
    "    add_destination_stats,\n",
    "    lambda tr, te: one_hot_encode_columns(tr, te, ['dist_bucket']),\n",
    "    lambda tr, te: (create_base_features(tr), create_base_features(te)),\n",
    "    lambda tr, te: (add_within_search_features(tr), add_within_search_features(te)),\n",
    "    lambda tr, te: (add_temporal_features(tr), add_temporal_features(te)),\n",
    "    lambda tr, te: (add_ranks(tr), add_ranks(te)),\n",
    "]\n",
    "for fn in steps:\n",
    "    train_feat, test_feat = fn(train_feat, test_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "48198da9-b7e9-4f8a-9a23-a189962f4003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_38332\\338084407.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_38332\\338084407.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(med, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_38332\\338084407.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col].fillna(med, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_38332\\338084407.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(med, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_38332\\338084407.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col].fillna(med, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 2) Train/Validation Split + Preprocessing\n",
    "\n",
    "\n",
    "# a) split on search IDs\n",
    "train_ids, valid_ids = train_test_split(\n",
    "    train_feat['srch_id'].unique(), \n",
    "    test_size=0.2, \n",
    "    random_state=22\n",
    ")\n",
    "mask_tr   = train_feat['srch_id'].isin(train_ids)\n",
    "mask_va   = ~mask_tr\n",
    "mask_full = mask_tr | mask_va  # full = all rows\n",
    "\n",
    "# b) pick your features\n",
    "drop = ['date_time','gross_bookings_usd','position',\n",
    "        'click_bool','booking_bool','srch_id','prop_id']\n",
    "features = [c for c in train_feat.columns if c not in drop]\n",
    "\n",
    "# c) pull out X, y\n",
    "X       = train_feat[features]\n",
    "X_test  = test_feat[features]\n",
    "y       = train['booking_bool'] * 5 + train['click_bool']  # as before\n",
    "\n",
    "# d) replace infinities/nans by train median\n",
    "for df in (X, X_test):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "for col in features:\n",
    "    med = X[col].median()\n",
    "    X[col].fillna(med, inplace=True)\n",
    "    X_test[col].fillna(med, inplace=True)\n",
    "\n",
    "# e) scale\n",
    "scaler = StandardScaler()\n",
    "X_tr    = scaler.fit_transform(X[mask_tr])\n",
    "X_va    = scaler.transform(X[mask_va])\n",
    "X_full  = scaler.transform(X)         # entire dataset\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "y_tr    = y[mask_tr].values\n",
    "y_va    = y[mask_va].values\n",
    "y_full  = y.values                     # entire dataset\n",
    "\n",
    "# 3) Build grouping arrays / session‐ids\n",
    "id_tr   = train_feat.loc[mask_tr, 'srch_id'].values\n",
    "id_va   = train_feat.loc[mask_va, 'srch_id'].values\n",
    "id_full = train_feat['srch_id'].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d73440b2-67ca-47db-b4b7-c52a95efb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_full = train_feat['srch_id'].groupby(train_feat['srch_id']).transform('size').values\n",
    "# But LightGBM wants the sizes *per group*, not per row, so:\n",
    "grp_full = train_feat['srch_id'].value_counts(sort=False).values\n",
    "\n",
    "# 2) Create the full‐data LGB Dataset\n",
    "lgb_full  = lgb.Dataset(X_full, label=y_full, group=grp_full)\n",
    "\n",
    "# 3) You already computed grp_tr and grp_va earlier:\n",
    "#    grp_tr = train_feat.loc[mask_tr, 'srch_id'].value_counts(sort=False).values\n",
    "#    grp_va = train_feat.loc[mask_va, 'srch_id'].value_counts(sort=False).values\n",
    "\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr, group=grp_tr)\n",
    "lgb_val   = lgb.Dataset(X_va, label=y_va, group=grp_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a7b7b589-6888-460b-ad4a-d5a2aac5aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Build grouping arrays\n",
    "\n",
    "train_pool = Pool(X_tr,   label=y_tr,   group_id=id_tr)\n",
    "val_pool   = Pool(X_va,   label=y_va,   group_id=id_va)\n",
    "full_pool  = Pool(X_full, label=y_full, group_id=id_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "0ec2bd5f-1730-4666-85f7-3952157d51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Define your search space\n",
    "\n",
    "param_dist = {\n",
    "    'learning_rate':    [0.005, 0.01, 0.02, 0.05],\n",
    "    'num_leaves':       [64, 128, 256],\n",
    "    'min_data_in_leaf': [10, 30, 50, 100],\n",
    "    'feature_fraction': [0.6, 0.8, 1.0],\n",
    "    'bagging_fraction': [0.6, 0.8, 1.0],\n",
    "    'bagging_freq':     [0, 5, 10],\n",
    "}\n",
    "\n",
    "n_iter = 12\n",
    "best_score, score = 0,0\n",
    "best_params,params = None,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673066f0-78f5-4834-ace3-a35f4110ea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.746426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6873\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 79\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    }
   ],
   "source": [
    "# 1) Your random search stays the same…\n",
    "for i in range(1, n_iter + 1):\n",
    "    print(i)\n",
    "    params = {\n",
    "        'objective':    'lambdarank',\n",
    "        'metric':       'ndcg',\n",
    "        'ndcg_eval_at': [5],\n",
    "        'verbose':      1,\n",
    "        **{k: np.random.choice(v) for k, v in param_dist.items()},\n",
    "        }\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set=lgb_train,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=lgb_val,\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    "    )\n",
    "    \n",
    "    score = model.best_score['valid']['ndcg@5']\n",
    "    print(f\"    → ndcg@5 = {score:.4f}, rounds = {model.best_iteration}\")\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score_ = score\n",
    "        best_params = params.copy()\n",
    "        best_iter =  model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f335fe-beb9-44c9-a698-c4a8dd99de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_score, best_params, best_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf22fe9-054d-4f3b-a757-a40119664b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Retrain on all data\n",
    "model_lgb_full = lgb.train(\n",
    "    best_params,\n",
    "    lgb_full,\n",
    "    num_boost_round=best_iter # can still be ajdusted to best best_iter\n",
    ")\n",
    "\n",
    "# 4) Predict on test\n",
    "lgb_test_preds = model_lgb_full.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9c4afe9f-c8cb-46c4-a86b-c567a7e81a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 09:46:28,628] A new study created in memory with name: catboost_yetirank\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_38332\\353303195.py:22: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  pruning_callback = CatBoostPruningCallback(trial, 'NDCG:top=5;type=Base')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.2745117\tbest: 0.2745117 (0)\ttotal: 1.57s\tremaining: 13m 5s\n",
      "100:\ttest: 0.3755858\tbest: 0.3755858 (100)\ttotal: 2m 23s\tremaining: 9m 25s\n",
      "200:\ttest: 0.3815620\tbest: 0.3816237 (199)\ttotal: 4m 40s\tremaining: 6m 56s\n",
      "300:\ttest: 0.3846451\tbest: 0.3847438 (296)\ttotal: 6m 57s\tremaining: 4m 36s\n",
      "400:\ttest: 0.3871070\tbest: 0.3871317 (396)\ttotal: 9m 17s\tremaining: 2m 17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 09:58:05,659] Trial 0 finished with value: 0.3881653609707162 and parameters: {'learning_rate': 0.09740586328756352, 'depth': 7, 'l2_leaf_reg': 0.03630015832989499, 'random_strength': 0.06674037741683808, 'bagging_temperature': 0.19219489235992915, 'border_count': 151}. Best is trial 0 with value: 0.3881653609707162.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\ttest: 0.3880986\tbest: 0.3881654 (485)\ttotal: 11m 34s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.388165361\n",
      "bestIteration = 485\n",
      "\n",
      "Shrink model to first 486 iterations.\n",
      "0:\ttest: 0.2858194\tbest: 0.2858194 (0)\ttotal: 1.66s\tremaining: 13m 46s\n",
      "100:\ttest: 0.3555800\tbest: 0.3555800 (100)\ttotal: 2m 34s\tremaining: 10m 8s\n",
      "200:\ttest: 0.3655050\tbest: 0.3655316 (199)\ttotal: 5m 4s\tremaining: 7m 33s\n",
      "300:\ttest: 0.3703105\tbest: 0.3703279 (299)\ttotal: 7m 35s\tremaining: 5m 1s\n",
      "400:\ttest: 0.3738567\tbest: 0.3738567 (400)\ttotal: 10m 6s\tremaining: 2m 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 10:10:39,337] Trial 1 finished with value: 0.375974008872716 and parameters: {'learning_rate': 0.014778139038873775, 'depth': 9, 'l2_leaf_reg': 0.014475747766503332, 'random_strength': 0.15764221966716066, 'bagging_temperature': 0.9774795280205144, 'border_count': 177}. Best is trial 0 with value: 0.3881653609707162.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\ttest: 0.3759477\tbest: 0.3759740 (494)\ttotal: 12m 31s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3759740089\n",
      "bestIteration = 494\n",
      "\n",
      "Shrink model to first 495 iterations.\n",
      "0:\ttest: 0.2950750\tbest: 0.2950750 (0)\ttotal: 2.43s\tremaining: 20m 13s\n",
      "100:\ttest: 0.3627879\tbest: 0.3627879 (100)\ttotal: 4m 8s\tremaining: 16m 21s\n",
      "200:\ttest: 0.3706162\tbest: 0.3706162 (200)\ttotal: 8m 4s\tremaining: 12m 1s\n",
      "300:\ttest: 0.3753733\tbest: 0.3754023 (291)\ttotal: 12m 6s\tremaining: 8m\n",
      "400:\ttest: 0.3778610\tbest: 0.3779310 (397)\ttotal: 16m 8s\tremaining: 3m 58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 10:30:48,701] Trial 2 finished with value: 0.38011017478259085 and parameters: {'learning_rate': 0.01981468519150568, 'depth': 12, 'l2_leaf_reg': 4.793812156448901, 'random_strength': 0.044442677514211125, 'bagging_temperature': 0.3266619382180912, 'border_count': 88}. Best is trial 0 with value: 0.3881653609707162.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\ttest: 0.3800321\tbest: 0.3801102 (495)\ttotal: 20m 6s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3801101748\n",
      "bestIteration = 495\n",
      "\n",
      "Shrink model to first 496 iterations.\n",
      "0:\ttest: 0.2788806\tbest: 0.2788806 (0)\ttotal: 1.62s\tremaining: 13m 28s\n",
      "100:\ttest: 0.3526806\tbest: 0.3526806 (100)\ttotal: 2m 34s\tremaining: 10m 9s\n",
      "200:\ttest: 0.3631007\tbest: 0.3631007 (200)\ttotal: 5m\tremaining: 7m 26s\n",
      "300:\ttest: 0.3679322\tbest: 0.3679322 (300)\ttotal: 7m 26s\tremaining: 4m 55s\n",
      "400:\ttest: 0.3714569\tbest: 0.3715255 (399)\ttotal: 9m 51s\tremaining: 2m 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-14 10:43:10,991] Trial 3 finished with value: 0.3741724877579421 and parameters: {'learning_rate': 0.01354025164736317, 'depth': 8, 'l2_leaf_reg': 0.013866370771875802, 'random_strength': 0.6302428378092374, 'bagging_temperature': 0.7407663751603011, 'border_count': 138}. Best is trial 0 with value: 0.3881653609707162.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\ttest: 0.3741725\tbest: 0.3741725 (499)\ttotal: 12m 19s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3741724878\n",
      "bestIteration = 499\n",
      "\n",
      "Best PFound: 0.3881653609707162\n",
      "Best hyperparameters:\n",
      "  learning_rate: 0.09740586328756352\n",
      "  depth: 7\n",
      "  l2_leaf_reg: 0.03630015832989499\n",
      "  random_strength: 0.06674037741683808\n",
      "  bagging_temperature: 0.19219489235992915\n",
      "  border_count: 151\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params_cat = {\n",
    "        'loss_function': 'YetiRank',\n",
    "        'eval_metric': 'NDCG:top=5',\n",
    "        'random_seed': 22,\n",
    "        'od_type': 'Iter',\n",
    "        'od_wait': 20,\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int(\"depth\", 6, 12),\n",
    "        'l2_leaf_reg': trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10.0, log=True),\n",
    "        'random_strength': trial.suggest_float(\"random_strength\", 1e-3, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "        'border_count': trial.suggest_int(\"border_count\", 32, 255),\n",
    "        'iterations': 400,\n",
    "        'use_best_model': True,\n",
    "        'verbose': 100,\n",
    "    }\n",
    "\n",
    "    model_cat = CatBoostRanker(**params_cat)\n",
    "\n",
    "    # Pruner callback for PFound\n",
    "    pruning_callback = CatBoostPruningCallback(trial, 'NDCG:top=5;type=Base')\n",
    "\n",
    "\n",
    "    model_cat.fit(\n",
    "        train_pool,\n",
    "        eval_set=val_pool,\n",
    "        early_stopping_rounds=50,\n",
    "        callbacks=[pruning_callback],\n",
    "    )\n",
    "\n",
    "    # Manually trigger pruning\n",
    "    pruning_callback.check_pruned()\n",
    "\n",
    "     # 5) Grab the best‐iteration score\n",
    "    hist = model_cat.get_evals_result()['validation']['NDCG:top=5;type=Base']\n",
    "    return max(hist) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"catboost_yetirank\",\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    ")\n",
    "study.optimize(objective, n_trials=50, timeout=7200)\n",
    "\n",
    "print(f\"Best PFound: {study.best_trial.value}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for k, v in study.best_trial.params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "73774e92-d62b-494c-bcc4-4a71b6d2ed26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "  learning_rate: 0.09740586328756352\n",
      "  depth: 7\n",
      "  l2_leaf_reg: 0.03630015832989499\n",
      "  random_strength: 0.06674037741683808\n",
      "  bagging_temperature: 0.19219489235992915\n",
      "  border_count: 151\n",
      "0:\ttotal: 2.03s\tremaining: 33m 52s\n",
      "100:\ttotal: 2m 55s\tremaining: 26m 4s\n",
      "200:\ttotal: 5m 45s\tremaining: 22m 54s\n",
      "300:\ttotal: 8m 36s\tremaining: 19m 58s\n",
      "400:\ttotal: 11m 31s\tremaining: 17m 12s\n",
      "500:\ttotal: 14m 21s\tremaining: 14m 18s\n",
      "600:\ttotal: 17m 26s\tremaining: 11m 35s\n",
      "700:\ttotal: 20m 14s\tremaining: 8m 38s\n",
      "800:\ttotal: 23m 2s\tremaining: 5m 43s\n",
      "900:\ttotal: 25m 52s\tremaining: 2m 50s\n",
      "999:\ttotal: 28m 38s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_params_cat = study.best_trial.params # Corrected line\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in best_params_cat.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "final_params_cat= {**best_params_cat, 'iterations': 1000, 'verbose': 100} #added verbose\n",
    "final_cat = CatBoostRanker(**final_params_cat)\n",
    "final_cat.fit(\n",
    "    full_pool,\n",
    "    early_stopping_rounds=100\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "48302777-0194-4965-a7c3-e1d508ec1a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Predict on test set\n",
    "cat_test_preds = final_cat.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "79ada07e-f959-4685-9006-2d37dbcd7a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv written using CatBoost only!\n"
     ]
    }
   ],
   "source": [
    "# 2) Put them into your submission\n",
    "sample['score'] = cat_test_preds\n",
    "submission = (\n",
    "    sample\n",
    "    .sort_values(['srch_id', 'score'], ascending=[True, False])\n",
    "    [['srch_id', 'prop_id']]\n",
    ")\n",
    "\n",
    "# 3) Write to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission.csv written using CatBoost only!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd28c4-fd34-4622-b6ef-0b93c42f8670",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"params = {\n",
    "    'loss_function':       'YetiRank',\n",
    "    'eval_metric':         'NDCG:top=5',\n",
    "    'random_seed':         22,\n",
    "    'od_type':             'Iter',\n",
    "    'od_wait':             20,\n",
    "    'learning_rate':       0.05,\n",
    "    'depth':               8,\n",
    "    'l2_leaf_reg':         3.0,\n",
    "    'random_strength':     1.0,\n",
    "    'bagging_temperature': 0.2,\n",
    "    'border_count':        128,\n",
    "    'iterations':          1000,\n",
    "    'use_best_model':      True,\n",
    "    'verbose':             100,\n",
    "}\n",
    "\n",
    "# 3) Train\n",
    "model = CatBoostRanker(**params)\n",
    "model.fit(\n",
    "    train_pool,\n",
    "    eval_set=val_pool,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=False,            # or True to see each iteration\n",
    "    verbose_eval=100,         # log every 100 iters\n",
    ")\n",
    "\n",
    "# 4) Best iteration\n",
    "best_iter = model.get_best_iteration()\n",
    "print(\"Best iteration:\", best_iter)\n",
    "\n",
    "# 5) Validation NDCG@5 history\n",
    "ndcg_history = model.get_evals_result()['validation']['NDCG:top=5;type=Base']\n",
    "print(f\"Validation NDCG@5 @ best_iter: {ndcg_history[best_iter]:.4f}\")\n",
    "\n",
    "# 6) Retrain on full data if desired\n",
    "# full_pool = Pool(X_full, label=y_full, group_id=id_full)\n",
    "# model_full = CatBoostRanker(**params)\n",
    "# model_full.fit(full_pool, use_best_model=True)\n",
    "\n",
    "# 7) Predict on test\n",
    "# test_pool = Pool(X_test)  # note: no label needed\n",
    "# test_preds = model_full.predict(test_pool)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "3eb20bf6-7ab7-4a2c-9572-727a7e61005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost Val NDCG@5: 0.4141\n",
      "\n",
      "LightGBM Val NDCG@5: 0.1669\n"
     ]
    }
   ],
   "source": [
    "# 1. Predict raw scores for the validation set\n",
    "cat_val_preds = final_cat.predict(X_va)\n",
    "lgb_val_preds = model_lgb_full.predict(X_va, num_iteration=best_it)\n",
    "\n",
    "# 2. Compute per-session NDCG@5 manually\n",
    "ndcgs_cat = []\n",
    "ndcgs_lgb = []\n",
    "\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:  # skip sessions with only 1 result\n",
    "        true_rels = y_va[idx]\n",
    "        ndcgs_cat.append(ndcg_score([true_rels], [cat_val_preds[idx]], k=5))\n",
    "        ndcgs_lgb.append(ndcg_score([true_rels], [lgb_val_preds[idx]], k=5))\n",
    "\n",
    "# 3. Average NDCG@5 for both models\n",
    "catboost_ndcg5 = np.mean(ndcgs_cat)\n",
    "lgb_ndcg5 = np.mean(ndcgs_lgb)\n",
    "\n",
    "print(f\"\\nCatBoost Val NDCG@5: {catboost_ndcg5:.4f}\")\n",
    "print(f\"\\nLightGBM Val NDCG@5: {lgb_ndcg5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "6991fd44-41cb-4f3c-8643-bb5f041603a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_cb=0.0, w_lgb=1.0 → Val NDCG@5: 0.1669\n",
      "w_cb=0.1, w_lgb=0.9 → Val NDCG@5: 0.2117\n",
      "w_cb=0.2, w_lgb=0.8 → Val NDCG@5: 0.2422\n",
      "w_cb=0.3, w_lgb=0.7 → Val NDCG@5: 0.2670\n",
      "w_cb=0.4, w_lgb=0.6 → Val NDCG@5: 0.2924\n",
      "w_cb=0.5, w_lgb=0.5 → Val NDCG@5: 0.3206\n",
      "w_cb=0.6, w_lgb=0.4 → Val NDCG@5: 0.3515\n",
      "w_cb=0.7, w_lgb=0.3 → Val NDCG@5: 0.3788\n",
      "w_cb=0.8, w_lgb=0.2 → Val NDCG@5: 0.3982\n",
      "w_cb=0.9, w_lgb=0.1 → Val NDCG@5: 0.4113\n",
      "w_cb=1.0, w_lgb=0.0 → Val NDCG@5: 0.4141\n",
      "\n",
      " Best blend (CB+LGB): w_cb=1.00, w_lgb=0.00 → NDCG@5=0.4141\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1) Scale just your two tree-based model preds on validation\n",
    "cb_s  = minmax(cat_val_preds)   # your CatBoost val preds\n",
    "lgb_s = minmax(lgb_val_preds)   # your LightGBM val preds\n",
    "\n",
    "# 2) Sweep over blends of just CB + LGB\n",
    "best, best_w = 0, None\n",
    "for w_cb in np.linspace(0, 1, 11):\n",
    "    w_lgb = 1 - w_cb\n",
    "    sc = w_cb * cb_s + w_lgb * lgb_s\n",
    "\n",
    "    # compute NDCG@5 on val\n",
    "    ndcgs = []\n",
    "    for q in np.unique(id_va):\n",
    "        idx = np.where(id_va == q)[0]\n",
    "        if len(idx) > 1:\n",
    "            true = y_va[idx]\n",
    "            ndcgs.append(ndcg_score([true], [sc[idx]], k=5))\n",
    "    mean_ndcg = np.mean(ndcgs)\n",
    "\n",
    "    print(f\"w_cb={w_cb:.1f}, w_lgb={w_lgb:.1f} → Val NDCG@5: {mean_ndcg:.4f}\")\n",
    "    if mean_ndcg > best:\n",
    "        best, best_w = mean_ndcg, (w_cb, w_lgb)\n",
    "\n",
    "print(f\"\\n Best blend (CB+LGB): w_cb={best_w[0]:.2f}, w_lgb={best_w[1]:.2f} → NDCG@5={best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "30e54659-6f48-4d9e-94ac-fecb7f8d15cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission.csv written using w_cb=0.50, w_lgb=0.50!\n"
     ]
    }
   ],
   "source": [
    "# --- Ensemble the test predictions with your optimal blend ---\n",
    "best_w = [0.5,0.5]\n",
    "\n",
    "ensemble_final_preds = ensemble_predictions(\n",
    "    cat_test_preds,\n",
    "    lgb_test_preds,\n",
    "    weights=[best_w[0], best_w[1]]\n",
    ")\n",
    "\n",
    "# Put them into submission\n",
    "sample['score'] = ensemble_final_preds\n",
    "submission = (\n",
    "    sample\n",
    "    .sort_values(['srch_id','score'], ascending=[True, False])\n",
    "    [['srch_id','prop_id']]\n",
    ")\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission.csv written using w_cb={best_w[0]:.2f}, w_lgb={best_w[1]:.2f}!\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ccd16-188e-40cc-8d80-e176c305925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# --- 1) ListNet loss (unchanged) ---\n",
    "def listnet_loss(scores, labels, group_ids):\n",
    "    loss, count = 0.0, 0\n",
    "    for q in np.unique(group_ids):\n",
    "        idx = np.where(group_ids == q)[0]\n",
    "        if len(idx) < 2:\n",
    "            continue\n",
    "        s_q, y_q = scores[idx], labels[idx].float()\n",
    "        P, P_hat = torch.softmax(y_q, 0), torch.softmax(s_q, 0)\n",
    "        loss += -torch.sum(P * torch.log(P_hat + 1e-8))\n",
    "        count += 1\n",
    "    return loss / max(count, 1)\n",
    "\n",
    "param_grid = {\n",
    "    'lr':           [1e-3, 2e-3],\n",
    "    'batch_size':   [512, 1024],\n",
    "    'dropout':      [0.1, 0.2],\n",
    "    'weight_decay': [0.0, 1e-4]\n",
    "}\n",
    "\n",
    "best = {'ndcg': 0.0, 'cfg': None}\n",
    "\n",
    "for lr, bs, drop, wd in itertools.product(*param_grid.values()):\n",
    "    tr_loader = DataLoader(ExpediaDataset(X_tr, y_tr.values),\n",
    "                           batch_size=bs, shuffle=True)\n",
    "    va_loader = DataLoader(ExpediaDataset(X_va, y_va.values),\n",
    "                           batch_size=bs, shuffle=False)\n",
    "\n",
    "    mdl = DeepRecommender(X_tr.shape[1]).to(device)\n",
    "    for m in mdl.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.p = drop\n",
    "\n",
    "    opt = torch.optim.Adam(\n",
    "        mdl.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=wd\n",
    "    )\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt,\n",
    "        max_lr=lr * 10,\n",
    "        steps_per_epoch=len(tr_loader),\n",
    "        epochs=10\n",
    "    )\n",
    "\n",
    "    best_ndcg, stale = 0.0, 0\n",
    "    for epoch in range(1, 8):\n",
    "        # — train —\n",
    "        mdl.train()\n",
    "        for Xb, yb in tr_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = listnet_loss(mdl(Xb), yb, id_tr[:len(Xb)])\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        # — validate —\n",
    "        mdl.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for Xb, _ in va_loader:\n",
    "                preds.extend(mdl(Xb.to(device)).cpu().numpy())\n",
    "        preds = np.array(preds)\n",
    "\n",
    "        # compute mean NDCG@5 using the same y_va array\n",
    "        ndcgs = []\n",
    "        for q in np.unique(id_va):\n",
    "            idx = np.where(id_va == q)[0]\n",
    "            if len(idx) > 1:\n",
    "                true = y_va.values[idx]\n",
    "                score = preds[idx]\n",
    "                ndcgs.append(ndcg_score([true], [score], k=5))\n",
    "        mean_ndcg = np.mean(ndcgs)\n",
    "        sched.step(mean_ndcg)\n",
    "\n",
    "        if mean_ndcg > best_ndcg + 1e-4:\n",
    "            best_ndcg, stale = mean_ndcg, 0\n",
    "        else:\n",
    "            stale += 1\n",
    "        if stale >= 5:\n",
    "            break\n",
    "\n",
    "    print(f\"cfg lr={lr}, bs={bs}, drop={drop} → Val NDCG@5: {best_ndcg:.4f}\")\n",
    "    if best_ndcg > best['ndcg']:\n",
    "        best.update({'ndcg': best_ndcg, 'cfg': (lr, bs, drop)})\n",
    "\n",
    "print(\"🏆 Best config:\", best)\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4855e15-4c6b-492f-a267-979ef406a160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef09feb-986f-496e-a691-8fedcee3d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# unpack your best cfg and tweak\n",
    "lr, bs, drop, wd = 1e-3, 128, 0.1, 1e-5\n",
    "\n",
    "# rebuild full-training loader\n",
    "full_loader = DataLoader(\n",
    "    ExpediaDatasetGrouped(X_full, y_full, id_full),\n",
    "    batch_size=bs, shuffle=True\n",
    ")\n",
    "\n",
    "# 1) Slightly larger network at the top\n",
    "class BiggerRecommender(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512), nn.ReLU(), nn.BatchNorm1d(512), nn.Dropout(drop),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.BatchNorm1d(256), nn.Dropout(drop),\n",
    "            nn.Linear(256, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(drop),\n",
    "            nn.Linear(128, 64),  nn.ReLU(), nn.Dropout(drop),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "final_nn = BiggerRecommender(X_full.shape[1]).to(device)\n",
    "\n",
    "# 2) Optimizer with very light weight decay\n",
    "opt = torch.optim.Adam(final_nn.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "# 3) Simpler stepLR scheduler (cuts LR by 0.5 every 10 epochs)\n",
    "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.5)\n",
    "\n",
    "# 4) Train for 30 epochs with gradient clipping\n",
    "for epoch in range(1, 31):\n",
    "    final_nn.train()\n",
    "    total_loss = 0.0\n",
    "    for Xb, yb, gb in full_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = final_nn(Xb)\n",
    "        loss   = listnet_loss(logits, yb, gb)  \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(final_nn.parameters(), 5.0)\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item() * Xb.size(0)\n",
    "\n",
    "    sched.step()\n",
    "    avg_loss = total_loss / len(full_loader.dataset)\n",
    "    print(f\"Epoch {epoch:02d}/30 — Avg ListNet Loss: {avg_loss:.4f} — LR: {opt.param_groups[0]['lr']:.1e}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f70ffb-f18d-43e7-a272-cbc58ee1c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# --- 4) Produce final test preds ---\n",
    "test_loader = DataLoader(\n",
    "    ExpediaDataset(X_test, np.zeros(len(X_test))),\n",
    "    batch_size=bs,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "nn_test_preds = []\n",
    "final_nn.eval()\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in test_loader:           # <-- unpack both X and dummy y\n",
    "        Xb = Xb.to(device)\n",
    "        nn_test_preds.extend(\n",
    "            torch.sigmoid(final_nn(Xb))\n",
    "                 .cpu()\n",
    "                 .numpy()\n",
    "        )\n",
    "nn_test_preds = np.array(nn_test_preds)\n",
    "\n",
    "print(\"NN preds:\", nn_test_preds.min(), nn_test_preds.max())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90180b4-66a8-435f-ad08-d1a9af7af2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 1) Get NN probabilities on the validation fold\n",
    "nn_val_probs = []\n",
    "final_nn.eval()\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in va_loader:\n",
    "        nn_val_probs.extend(\n",
    "            torch.sigmoid(final_nn(Xb.to(device)))\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "nn_val_probs = np.array(nn_val_probs)  # shape = (n_val,)\n",
    "\n",
    "# 2) Compute per-session NDCG@5\n",
    "ndcgs = []\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:\n",
    "        true_rels = y_val_nn[idx]\n",
    "        scores    = nn_val_probs[idx]\n",
    "        ndcgs.append(ndcg_score([true_rels], [scores], k=5))\n",
    "\n",
    "nn_val_ndcg5 = np.mean(ndcgs)\n",
    "print(f\"NN  Val NDCG@5: {nn_val_ndcg5:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af293dc-e382-4a3a-bee5-e767a32048c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# --- Ensemble the predictions ---\n",
    "ensemble_final_preds = ensemble_predictions(nn_test_preds, model_lgb_pred, weights=[0.5, 0.5]) # Adjust weights\n",
    "\n",
    "# Predict relevance scores for each test row\n",
    "preds_ens = ensemble_final_preds\n",
    "\n",
    "# Insert those scores into the sample submission DataFrame\n",
    "sample['score'] = preds_ens\n",
    "\n",
    "# Sort by search session (ascending) and score (descending)\n",
    "#   so that for each srch_id, the most relevant prop_id comes first\n",
    "submission = sample.sort_values(\n",
    "    ['srch_id', 'score'],\n",
    "    ascending=[True, False]\n",
    ")\n",
    "\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3c1e5-a601-4f56-b331-cfbce1e4753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 1) LightGBM val set predictions\n",
    "# Replace `model_lgb` with whatever variable you named your trained LightGBM model\n",
    "val_preds_lgb = model_lgb.predict(X_va)   # shape = (n_val,)\n",
    "\n",
    "# 2) NN val set predictions\n",
    "final_nn.eval()\n",
    "nn_val_preds = []\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in va_loader:  # va_loader from your NN split on X_va/y_va\n",
    "        nn_val_preds.extend(\n",
    "            torch.sigmoid(final_nn(Xb.to(device))).cpu().numpy()\n",
    "        )\n",
    "nn_val_preds = np.array(nn_val_preds)      # shape = (n_val,)\n",
    "\n",
    "# 3) Blend them\n",
    "w_nn, w_lgb = 0.4, 0.6\n",
    "ensemble_val = w_nn * nn_val_preds + w_lgb * val_preds_lgb\n",
    "\n",
    "\n",
    "ndcgs = []\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:\n",
    "        true_rel  = y_val_nn[idx]    # your val labels array\n",
    "        score_rel = ensemble_val[idx]\n",
    "        ndcgs.append(ndcg_score([true_rel], [score_rel], k=5))\n",
    "\n",
    "mean_ndcg5 = np.mean(ndcgs)\n",
    "print(f\"Ensembled Val NDCG@5: {mean_ndcg5:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35a973-a5cc-4f52-afb4-b8ae2f7b9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 1) Min–max scale each prediction array into [0,1]\n",
    "def minmax(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
    "\n",
    "nn_scaled  = minmax(nn_test_preds)\n",
    "lgb_scaled = minmax(model_lgb_pred)   # or whatever your LGB test‐preds variable is\n",
    "\n",
    "# 2) Do the two blends\n",
    "ens1 = ensemble_predictions(nn_scaled, lgb_scaled, [0.5, 0.5])\n",
    "ens2 = ensemble_predictions(nn_scaled, lgb_scaled, [0.0, 1.0])\n",
    "\n",
    "# 3) Compare their sorted‐order permutations\n",
    "order1 = np.argsort(ens1)\n",
    "order2 = np.argsort(ens2)\n",
    "\n",
    "# 4) Compute fraction of positions that differ\n",
    "fraction_changed = np.mean(order1 != order2)\n",
    "print(f\"Fraction of test‐rows whose position changes: {fraction_changed:.4%}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5d100-acc8-4754-9d9b-853cd760f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 0) Scale both NN & LGB validation predictions into [0,1]\n",
    "nn_scaled_val  = minmax_scale(nn_val_preds)      # shape = (n_val,)\n",
    "lgb_scaled_val = minmax_scale(val_preds_lgb)     # shape = (n_val,)\n",
    "\n",
    "best_w, best_score = None, 0.0\n",
    "for w_nn in np.linspace(0, 1, 11):\n",
    "    w_lgb = 1 - w_nn\n",
    "\n",
    "    # blended on the same [0,1] scale\n",
    "    blended = w_nn * nn_scaled_val + w_lgb * lgb_scaled_val\n",
    "\n",
    "    # compute NDCG@5 per session\n",
    "    ndcgs = []\n",
    "    for q in np.unique(id_va):\n",
    "        idx = np.where(id_va == q)[0]\n",
    "        if len(idx) > 1:\n",
    "            true   = y_val_nn[idx]\n",
    "            scores = blended[idx]\n",
    "            ndcgs.append(ndcg_score([true], [scores], k=5))\n",
    "    mean_ndcg = np.mean(ndcgs)\n",
    "\n",
    "    print(f\"w_nn={w_nn:.1f}, w_lgb={w_lgb:.1f} → Val NDCG@5: {mean_ndcg:.4f}\")\n",
    "    if mean_ndcg > best_score:\n",
    "        best_score, best_w = mean_ndcg, w_nn\n",
    "\n",
    "print(f\"\\n🏆 Best blend: w_nn={best_w:.2f}, w_lgb={1-best_w:.2f} → NDCG@5={best_score:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6eb97c-337e-4156-9a0c-0badb3dbabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df = sample[['srch_id']].copy()\n",
    "df['nn_rank']  = pd.DataFrame({'score': nn_test_preds,  'srch': sample['srch_id']}) \\\n",
    "                    .groupby('srch')['score'] \\\n",
    "                    .rank(method='dense', ascending=False)\n",
    "df['lgb_rank'] = pd.DataFrame({'score': model_lgb_pred,'srch': sample['srch_id']}) \\\n",
    "                    .groupby('srch')['score'] \\\n",
    "                    .rank(method='dense', ascending=False)\n",
    "\n",
    "# weighted rank\n",
    "w_nn, w_lgb = best_w, (1-best_w)\n",
    "df['ensemble_rank'] = w_nn * df['nn_rank'] + w_lgb * df['lgb_rank']\n",
    "\n",
    "# use that to sort\n",
    "submission = sample.assign(_rank=df['ensemble_rank']) \\\n",
    "    .sort_values(['srch_id','_rank'], ascending=[True,True]) \\\n",
    "    [['srch_id','prop_id']]\n",
    "\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7bccc1-01c7-405a-8e9f-913dc53fd5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df_sub = sample[['srch_id']].copy()\n",
    "df_sub['nn_rank']  = pd.Series(nn_test_preds).groupby(sample['srch_id']).rank(\"dense\", ascending=False)\n",
    "df_sub['lgb_rank'] = pd.Series(model_lgb_pred).groupby(sample['srch_id']).rank(\"dense\", ascending=False)\n",
    "\n",
    "# weighted rank blend\n",
    "df_sub['ensemble_rank'] = 0.2*df_sub['nn_rank'] + 0.8*df_sub['lgb_rank']\n",
    "\n",
    "submission = (\n",
    "    sample.assign(_rank=df_sub['ensemble_rank'])\n",
    "          .sort_values(['srch_id','_rank'], ascending=[True,True])\n",
    "          [['srch_id','prop_id']]\n",
    ")\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
