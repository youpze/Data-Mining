{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca254db0-81c6-46c4-a66e-9b7f66172755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score, roc_auc_score\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder,  minmax_scale\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GroupShuffleSplit\n",
    "import itertools\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from catboost import CatBoostRanker, Pool,  cv\n",
    "import optuna\n",
    "from optuna.integration import CatBoostPruningCallback\n",
    "from catboost.utils import eval_metric\n",
    "from optuna.pruners import SuccessiveHalvingPruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f7bcaa-d6d3-49c1-b9b0-5edec2d3a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the files changes path to where the data is stored\n",
    "test = pd.read_csv(r\"C:\\Users\\youpz\\Documents\\Master\\P5\\Data mining techniques\\Assignment2\\data\\dmt-2025-2nd-assignment\\test_set_VU_DM.csv\")\n",
    "train = pd.read_csv(r\"C:\\Users\\youpz\\Documents\\Master\\P5\\Data mining techniques\\Assignment2\\data\\dmt-2025-2nd-assignment\\training_set_VU_DM.csv\")\n",
    "sample = pd.read_csv(r\"C:\\Users\\youpz\\Documents\\Master\\P5\\Data mining techniques\\Assignment2\\data\\dmt-2025-2nd-assignment\\submission_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a5d234-6885-41df-bdf7-94794f3df4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "    \"\"\"Returns a DataFrame with missing counts and percent missing for each column.\"\"\"\n",
    "    n = len(df)\n",
    "    missing_count   = df.isna().sum()\n",
    "    missing_percent = 100 * missing_count / n\n",
    "    missing_df = (\n",
    "        pd.DataFrame({\n",
    "            'missing_count':   missing_count,\n",
    "            'missing_percent': missing_percent\n",
    "        })\n",
    "        .sort_values('missing_percent', ascending=False)\n",
    "    )\n",
    "    return missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0e5c47-2faf-4d18-9955-94abd8b44a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "comp3_rate                       3424059        69.056462\n",
      "comp3_inv                        3307357        66.702814\n",
      "comp8_rate                       3041693        61.344900\n",
      "comp8_inv                        2970844        59.916016\n",
      "comp2_rate                       2933675        59.166392\n",
      "comp2_inv                        2828078        57.036710\n",
      "comp5_rate                       2735974        55.179155\n",
      "comp5_inv                        2598327        52.403089\n",
      "orig_destination_distance        1607782        32.425766\n"
     ]
    }
   ],
   "source": [
    "mv = missing_values_table(train)\n",
    "print(mv.head(20))       # top 20 most‐missing columns\n",
    "# Or to filter down to “lots” of missing, say >30%:\n",
    "print(mv[mv['missing_percent'] > 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ea75187-7171-44a8-b8d1-ef210c3b2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## some beginning on the feature engineering\n",
    "def missing_values_table(df):\n",
    "    \"\"\"Returns a DataFrame with missing counts and percent missing for each column.\"\"\"\n",
    "    n = len(df)\n",
    "    missing_count   = df.isna().sum()\n",
    "    missing_percent = 100 * missing_count / n\n",
    "    missing_df = (\n",
    "        pd.DataFrame({\n",
    "            'missing_count':   missing_count,\n",
    "            'missing_percent': missing_percent\n",
    "        })\n",
    "        .sort_values('missing_percent', ascending=False)\n",
    "    )\n",
    "    return missing_df\n",
    "    \n",
    "def preprocess_missing_and_competitors(train_df, test_df):\n",
    "    # 1) Drop features with >93% missing or that leak the target\n",
    "    drop_cols = [\n",
    "        # competitor 1,4,6,7 are ~97–98% missing → too sparse to learn\n",
    "        *[f'comp{i}_{t}' for i in [1,4,6,7] for t in ['rate','inv','rate_percent_diff']],\n",
    "        'gross_bookings_usd'  # only in train, leaks booking price\n",
    "    ]\n",
    "    train_df.drop(columns=drop_cols, errors='ignore', inplace=True)\n",
    "    test_df.drop(columns=drop_cols, errors='ignore', inplace=True)\n",
    "\n",
    "    # 2) Impute & flag user history features\n",
    "    #    Missing means “no prior purchases” → keep with sentinel + flag\n",
    "    for df in (train_df, test_df):\n",
    "        # visitor_hist_starrating\n",
    "        df['hist_star_na'] = df['visitor_hist_starrating'].isna().astype(int)\n",
    "        # fill with median starrating across users\n",
    "        star_med = train_df['visitor_hist_starrating'].median()\n",
    "        df['visitor_hist_starrating'] = df['visitor_hist_starrating'].fillna(star_med)\n",
    "\n",
    "        # visitor_hist_adr_usd (avg USD spend)\n",
    "        df['hist_adr_na'] = df['visitor_hist_adr_usd'].isna().astype(int)\n",
    "        adr_med = train_df['visitor_hist_adr_usd'].median()\n",
    "        df['visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].fillna(adr_med)\n",
    "\n",
    "    # 3) Impute & flag affinity score\n",
    "    #    Null means “hotel never seen” → fill with global minimum and flag\n",
    "    affinity_min = train_df['srch_query_affinity_score'].min(skipna=True)\n",
    "    for df in (train_df, test_df):\n",
    "        df['affinity_na'] = df['srch_query_affinity_score'].isna().astype(int)\n",
    "        df['srch_query_affinity_score'] = (\n",
    "            df['srch_query_affinity_score']\n",
    "            .fillna(affinity_min)\n",
    "        )\n",
    "\n",
    "    # 4) Keep & impute competitor 2,3,5,8 features (~50–90% missing)\n",
    "    #    Null → “no data” sentinel (for categorical) or 0 (for percent diff), plus flag\n",
    "    keep_comps = [2,3,5,8]\n",
    "    for i in keep_comps:\n",
    "        # availability flag\n",
    "        inv_col = f'comp{i}_inv'\n",
    "        flag_col = f'comp{i}_inv_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[flag_col] = df[inv_col].isna().astype(int)\n",
    "            # fill null with 2 (new category: 0=no avail,1=avail,2=no data)\n",
    "            df[inv_col] = df[inv_col].fillna(2).astype(int)\n",
    "\n",
    "        # price‐compare flag\n",
    "        rate_col = f'comp{i}_rate'\n",
    "        rate_flag = f'comp{i}_rate_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[rate_flag] = df[rate_col].isna().astype(int)\n",
    "            # fill null as “no data” = 2\n",
    "            df[rate_col] = df[rate_col].fillna(2).astype(int)\n",
    "\n",
    "        # percent_diff\n",
    "        pdiff_col = f'comp{i}_rate_percent_diff'\n",
    "        pdiff_flag = f'comp{i}_pdiff_na'\n",
    "        for df in (train_df, test_df):\n",
    "            df[pdiff_flag] = df[pdiff_col].isna().astype(int)\n",
    "            # fill null as 0% diff (no info)\n",
    "            df[pdiff_col] = df[pdiff_col].fillna(0.0)\n",
    "\n",
    "    # 5) Bucket orig_destination_distance\n",
    "    #    Missing → sentinel bucket + flag\n",
    "    for df in (train_df, test_df):\n",
    "        df['dist_na'] = df['orig_destination_distance'].isna().astype(int)\n",
    "        df['orig_destination_distance'] = (\n",
    "            df['orig_destination_distance'].fillna(-1)\n",
    "        )\n",
    "        # define bins (in km)\n",
    "        bins = [-1, 0, 10, 50, 200, np.inf]\n",
    "        labels = ['missing','0-10km','10-50km','50-200km','200km+']\n",
    "        df['dist_bucket'] = pd.cut(\n",
    "            df['orig_destination_distance'],\n",
    "            bins=bins, labels=labels\n",
    "        )\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def create_base_features(df):\n",
    "    \"\"\"1) Parse datetime & basic price/historical features.\"\"\"\n",
    "    df = df.copy()\n",
    "    # --- Date/time splits ---\n",
    "    df['date_time']   = pd.to_datetime(df['date_time'])\n",
    "    df['search_year'] = df['date_time'].dt.year\n",
    "    df['search_month']= df['date_time'].dt.month\n",
    "    df['search_day']  = df['date_time'].dt.day\n",
    "    df['search_hour'] = df['date_time'].dt.hour\n",
    "\n",
    "    # --- Price per night & hist price devation ---\n",
    "    df['price_per_night'] = df['price_usd'] / df['srch_length_of_stay']\n",
    "    df['price_vs_historical'] = df['price_usd'] - df['prop_log_historical_price']\n",
    "    df['price_vs_historical'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_destination_stats(train_df, test_df):\n",
    "    \"\"\"6) Dest‑level total searches & booking rate.\"\"\"\n",
    "    dest = (\n",
    "        train_df\n",
    "        .groupby('srch_destination_id')\n",
    "        .agg(dest_searches=('srch_id','count'),\n",
    "             dest_bookings=('booking_bool','sum'))\n",
    "        .assign(dest_booking_rate=lambda x: x.dest_bookings / x.dest_searches)\n",
    "        .reset_index()\n",
    "    )\n",
    "    # Reassign merge result back to each DataFrame\n",
    "    train_df = train_df.merge(\n",
    "        dest[['srch_destination_id','dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "    test_df = test_df.merge(\n",
    "        dest[['srch_destination_id','dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "    return train_df, test_df\n",
    "\n",
    "def add_within_search_features(df):\n",
    "    \"\"\"7) Z‑scores & deltas in each search group.\"\"\"\n",
    "    grp = df.groupby('srch_id')\n",
    "    # price\n",
    "    df['price_mean_srch'] = grp['price_usd'].transform('mean')\n",
    "    df['price_std_srch']  = grp['price_usd'].transform('std').fillna(1)\n",
    "    df['price_zscore']    = (df['price_usd'] - df['price_mean_srch']) / df['price_std_srch']\n",
    "    # stars\n",
    "    df['star_mean_srch']  = grp['prop_starrating'].transform('mean')\n",
    "    df['star_delta_srch'] = df['prop_starrating'] - df['star_mean_srch']\n",
    "    # user delta\n",
    "    df['star_delta_user'] = df['prop_starrating'] - df['visitor_hist_starrating']\n",
    "    # distance\n",
    "    df['dist_mean_srch']  = grp['orig_destination_distance'].transform('mean')\n",
    "    df['dist_std_srch']   = grp['orig_destination_distance'].transform('std').fillna(1)\n",
    "    df['dist_zscore']     = (df['orig_destination_distance'] - df['dist_mean_srch']) / df['dist_std_srch']\n",
    "    return df\n",
    "\n",
    "def add_temporal_features(df):\n",
    "    \"\"\"8) Weekday/weekend & check‑in weekend flags.\"\"\"\n",
    "    # day‑of‑week for search\n",
    "    df['search_dow'] = df['date_time'].dt.weekday  # 0=Mon…6=Sun\n",
    "    df['is_search_weekend'] = df['search_dow'].isin([5,6]).astype(int)\n",
    "    # approximate check‑in day\n",
    "    checkin = df['date_time'] + pd.to_timedelta(df['srch_booking_window'], 'D')\n",
    "    df['checkin_dow'] = checkin.dt.weekday\n",
    "    df['is_checkin_weekend'] = df['checkin_dow'].isin([5,6]).astype(int)\n",
    "    return df\n",
    "\n",
    "def add_ranks(df):\n",
    "    \"\"\"9) Dense ranks of price, star & distance within each search.\"\"\"\n",
    "    df['price_rank'] = df.groupby('srch_id')['price_usd'].rank('dense', ascending=True)\n",
    "    df['star_rank']  = df.groupby('srch_id')['prop_starrating'].rank('dense', ascending=False)\n",
    "    df['dist_rank']  = df.groupby('srch_id')['orig_destination_distance'].rank('dense', ascending=True)\n",
    "    return df\n",
    "\n",
    "def one_hot_encode_columns(train_df, test_df, columns_to_encode):\n",
    "    \"\"\"\n",
    "    Converts specified string columns in train and test DataFrames to one-hot encoded features.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): The training DataFrame.\n",
    "        test_df (pd.DataFrame): The testing DataFrame.\n",
    "        columns_to_encode (list): A list of column names (strings) to be one-hot encoded.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the modified training and testing DataFrames with one-hot encoded columns.\n",
    "    \"\"\"\n",
    "    train_processed = train_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "\n",
    "    for col in columns_to_encode:\n",
    "        if col in train_processed.columns and col in test_processed.columns:\n",
    "            # Get unique values from both train and test to ensure consistent encoding\n",
    "            all_unique_values = pd.concat([train_processed[col], test_processed[col]]).unique()\n",
    "\n",
    "            for value in all_unique_values:\n",
    "                train_processed[f'{col}_{value}'] = (train_processed[col] == value).astype(int)\n",
    "                test_processed[f'{col}_{value}'] = (test_processed[col] == value).astype(int)\n",
    "\n",
    "            # Drop the original categorical column\n",
    "            train_processed.drop(columns=[col], inplace=True)\n",
    "            test_processed.drop(columns=[col], inplace=True)\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in both train and test DataFrames. Skipping one-hot encoding for this column.\")\n",
    "\n",
    "    return train_processed, test_processed\n",
    "\n",
    "def minmax(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
    "\n",
    "def ensemble_predictions(pred1, pred2, weights):\n",
    "    w1, w2 = weights\n",
    "    return w1 * minmax(pred1) + w2 * minmax(pred2)\n",
    "\n",
    "def preprocess_missing_and_competitors_fit(train_df):\n",
    "    stats = {}\n",
    "    # 1) Which cols to drop\n",
    "    stats['drop_cols'] = [\n",
    "        *[f'comp{i}_{t}' for i in [1,4,6,7] \n",
    "          for t in ['rate','inv','rate_percent_diff']],\n",
    "        'gross_bookings_usd'\n",
    "    ]\n",
    "    # 2) Medians & mins for imputation\n",
    "    stats['star_med']     = train_df['visitor_hist_starrating'].median()\n",
    "    stats['adr_med']      = train_df['visitor_hist_adr_usd'].median()\n",
    "    stats['affinity_min'] = train_df['srch_query_affinity_score'].min(skipna=True)\n",
    "    return stats\n",
    "\n",
    "def preprocess_missing_and_competitors_transform(df, stats):\n",
    "    df = df.copy()\n",
    "    df.drop(columns=stats['drop_cols'], errors='ignore', inplace=True)\n",
    "\n",
    "    # visitor history\n",
    "    df['hist_star_na'] = df['visitor_hist_starrating'].isna().astype(int)\n",
    "    df['visitor_hist_starrating'] = (\n",
    "        df['visitor_hist_starrating']\n",
    "          .fillna(stats['star_med'])\n",
    "    )\n",
    "    df['hist_adr_na'] = df['visitor_hist_adr_usd'].isna().astype(int)\n",
    "    df['visitor_hist_adr_usd'] = (\n",
    "        df['visitor_hist_adr_usd']\n",
    "          .fillna(stats['adr_med'])\n",
    "    )\n",
    "\n",
    "    # affinity\n",
    "    df['affinity_na'] = df['srch_query_affinity_score'].isna().astype(int)\n",
    "    df['srch_query_affinity_score'] = (\n",
    "        df['srch_query_affinity_score']\n",
    "          .fillna(stats['affinity_min'])\n",
    "    )\n",
    "\n",
    "    # keep comps 2,3,5,8\n",
    "    for i in [2,3,5,8]:\n",
    "        for col, fill in [\n",
    "            (f'comp{i}_inv',               2),\n",
    "            (f'comp{i}_rate',              2),\n",
    "            (f'comp{i}_rate_percent_diff', 0.0),\n",
    "        ]:\n",
    "            df[f'{col}_na'] = df[col].isna().astype(int)\n",
    "            df[col] = df[col].fillna(fill)\n",
    "\n",
    "    # distance bucket\n",
    "    df['dist_na'] = df['orig_destination_distance'].isna().astype(int)\n",
    "    df['orig_destination_distance'] = (\n",
    "        df['orig_destination_distance'].fillna(-1)\n",
    "    )\n",
    "    bins  = [-1,0,10,50,200,np.inf]\n",
    "    lbls  = ['missing','0-10km','10-50km','50-200km','200km+']\n",
    "    df['dist_bucket'] = pd.cut(\n",
    "        df['orig_destination_distance'], bins=bins, labels=lbls\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def add_destination_stats_fit(train_df):\n",
    "    dest = (\n",
    "        train_df\n",
    "        .groupby('srch_destination_id')\n",
    "        .agg(dest_searches=('srch_id','count'),\n",
    "             dest_bookings=('booking_bool','sum'))\n",
    "    )\n",
    "    dest['dest_booking_rate'] = dest['dest_bookings'] / dest['dest_searches']\n",
    "    return dest\n",
    "\n",
    "def add_destination_stats_transform(df, dest_stats):\n",
    "    df = df.copy()\n",
    "    return df.merge(\n",
    "        dest_stats[['dest_searches','dest_booking_rate']],\n",
    "        on='srch_destination_id', how='left'\n",
    "    )\n",
    "def run_pipeline_on(train_df, other_df, steps):\n",
    "    df1, df2 = train_df.copy(), other_df.copy()\n",
    "    for fn in steps:\n",
    "        df1, df2 = fn(df1, df2)\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1039db90-505b-4710-a4cc-2ac0b456f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your FE pipeline, exactly as before\n",
    "steps = [\n",
    "    preprocess_missing_and_competitors,\n",
    "    add_destination_stats,\n",
    "    lambda tr, te: one_hot_encode_columns(tr, te, ['dist_bucket']),\n",
    "    lambda tr, te: (create_base_features(tr),     create_base_features(te)),\n",
    "    lambda tr, te: (add_within_search_features(tr), add_within_search_features(te)),\n",
    "    lambda tr, te: (add_temporal_features(tr),    add_temporal_features(te)),\n",
    "    lambda tr, te: (add_ranks(tr),                add_ranks(te)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb187d0-fb92-49dc-8060-582ebf758368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "                           missing_count  missing_percent\n",
      "comp1_rate_percent_diff          4863908        98.095353\n",
      "comp6_rate_percent_diff          4862173        98.060362\n",
      "comp1_rate                       4838417        97.581250\n",
      "comp1_inv                        4828788        97.387053\n",
      "comp4_rate_percent_diff          4827261        97.356256\n",
      "gross_bookings_usd               4819957        97.208949\n",
      "comp7_rate_percent_diff          4819832        97.206428\n",
      "comp6_rate                       4718190        95.156511\n",
      "visitor_hist_starrating          4706481        94.920364\n",
      "visitor_hist_adr_usd             4705359        94.897735\n",
      "comp6_inv                        4697371        94.736633\n",
      "comp4_rate                       4650969        93.800797\n",
      "comp7_rate                       4642999        93.640058\n",
      "srch_query_affinity_score        4640941        93.598552\n",
      "comp4_inv                        4614684        93.069001\n",
      "comp7_inv                        4601925        92.811677\n",
      "comp3_rate_percent_diff          4485550        90.464625\n",
      "comp2_rate_percent_diff          4402109        88.781786\n",
      "comp8_rate_percent_diff          4343617        87.602118\n",
      "comp5_rate_percent_diff          4117248        83.036706\n",
      "comp3_rate                       3424059        69.056462\n",
      "comp3_inv                        3307357        66.702814\n",
      "comp8_rate                       3041693        61.344900\n",
      "comp8_inv                        2970844        59.916016\n",
      "comp2_rate                       2933675        59.166392\n",
      "comp2_inv                        2828078        57.036710\n",
      "comp5_rate                       2735974        55.179155\n",
      "comp5_inv                        2598327        52.403089\n",
      "orig_destination_distance        1607782        32.425766\n"
     ]
    }
   ],
   "source": [
    "mv = missing_values_table(train)\n",
    "print(mv.head(20))       # top 20 most‐missing columns\n",
    "# Or to filter down to “lots” of missing, say >30%:\n",
    "print(mv[mv['missing_percent'] > 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48198da9-b7e9-4f8a-9a23-a189962f4003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_29192\\2243288486.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_29192\\2243288486.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_29192\\2243288486.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_29192\\2243288486.py:108: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['price_vs_historical'].fillna(0, inplace=True)\n",
      "C:\\Users\\youpz\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 0) define target\n",
    "y = train['booking_bool'] * 5 + train['click_bool']\n",
    "\n",
    "# 1) Split out search-IDs into train vs. valid\n",
    "train_ids, valid_ids = train_test_split(\n",
    "    train['srch_id'].unique(),\n",
    "    test_size=0.2,\n",
    "    random_state=22\n",
    ")\n",
    "train_raw = train[ train['srch_id'].isin(train_ids) ].reset_index(drop=True)\n",
    "valid_raw = train[ train['srch_id'].isin(valid_ids) ].reset_index(drop=True)\n",
    "test_raw  = test.copy()\n",
    "\n",
    "# 2) Feature engineering pipeline\n",
    "train_feat, test_feat = run_pipeline_on(train_raw, test_raw, steps)\n",
    "_, valid_feat        = run_pipeline_on(train_feat, valid_raw, steps)\n",
    "\n",
    "# 3) Select base feature columns\n",
    "drop_cols = ['date_time','gross_bookings_usd','position',\n",
    "             'click_bool','booking_bool','srch_id','prop_id']\n",
    "features = [c for c in train_feat.columns if c not in drop_cols]\n",
    "\n",
    "# 4) Compute mean position on TRAIN_RAW\n",
    "mean_pos_map = train_raw.groupby('prop_id')['position'].mean()\n",
    "\n",
    "# 5) Inject mean_pos into all feature frames\n",
    "for df in (train_feat, valid_feat, test_feat):\n",
    "    df['mean_pos'] = df['prop_id'].map(mean_pos_map)\n",
    "\n",
    "# 6) Rebuild feature matrices including mean_pos\n",
    "features = [c for c in train_feat.columns if c not in drop_cols]\n",
    "X        = train_feat[features].copy()\n",
    "X_va_all = valid_feat[features].copy()\n",
    "X_test   = test_feat[features].copy()\n",
    "\n",
    "# 7) Replace infinities/NaNs and impute with TRAIN medians\n",
    "for df in (X, X_va_all, X_test):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "train_medians = X.median()\n",
    "X     .fillna(train_medians, inplace=True)\n",
    "X_va_all.fillna(train_medians, inplace=True)\n",
    "X_test .fillna(train_medians, inplace=True)\n",
    "\n",
    "# 8) Scale\n",
    "scaler = StandardScaler()\n",
    "X_tr   = scaler.fit_transform(X)                       # train only\n",
    "X_va   = scaler.transform(X_va_all)                    # valid\n",
    "X_full = scaler.transform(np.vstack([X, X_va_all]))    # full\n",
    "X_test = scaler.transform(X_test)                      # test\n",
    "\n",
    "# 9) Build y arrays and grouping\n",
    "y_tr   = (train_raw['booking_bool'] * 5 + train_raw['click_bool']).values\n",
    "y_va   = (valid_raw['booking_bool'] * 5 + valid_raw['click_bool']).values\n",
    "y_full = np.concatenate([y_tr, y_va])\n",
    "\n",
    "id_tr   = train_raw['srch_id'].values\n",
    "id_va   = valid_raw['srch_id'].values\n",
    "id_full = np.concatenate([id_tr, id_va])\n",
    "\n",
    "grp_tr   = train_raw['srch_id'].value_counts(sort=False).values\n",
    "grp_va   = valid_raw['srch_id'].value_counts(sort=False).values\n",
    "grp_full = np.concatenate([grp_tr, grp_va])\n",
    "\n",
    "# 10) Create LightGBM & CatBoost datasets\n",
    "lgb_train = lgb.Dataset(X_tr,   label=y_tr,   group=grp_tr)\n",
    "lgb_val   = lgb.Dataset(X_va,   label=y_va,   group=grp_va)\n",
    "lgb_full  = lgb.Dataset(X_full, label=y_full, group=grp_full)\n",
    "\n",
    "train_pool = Pool(X_tr,   label=y_tr,   group_id=id_tr)\n",
    "val_pool   = Pool(X_va,   label=y_va,   group_id=id_va)\n",
    "full_pool  = Pool(X_full, label=y_full, group_id=id_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ec2bd5f-1730-4666-85f7-3952157d51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Define your search space\n",
    "\n",
    "param_dist = {\n",
    "    'learning_rate':    [0.005, 0.01, 0.02, 0.05],\n",
    "    'num_leaves':       [64, 128, 256],\n",
    "    'min_data_in_leaf': [10, 30, 50, 100],\n",
    "    'feature_fraction': [0.6, 0.8, 1.0],\n",
    "    'bagging_fraction': [0.6, 0.8, 1.0],\n",
    "    'bagging_freq':     [0, 5, 10]\n",
    "}\n",
    "\n",
    "n_iter = 30\n",
    "best_score, score = 0,0\n",
    "best_params,params = None,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "673066f0-78f5-4834-ace3-a35f4110ea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.05, 'num_leaves': 64, 'min_data_in_leaf': 30, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.184144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[367]\tvalid's ndcg@5: 0.396017\n",
      "    → ndcg@5 = 0.3960, rounds = 367\n",
      "2\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.005, 'num_leaves': 64, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.164882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\tvalid's ndcg@5: 0.385618\n",
      "    → ndcg@5 = 0.3856, rounds = 900\n",
      "3\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 128, 'min_data_in_leaf': 30, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.260697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[895]\tvalid's ndcg@5: 0.395297\n",
      "    → ndcg@5 = 0.3953, rounds = 895\n",
      "4\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.05, 'num_leaves': 64, 'min_data_in_leaf': 100, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.538149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[452]\tvalid's ndcg@5: 0.39663\n",
      "    → ndcg@5 = 0.3966, rounds = 452\n",
      "5\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 64, 'min_data_in_leaf': 30, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.257834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[897]\tvalid's ndcg@5: 0.392125\n",
      "    → ndcg@5 = 0.3921, rounds = 897\n",
      "6\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.005, 'num_leaves': 256, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.301208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\tvalid's ndcg@5: 0.39228\n",
      "    → ndcg@5 = 0.3923, rounds = 900\n",
      "7\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 64, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.223485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[894]\tvalid's ndcg@5: 0.393394\n",
      "    → ndcg@5 = 0.3934, rounds = 894\n",
      "8\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 128, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 10}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.264397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[897]\tvalid's ndcg@5: 0.395185\n",
      "    → ndcg@5 = 0.3952, rounds = 897\n",
      "9\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.005, 'num_leaves': 64, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 10}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.249977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\tvalid's ndcg@5: 0.386408\n",
      "    → ndcg@5 = 0.3864, rounds = 900\n",
      "10\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.05, 'num_leaves': 128, 'min_data_in_leaf': 30, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 10}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.543853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[318]\tvalid's ndcg@5: 0.397963\n",
      "    → ndcg@5 = 0.3980, rounds = 318\n",
      "11\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 256, 'min_data_in_leaf': 30, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.195397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[588]\tvalid's ndcg@5: 0.399707\n",
      "    → ndcg@5 = 0.3997, rounds = 588\n",
      "12\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.05, 'num_leaves': 128, 'min_data_in_leaf': 100, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.624100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[368]\tvalid's ndcg@5: 0.397199\n",
      "    → ndcg@5 = 0.3972, rounds = 368\n",
      "13\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.005, 'num_leaves': 128, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.539486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[897]\tvalid's ndcg@5: 0.390304\n",
      "    → ndcg@5 = 0.3903, rounds = 897\n",
      "14\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 128, 'min_data_in_leaf': 30, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.544716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[585]\tvalid's ndcg@5: 0.397687\n",
      "    → ndcg@5 = 0.3977, rounds = 585\n",
      "15\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 128, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.573477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[681]\tvalid's ndcg@5: 0.397755\n",
      "    → ndcg@5 = 0.3978, rounds = 681\n",
      "16\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 64, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.642365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[899]\tvalid's ndcg@5: 0.391807\n",
      "    → ndcg@5 = 0.3918, rounds = 899\n",
      "17\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.005, 'num_leaves': 128, 'min_data_in_leaf': 100, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.212420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid's ndcg@5: 0.387011\n",
      "    → ndcg@5 = 0.3870, rounds = 252\n",
      "18\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.005, 'num_leaves': 256, 'min_data_in_leaf': 30, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.297046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[892]\tvalid's ndcg@5: 0.395269\n",
      "    → ndcg@5 = 0.3953, rounds = 892\n",
      "19\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 256, 'min_data_in_leaf': 100, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.249709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\tvalid's ndcg@5: 0.400458\n",
      "    → ndcg@5 = 0.4005, rounds = 900\n",
      "20\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 256, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 10}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.667782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[775]\tvalid's ndcg@5: 0.399235\n",
      "    → ndcg@5 = 0.3992, rounds = 775\n",
      "21\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 256, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.304422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[674]\tvalid's ndcg@5: 0.39625\n",
      "    → ndcg@5 = 0.3963, rounds = 674\n",
      "22\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.005, 'num_leaves': 128, 'min_data_in_leaf': 30, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.560122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid's ndcg@5: 0.38206\n",
      "    → ndcg@5 = 0.3821, rounds = 198\n",
      "23\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.005, 'num_leaves': 128, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.590885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\tvalid's ndcg@5: 0.388627\n",
      "    → ndcg@5 = 0.3886, rounds = 900\n",
      "24\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 256, 'min_data_in_leaf': 30, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 10}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.200988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[522]\tvalid's ndcg@5: 0.398939\n",
      "    → ndcg@5 = 0.3989, rounds = 522\n",
      "25\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.005, 'num_leaves': 128, 'min_data_in_leaf': 100, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.287537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\tvalid's ndcg@5: 0.388459\n",
      "    → ndcg@5 = 0.3885, rounds = 900\n",
      "26\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 64, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.258674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\tvalid's ndcg@5: 0.392248\n",
      "    → ndcg@5 = 0.3922, rounds = 900\n",
      "27\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 64, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.282468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\tvalid's ndcg@5: 0.392113\n",
      "    → ndcg@5 = 0.3921, rounds = 900\n",
      "28\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.01, 'num_leaves': 256, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.224295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[898]\tvalid's ndcg@5: 0.399336\n",
      "    → ndcg@5 = 0.3993, rounds = 898\n",
      "29\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.005, 'num_leaves': 128, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 10}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.549930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[899]\tvalid's ndcg@5: 0.390159\n",
      "    → ndcg@5 = 0.3902, rounds = 899\n",
      "30\n",
      "{'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 256, 'min_data_in_leaf': 30, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.229516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7129\n",
      "[LightGBM] [Info] Number of data points in the train set: 3968534, number of used features: 80\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[523]\tvalid's ndcg@5: 0.39953\n",
      "    → ndcg@5 = 0.3995, rounds = 523\n"
     ]
    }
   ],
   "source": [
    "# 1) Your random search stays the same…\n",
    "for i in range(1, n_iter + 1):\n",
    "    print(i)\n",
    "    params = {\n",
    "        'objective':         'lambdarank',\n",
    "        'metric':            'ndcg',\n",
    "        'ndcg_eval_at':      [5],\n",
    "        'verbose':           1,\n",
    "        'feature_pre_filter': False,      # ← disable the one-shot pre-filter\n",
    "    }\n",
    "    # 2) then overlay your random hyper‐params\n",
    "    params.update({k: np.random.choice(v) for k, v in param_dist.items()})\n",
    "    print(params)\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set=lgb_train,\n",
    "        num_boost_round=900,\n",
    "        valid_sets=lgb_val,\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    "    )\n",
    "    \n",
    "    score = model.best_score['valid']['ndcg@5']\n",
    "    print(f\"    → ndcg@5 = {score:.4f}, rounds = {model.best_iteration}\")\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score_ = score\n",
    "        best_params = params.copy()\n",
    "        best_iter =  model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06f335fe-beb9-44c9-a698-c4a8dd99de6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [5], 'verbose': 1, 'feature_pre_filter': False, 'learning_rate': 0.02, 'num_leaves': 256, 'min_data_in_leaf': 30, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5} 523\n"
     ]
    }
   ],
   "source": [
    "print(best_score, best_params, best_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf22fe9-054d-4f3b-a757-a40119664b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.285572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7147\n",
      "[LightGBM] [Info] Number of data points in the train set: 4958347, number of used features: 80\n"
     ]
    }
   ],
   "source": [
    "# 3) Retrain on all data\n",
    "model_lgb_full = lgb.train(\n",
    "    best_params,\n",
    "    lgb_full,\n",
    "    num_boost_round=best_iter # can still be ajdusted to best best_iter\n",
    ")\n",
    "\n",
    "# 4) Predict on test\n",
    "lgb_test_preds = model_lgb_full.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c4afe9f-c8cb-46c4-a86b-c567a7e81a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 00:37:49,941] A new study created in memory with name: catboost_yetirank\n",
      "C:\\Users\\youpz\\AppData\\Local\\Temp\\ipykernel_29192\\3197025621.py:22: ExperimentalWarning: CatBoostPruningCallback is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  pruning_callback = CatBoostPruningCallback(trial, 'NDCG:top=5;type=Base')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.2841405\tbest: 0.2841405 (0)\ttotal: 1.85s\tremaining: 30m 47s\n",
      "100:\ttest: 0.3807906\tbest: 0.3807906 (100)\ttotal: 2m 27s\tremaining: 21m 48s\n",
      "200:\ttest: 0.3878113\tbest: 0.3878113 (200)\ttotal: 4m 49s\tremaining: 19m 11s\n",
      "300:\ttest: 0.3913843\tbest: 0.3913852 (298)\ttotal: 7m 11s\tremaining: 16m 41s\n",
      "400:\ttest: 0.3926806\tbest: 0.3927012 (399)\ttotal: 9m 33s\tremaining: 14m 16s\n",
      "500:\ttest: 0.3945817\tbest: 0.3945817 (500)\ttotal: 11m 54s\tremaining: 11m 52s\n",
      "600:\ttest: 0.3960178\tbest: 0.3960263 (598)\ttotal: 14m 17s\tremaining: 9m 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 00:53:41,106] Trial 0 finished with value: 0.39625695413322704 and parameters: {'learning_rate': 0.060037472753694913, 'depth': 9, 'l2_leaf_reg': 0.14612754406308678, 'random_strength': 0.0027857831867539825, 'bagging_temperature': 0.7319243386688927, 'border_count': 96}. Best is trial 0 with value: 0.39625695413322704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (30 iterations wait)\n",
      "\n",
      "bestTest = 0.3962569541\n",
      "bestIteration = 634\n",
      "\n",
      "Shrink model to first 635 iterations.\n",
      "0:\ttest: 0.2776063\tbest: 0.2776063 (0)\ttotal: 1.66s\tremaining: 27m 39s\n",
      "100:\ttest: 0.3746603\tbest: 0.3746603 (100)\ttotal: 2m 23s\tremaining: 21m 16s\n",
      "200:\ttest: 0.3821236\tbest: 0.3821236 (200)\ttotal: 4m 41s\tremaining: 18m 40s\n",
      "300:\ttest: 0.3855980\tbest: 0.3855980 (300)\ttotal: 6m 59s\tremaining: 16m 14s\n",
      "400:\ttest: 0.3881438\tbest: 0.3882277 (393)\ttotal: 9m 16s\tremaining: 13m 51s\n",
      "500:\ttest: 0.3902310\tbest: 0.3902395 (499)\ttotal: 11m 33s\tremaining: 11m 30s\n",
      "600:\ttest: 0.3918723\tbest: 0.3919458 (593)\ttotal: 13m 51s\tremaining: 9m 11s\n",
      "700:\ttest: 0.3924868\tbest: 0.3925033 (699)\ttotal: 16m 9s\tremaining: 6m 53s\n",
      "800:\ttest: 0.3938362\tbest: 0.3938362 (800)\ttotal: 18m 27s\tremaining: 4m 35s\n",
      "900:\ttest: 0.3942616\tbest: 0.3945326 (885)\ttotal: 20m 44s\tremaining: 2m 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 01:14:48,781] Trial 1 finished with value: 0.3945326307726628 and parameters: {'learning_rate': 0.036561589107275756, 'depth': 8, 'l2_leaf_reg': 0.0018264816047791127, 'random_strength': 0.0015143252355895923, 'bagging_temperature': 0.799084783315431, 'border_count': 106}. Best is trial 0 with value: 0.39625695413322704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (30 iterations wait)\n",
      "\n",
      "bestTest = 0.3945326308\n",
      "bestIteration = 885\n",
      "\n",
      "Shrink model to first 886 iterations.\n",
      "0:\ttest: 0.2336850\tbest: 0.2336850 (0)\ttotal: 1.49s\tremaining: 24m 44s\n",
      "100:\ttest: 0.3723369\tbest: 0.3723369 (100)\ttotal: 2m 15s\tremaining: 20m 7s\n",
      "200:\ttest: 0.3791077\tbest: 0.3791077 (200)\ttotal: 4m 27s\tremaining: 17m 44s\n",
      "300:\ttest: 0.3829914\tbest: 0.3829914 (300)\ttotal: 6m 39s\tremaining: 15m 27s\n",
      "400:\ttest: 0.3864335\tbest: 0.3864335 (400)\ttotal: 8m 50s\tremaining: 13m 13s\n",
      "500:\ttest: 0.3888303\tbest: 0.3889644 (496)\ttotal: 11m 1s\tremaining: 10m 59s\n",
      "600:\ttest: 0.3902879\tbest: 0.3904538 (585)\ttotal: 13m 13s\tremaining: 8m 46s\n",
      "700:\ttest: 0.3919494\tbest: 0.3919639 (689)\ttotal: 15m 24s\tremaining: 6m 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 01:30:40,318] Trial 2 finished with value: 0.39196391779102024 and parameters: {'learning_rate': 0.05464372853684204, 'depth': 6, 'l2_leaf_reg': 0.14420574933728642, 'random_strength': 9.052869125184376, 'bagging_temperature': 0.40793600323772305, 'border_count': 78}. Best is trial 0 with value: 0.39625695413322704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (30 iterations wait)\n",
      "\n",
      "bestTest = 0.3919639178\n",
      "bestIteration = 689\n",
      "\n",
      "Shrink model to first 690 iterations.\n",
      "0:\ttest: 0.2781345\tbest: 0.2781345 (0)\ttotal: 1.51s\tremaining: 25m 11s\n",
      "100:\ttest: 0.3556210\tbest: 0.3556210 (100)\ttotal: 2m 27s\tremaining: 21m 55s\n",
      "200:\ttest: 0.3646489\tbest: 0.3646676 (199)\ttotal: 4m 49s\tremaining: 19m 12s\n",
      "300:\ttest: 0.3707216\tbest: 0.3707216 (300)\ttotal: 7m 10s\tremaining: 16m 39s\n",
      "400:\ttest: 0.3742642\tbest: 0.3742642 (400)\ttotal: 9m 31s\tremaining: 14m 13s\n",
      "500:\ttest: 0.3768738\tbest: 0.3769119 (498)\ttotal: 11m 50s\tremaining: 11m 48s\n",
      "600:\ttest: 0.3788458\tbest: 0.3788458 (600)\ttotal: 14m 10s\tremaining: 9m 24s\n",
      "700:\ttest: 0.3805252\tbest: 0.3805252 (700)\ttotal: 16m 29s\tremaining: 7m 1s\n",
      "800:\ttest: 0.3823622\tbest: 0.3823956 (799)\ttotal: 18m 47s\tremaining: 4m 40s\n",
      "900:\ttest: 0.3834466\tbest: 0.3834982 (895)\ttotal: 21m 5s\tremaining: 2m 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 01:54:05,130] Trial 3 finished with value: 0.38432635641317175 and parameters: {'learning_rate': 0.010353835328702593, 'depth': 8, 'l2_leaf_reg': 0.013941743088211635, 'random_strength': 4.31388053176973, 'bagging_temperature': 0.6332316438362043, 'border_count': 180}. Best is trial 0 with value: 0.39625695413322704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999:\ttest: 0.3842573\tbest: 0.3843264 (993)\ttotal: 23m 22s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3843263564\n",
      "bestIteration = 993\n",
      "\n",
      "Shrink model to first 994 iterations.\n",
      "0:\ttest: 0.3073349\tbest: 0.3073349 (0)\ttotal: 2.47s\tremaining: 41m 6s\n",
      "100:\ttest: 0.3820627\tbest: 0.3820627 (100)\ttotal: 3m 47s\tremaining: 33m 47s\n",
      "200:\ttest: 0.3881168\tbest: 0.3881168 (200)\ttotal: 7m 29s\tremaining: 29m 47s\n",
      "300:\ttest: 0.3913648\tbest: 0.3913648 (300)\ttotal: 11m 11s\tremaining: 25m 59s\n",
      "400:\ttest: 0.3931133\tbest: 0.3933035 (386)\ttotal: 14m 54s\tremaining: 22m 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 02:11:57,374] Trial 4 finished with value: 0.39399409724679096 and parameters: {'learning_rate': 0.05400727720080948, 'depth': 11, 'l2_leaf_reg': 0.0083664395127882, 'random_strength': 0.15101932166017648, 'bagging_temperature': 0.7242368076581591, 'border_count': 169}. Best is trial 0 with value: 0.39625695413322704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (30 iterations wait)\n",
      "\n",
      "bestTest = 0.3939940972\n",
      "bestIteration = 449\n",
      "\n",
      "Shrink model to first 450 iterations.\n",
      "0:\ttest: 0.2775364\tbest: 0.2775364 (0)\ttotal: 1.67s\tremaining: 27m 50s\n",
      "100:\ttest: 0.3796861\tbest: 0.3796861 (100)\ttotal: 2m 22s\tremaining: 21m 10s\n",
      "200:\ttest: 0.3864549\tbest: 0.3864549 (200)\ttotal: 4m 41s\tremaining: 18m 39s\n",
      "300:\ttest: 0.3902908\tbest: 0.3902908 (300)\ttotal: 7m 3s\tremaining: 16m 23s\n",
      "400:\ttest: 0.3924034\tbest: 0.3924124 (399)\ttotal: 9m 21s\tremaining: 13m 58s\n",
      "500:\ttest: 0.3937895\tbest: 0.3938211 (482)\ttotal: 11m 40s\tremaining: 11m 37s\n",
      "600:\ttest: 0.3950487\tbest: 0.3950487 (600)\ttotal: 13m 59s\tremaining: 9m 17s\n",
      "700:\ttest: 0.3959787\tbest: 0.3959787 (700)\ttotal: 16m 18s\tremaining: 6m 57s\n",
      "800:\ttest: 0.3968031\tbest: 0.3968176 (779)\ttotal: 18m 36s\tremaining: 4m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 02:32:01,678] Trial 5 finished with value: 0.39753069375658057 and parameters: {'learning_rate': 0.06026180751253327, 'depth': 8, 'l2_leaf_reg': 0.2786699283715661, 'random_strength': 0.02523852969087604, 'bagging_temperature': 0.5256530475378764, 'border_count': 159}. Best is trial 5 with value: 0.39753069375658057.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (30 iterations wait)\n",
      "\n",
      "bestTest = 0.3975306938\n",
      "bestIteration = 832\n",
      "\n",
      "Shrink model to first 833 iterations.\n",
      "0:\ttest: 0.3078184\tbest: 0.3078184 (0)\ttotal: 2.27s\tremaining: 37m 46s\n",
      "100:\ttest: 0.3836688\tbest: 0.3836688 (100)\ttotal: 3m 46s\tremaining: 33m 35s\n",
      "200:\ttest: 0.3905280\tbest: 0.3905414 (199)\ttotal: 7m 27s\tremaining: 29m 39s\n",
      "300:\ttest: 0.3936913\tbest: 0.3936913 (300)\ttotal: 11m 10s\tremaining: 25m 56s\n",
      "400:\ttest: 0.3960396\tbest: 0.3960396 (400)\ttotal: 14m 51s\tremaining: 22m 12s\n",
      "500:\ttest: 0.3976913\tbest: 0.3978073 (499)\ttotal: 18m 34s\tremaining: 18m 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 02:53:47,164] Trial 6 finished with value: 0.3986384254883281 and parameters: {'learning_rate': 0.06157600133358606, 'depth': 11, 'l2_leaf_reg': 0.19294179638242617, 'random_strength': 0.019360441952358007, 'bagging_temperature': 0.3826667121443247, 'border_count': 146}. Best is trial 6 with value: 0.3986384254883281.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (30 iterations wait)\n",
      "\n",
      "bestTest = 0.3986384255\n",
      "bestIteration = 555\n",
      "\n",
      "Shrink model to first 556 iterations.\n",
      "0:\ttest: 0.2555732\tbest: 0.2555732 (0)\ttotal: 1.41s\tremaining: 23m 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 02:54:04,761] Trial 7 pruned. Trial was pruned at iteration 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3236531864\n",
      "bestIteration = 10\n",
      "\n",
      "Shrink model to first 11 iterations.\n",
      "0:\ttest: 0.2738795\tbest: 0.2738795 (0)\ttotal: 1.62s\tremaining: 26m 55s\n",
      "100:\ttest: 0.3810157\tbest: 0.3810157 (100)\ttotal: 2m 20s\tremaining: 20m 49s\n",
      "200:\ttest: 0.3880621\tbest: 0.3880621 (200)\ttotal: 4m 35s\tremaining: 18m 13s\n",
      "300:\ttest: 0.3911227\tbest: 0.3912179 (292)\ttotal: 6m 49s\tremaining: 15m 50s\n",
      "400:\ttest: 0.3929803\tbest: 0.3929803 (400)\ttotal: 9m 4s\tremaining: 13m 32s\n",
      "500:\ttest: 0.3942905\tbest: 0.3944556 (472)\ttotal: 11m 18s\tremaining: 11m 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 03:05:28,021] Trial 8 finished with value: 0.3944556217874901 and parameters: {'learning_rate': 0.0872333543829379, 'depth': 7, 'l2_leaf_reg': 0.6572876584726657, 'random_strength': 0.0018891145247801314, 'bagging_temperature': 0.34991813186434984, 'border_count': 244}. Best is trial 6 with value: 0.3986384254883281.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (30 iterations wait)\n",
      "\n",
      "bestTest = 0.3944556218\n",
      "bestIteration = 472\n",
      "\n",
      "Shrink model to first 473 iterations.\n",
      "0:\ttest: 0.3032971\tbest: 0.3032971 (0)\ttotal: 2.7s\tremaining: 44m 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 03:05:58,241] Trial 9 pruned. Trial was pruned at iteration 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3413936852\n",
      "bestIteration = 10\n",
      "\n",
      "Shrink model to first 11 iterations.\n",
      "0:\ttest: 0.3059792\tbest: 0.3059792 (0)\ttotal: 2.38s\tremaining: 39m 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 03:06:24,568] Trial 10 pruned. Trial was pruned at iteration 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3391467158\n",
      "bestIteration = 10\n",
      "\n",
      "Shrink model to first 11 iterations.\n",
      "0:\ttest: 0.3012820\tbest: 0.3012820 (0)\ttotal: 2.14s\tremaining: 35m 35s\n",
      "100:\ttest: 0.3849523\tbest: 0.3850054 (99)\ttotal: 3m 31s\tremaining: 31m 26s\n",
      "200:\ttest: 0.3909221\tbest: 0.3909454 (199)\ttotal: 7m 2s\tremaining: 27m 57s\n",
      "300:\ttest: 0.3948607\tbest: 0.3948607 (300)\ttotal: 10m 30s\tremaining: 24m 23s\n",
      "400:\ttest: 0.3960339\tbest: 0.3960339 (400)\ttotal: 13m 58s\tremaining: 20m 53s\n",
      "500:\ttest: 0.3971053\tbest: 0.3973588 (499)\ttotal: 17m 27s\tremaining: 17m 23s\n",
      "600:\ttest: 0.3982682\tbest: 0.3983107 (599)\ttotal: 20m 56s\tremaining: 13m 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 03:30:00,408] Trial 11 finished with value: 0.39881597240773276 and parameters: {'learning_rate': 0.08406208900443744, 'depth': 10, 'l2_leaf_reg': 1.6269951399649503, 'random_strength': 0.02262538684180315, 'bagging_temperature': 0.24657580940559032, 'border_count': 206}. Best is trial 11 with value: 0.39881597240773276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (30 iterations wait)\n",
      "\n",
      "bestTest = 0.3988159724\n",
      "bestIteration = 646\n",
      "\n",
      "Shrink model to first 647 iterations.\n",
      "Best PFound: 0.39881597240773276\n",
      "Best hyperparameters:\n",
      "  learning_rate: 0.08406208900443744\n",
      "  depth: 10\n",
      "  l2_leaf_reg: 1.6269951399649503\n",
      "  random_strength: 0.02262538684180315\n",
      "  bagging_temperature: 0.24657580940559032\n",
      "  border_count: 206\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params_cat = {\n",
    "        'loss_function': 'YetiRank',\n",
    "        'eval_metric': 'NDCG:top=5',\n",
    "        'random_seed': 5,\n",
    "        'od_type': 'Iter',\n",
    "        'od_wait': 20,\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int(\"depth\", 6, 12),\n",
    "        'l2_leaf_reg': trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10.0, log=True),\n",
    "        'random_strength': trial.suggest_float(\"random_strength\", 1e-3, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "        'border_count': trial.suggest_int(\"border_count\", 32, 255),\n",
    "        'iterations': 1000,\n",
    "        'use_best_model': True,\n",
    "        'verbose': 100,\n",
    "    }\n",
    "\n",
    "    model_cat = CatBoostRanker(**params_cat)\n",
    "\n",
    "    # Pruner callback for PFound\n",
    "    pruning_callback = CatBoostPruningCallback(trial, 'NDCG:top=5;type=Base')\n",
    "\n",
    "\n",
    "    model_cat.fit(\n",
    "        train_pool,\n",
    "        eval_set=val_pool,\n",
    "        early_stopping_rounds=30,\n",
    "        callbacks=[pruning_callback],\n",
    "    )\n",
    "\n",
    "    # Manually trigger pruning\n",
    "    pruning_callback.check_pruned()\n",
    "\n",
    "     # 5) Grab the best‐iteration score\n",
    "    hist = model_cat.get_evals_result()['validation']['NDCG:top=5;type=Base']\n",
    "    return max(hist) \n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"catboost_yetirank\",\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    ")\n",
    "study.optimize(objective, n_trials=60, timeout=9800)\n",
    "\n",
    "print(f\"Best PFound: {study.best_trial.value}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for k, v in study.best_trial.params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fff8cf2-1c00-4142-963c-7814bd9db8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 1) Print your Optuna CV results\\nbest_params_cat = study.best_trial.params\\nbest_ndcg5      = study.best_trial.value\\nprint(f\"Best CV NDCG@5 (Optuna): {best_ndcg5:.4f}\")\\nprint(\"Best hyperparameters:\")\\nfor k, v in best_params_cat.items():\\n    print(f\"  {k}: {v}\")\\n\\n# 4) Immediately pull out that best_iteration\\n\\nbest_iter = full_model.get_best_iteration()\\nprint(f\"▶️  Early stopping picked {best_iter} iterations\")\\n\\n\\n# 2) Build final model stub\\nfinal_model = CatBoostRanker(\\n    loss_function    = \\'YetiRank\\',\\n    eval_metric      = \\'NDCG:top=5\\',\\n    random_seed      = 22,\\n    use_best_model   = False,     # we’re fixing the tree count manually\\n    iterations       = best_iter,\\n    verbose          = 100,\\n    **best_params_cat\\n)\\n\\n# 3) Fit on the full Pool, with no early stopping or eval_set\\nfinal_model.fit(full_pool)  \\n\\n# 4) Predict on your test set\\ncat_test_preds = final_model.predict(X_test)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 1) Print your Optuna CV results\n",
    "best_params_cat = study.best_trial.params\n",
    "best_ndcg5      = study.best_trial.value\n",
    "print(f\"Best CV NDCG@5 (Optuna): {best_ndcg5:.4f}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for k, v in best_params_cat.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# 4) Immediately pull out that best_iteration\n",
    "\n",
    "best_iter = full_model.get_best_iteration()\n",
    "print(f\"▶️  Early stopping picked {best_iter} iterations\")\n",
    "\n",
    "\n",
    "# 2) Build final model stub\n",
    "final_model = CatBoostRanker(\n",
    "    loss_function    = 'YetiRank',\n",
    "    eval_metric      = 'NDCG:top=5',\n",
    "    random_seed      = 22,\n",
    "    use_best_model   = False,     # we’re fixing the tree count manually\n",
    "    iterations       = best_iter,\n",
    "    verbose          = 100,\n",
    "    **best_params_cat\n",
    ")\n",
    "\n",
    "# 3) Fit on the full Pool, with no early stopping or eval_set\n",
    "final_model.fit(full_pool)  \n",
    "\n",
    "# 4) Predict on your test set\n",
    "cat_test_preds = final_model.predict(X_test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93c6ad64-5139-4b3f-9cf7-c28213d1a75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV NDCG@5 (Optuna): 0.3988\n",
      "Best hyperparameters:\n",
      "  learning_rate: 0.08406208900443744\n",
      "  depth: 10\n",
      "  l2_leaf_reg: 1.6269951399649503\n",
      "  random_strength: 0.02262538684180315\n",
      "  bagging_temperature: 0.24657580940559032\n",
      "  border_count: 206\n",
      "0:\ttest: 0.3044585\tbest: 0.3044585 (0)\ttotal: 2.97s\tremaining: 44m 31s\n",
      "100:\ttest: 0.3946974\tbest: 0.3946974 (100)\ttotal: 4m 30s\tremaining: 35m 37s\n",
      "200:\ttest: 0.4046401\tbest: 0.4046401 (200)\ttotal: 8m 54s\tremaining: 30m 57s\n",
      "300:\ttest: 0.4129879\tbest: 0.4129879 (300)\ttotal: 13m 21s\tremaining: 26m 34s\n",
      "400:\ttest: 0.4204083\tbest: 0.4204083 (400)\ttotal: 17m 46s\tremaining: 22m 6s\n",
      "500:\ttest: 0.4276690\tbest: 0.4276690 (500)\ttotal: 22m 11s\tremaining: 17m 40s\n",
      "600:\ttest: 0.4341641\tbest: 0.4341641 (600)\ttotal: 26m 37s\tremaining: 13m 14s\n",
      "700:\ttest: 0.4397404\tbest: 0.4397404 (700)\ttotal: 31m 3s\tremaining: 8m 48s\n",
      "800:\ttest: 0.4452136\tbest: 0.4452136 (800)\ttotal: 35m 27s\tremaining: 4m 22s\n",
      "899:\ttest: 0.4500571\tbest: 0.4500571 (899)\ttotal: 39m 50s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4500570692\n",
      "bestIteration = 899\n",
      "\n",
      "▶️  Early stopping picked 899 iterations\n",
      "0:\ttotal: 2.72s\tremaining: 40m 40s\n",
      "100:\ttotal: 4m 25s\tremaining: 34m 58s\n",
      "200:\ttotal: 8m 43s\tremaining: 30m 17s\n",
      "300:\ttotal: 13m 2s\tremaining: 25m 54s\n",
      "400:\ttotal: 17m 21s\tremaining: 21m 33s\n",
      "500:\ttotal: 21m 40s\tremaining: 17m 13s\n",
      "600:\ttotal: 25m 59s\tremaining: 12m 53s\n",
      "700:\ttotal: 30m 18s\tremaining: 8m 33s\n",
      "800:\ttotal: 34m 37s\tremaining: 4m 14s\n",
      "898:\ttotal: 38m 50s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# 1) After Optuna, get your best‐found params and CV score\n",
    "best_params_cat = study.best_trial.params\n",
    "best_ndcg5      = study.best_trial.value\n",
    "print(f\"Best CV NDCG@5 (Optuna): {best_ndcg5:.4f}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for k, v in best_params_cat.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# 2) Build a “big” model stub on full data with early stopping\n",
    "full_model = CatBoostRanker(\n",
    "    loss_function  = 'YetiRank',\n",
    "    eval_metric    = 'NDCG:top=5',\n",
    "    random_seed    = 22,\n",
    "    use_best_model = True,      # enable early stopping\n",
    "    iterations     = 1000,      # generous upper bound\n",
    "    verbose        = 100,\n",
    "    **best_params_cat           # your Optuna‐tuned hyperparams\n",
    ")\n",
    "# 3) Fit on the FULL pool as its own eval_set\n",
    "full_model.fit(\n",
    "    full_pool,\n",
    "    eval_set=full_pool,\n",
    "    early_stopping_rounds=20,\n",
    ")\n",
    "best_iter = full_model.get_best_iteration()\n",
    "print(f\"▶️  Early stopping picked {best_iter} iterations\")\n",
    "\n",
    "# 4) Now re‐instantiate EXACTLY that many trees (no early stopping)\n",
    "final_model_big = CatBoostRanker(\n",
    "    loss_function  = 'YetiRank',\n",
    "    eval_metric    = 'NDCG:top=5',\n",
    "    random_seed    = 22,\n",
    "    iterations     = best_iter, # freeze at the optimal point\n",
    "    use_best_model = False,     # no more early stopping\n",
    "    verbose        = 100,\n",
    "    **best_params_cat\n",
    ")\n",
    "final_model_big.fit(full_pool)\n",
    "\n",
    "# 5) Finally predict on test\n",
    "cat_test_preds_big = final_model_big.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "79ada07e-f959-4685-9006-2d37dbcd7a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv written using lgb only!\n"
     ]
    }
   ],
   "source": [
    "# 2) Put them into your submission\n",
    "\n",
    "#can use cat_test_pred or lgb_test_preds\n",
    "\n",
    "sample['score'] = cat_test_preds_big\n",
    "submission = (\n",
    "    sample\n",
    "    .sort_values(['srch_id', 'score'], ascending=[True, False])\n",
    "    [['srch_id', 'prop_id']]\n",
    ")\n",
    "\n",
    "# 3) Write to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission.csv written using lgb only!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3eb20bf6-7ab7-4a2c-9572-727a7e61005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost Val NDCG@5: 0.4486\n",
      "\n",
      "LightGBM Val NDCG@5: 0.4832\n"
     ]
    }
   ],
   "source": [
    "# 1. Predict raw scores for the validation set\n",
    "cat_val_preds = final_model_big.predict(X_va)\n",
    "lgb_val_preds = model_lgb_full.predict(X_va)\n",
    "\n",
    "# 2. Compute per-session NDCG@5 manually\n",
    "ndcgs_cat = []\n",
    "ndcgs_lgb = []\n",
    "\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:  # skip sessions with only 1 result\n",
    "        true_rels = y_va[idx]\n",
    "        ndcgs_cat.append(ndcg_score([true_rels], [cat_val_preds[idx]], k=5))\n",
    "        ndcgs_lgb.append(ndcg_score([true_rels], [lgb_val_preds[idx]], k=5))\n",
    "\n",
    "# 3. Average NDCG@5 for both models\n",
    "catboost_ndcg5 = np.mean(ndcgs_cat)\n",
    "lgb_ndcg5 = np.mean(ndcgs_lgb)\n",
    "\n",
    "print(f\"\\nCatBoost Val NDCG@5: {catboost_ndcg5:.4f}\")\n",
    "print(f\"\\nLightGBM Val NDCG@5: {lgb_ndcg5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6991fd44-41cb-4f3c-8643-bb5f041603a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_cb=0.0, w_lgb=1.0 → Val NDCG@5: 0.4832\n",
      "w_cb=0.1, w_lgb=0.9 → Val NDCG@5: 0.4794\n",
      "w_cb=0.2, w_lgb=0.8 → Val NDCG@5: 0.4754\n",
      "w_cb=0.3, w_lgb=0.7 → Val NDCG@5: 0.4718\n",
      "w_cb=0.4, w_lgb=0.6 → Val NDCG@5: 0.4681\n",
      "w_cb=0.5, w_lgb=0.5 → Val NDCG@5: 0.4644\n",
      "w_cb=0.6, w_lgb=0.4 → Val NDCG@5: 0.4606\n",
      "w_cb=0.7, w_lgb=0.3 → Val NDCG@5: 0.4576\n",
      "w_cb=0.8, w_lgb=0.2 → Val NDCG@5: 0.4546\n",
      "w_cb=0.9, w_lgb=0.1 → Val NDCG@5: 0.4519\n",
      "w_cb=1.0, w_lgb=0.0 → Val NDCG@5: 0.4486\n",
      "\n",
      " Best blend (CB+LGB): w_cb=0.00, w_lgb=1.00 → NDCG@5=0.4832\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1) Scale just your two tree-based model preds on validation\n",
    "cb_s  = minmax(cat_val_preds)   # your CatBoost val preds\n",
    "lgb_s = minmax(lgb_val_preds)   # your LightGBM val preds\n",
    "\n",
    "# 2) Sweep over blends of just CB + LGB\n",
    "best, best_w = 0, None\n",
    "for w_cb in np.linspace(0, 1, 11):\n",
    "    w_lgb = 1 - w_cb\n",
    "    sc = w_cb * cb_s + w_lgb * lgb_s\n",
    "\n",
    "    # compute NDCG@5 on val\n",
    "    ndcgs = []\n",
    "    for q in np.unique(id_va):\n",
    "        idx = np.where(id_va == q)[0]\n",
    "        if len(idx) > 1:\n",
    "            true = y_va[idx]\n",
    "            ndcgs.append(ndcg_score([true], [sc[idx]], k=5))\n",
    "    mean_ndcg = np.mean(ndcgs)\n",
    "\n",
    "    print(f\"w_cb={w_cb:.1f}, w_lgb={w_lgb:.1f} → Val NDCG@5: {mean_ndcg:.4f}\")\n",
    "    if mean_ndcg > best:\n",
    "        best, best_w = mean_ndcg, (w_cb, w_lgb)\n",
    "\n",
    "print(f\"\\n Best blend (CB+LGB): w_cb={best_w[0]:.2f}, w_lgb={best_w[1]:.2f} → NDCG@5={best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30e54659-6f48-4d9e-94ac-fecb7f8d15cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission.csv written using w_cb=0.40, w_lgb=0.60!\n"
     ]
    }
   ],
   "source": [
    "# --- Ensemble the test predictions with your optimal blend ---\n",
    "best_w = [0.4,0.6]\n",
    "\n",
    "ensemble_final_preds = ensemble_predictions(\n",
    "    cat_test_preds_big,\n",
    "    lgb_test_preds,\n",
    "    weights=[best_w[0], best_w[1]]\n",
    ")\n",
    "\n",
    "# Put them into submission\n",
    "sample['score'] = ensemble_final_preds\n",
    "submission = (\n",
    "    sample\n",
    "    .sort_values(['srch_id','score'], ascending=[True, False])\n",
    "    [['srch_id','prop_id']]\n",
    ")\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission.csv written using w_cb={best_w[0]:.2f}, w_lgb={best_w[1]:.2f}!\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b65ccd16-188e-40cc-8d80-e176c305925a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# --- 1) ListNet loss (unchanged) ---\\ndef listnet_loss(scores, labels, group_ids):\\n    loss, count = 0.0, 0\\n    for q in np.unique(group_ids):\\n        idx = np.where(group_ids == q)[0]\\n        if len(idx) < 2:\\n            continue\\n        s_q, y_q = scores[idx], labels[idx].float()\\n        P, P_hat = torch.softmax(y_q, 0), torch.softmax(s_q, 0)\\n        loss += -torch.sum(P * torch.log(P_hat + 1e-8))\\n        count += 1\\n    return loss / max(count, 1)\\n\\nparam_grid = {\\n    \\'lr\\':           [1e-3, 2e-3],\\n    \\'batch_size\\':   [512, 1024],\\n    \\'dropout\\':      [0.1, 0.2],\\n    \\'weight_decay\\': [0.0, 1e-4]\\n}\\n\\nbest = {\\'ndcg\\': 0.0, \\'cfg\\': None}\\n\\nfor lr, bs, drop, wd in itertools.product(*param_grid.values()):\\n    tr_loader = DataLoader(ExpediaDataset(X_tr, y_tr.values),\\n                           batch_size=bs, shuffle=True)\\n    va_loader = DataLoader(ExpediaDataset(X_va, y_va.values),\\n                           batch_size=bs, shuffle=False)\\n\\n    mdl = DeepRecommender(X_tr.shape[1]).to(device)\\n    for m in mdl.modules():\\n        if isinstance(m, nn.Dropout):\\n            m.p = drop\\n\\n    opt = torch.optim.Adam(\\n        mdl.parameters(),\\n        lr=lr,\\n        weight_decay=wd\\n    )\\n    sched = torch.optim.lr_scheduler.OneCycleLR(\\n        opt,\\n        max_lr=lr * 10,\\n        steps_per_epoch=len(tr_loader),\\n        epochs=10\\n    )\\n\\n    best_ndcg, stale = 0.0, 0\\n    for epoch in range(1, 8):\\n        # — train —\\n        mdl.train()\\n        for Xb, yb in tr_loader:\\n            Xb, yb = Xb.to(device), yb.to(device)\\n            opt.zero_grad()\\n            loss = listnet_loss(mdl(Xb), yb, id_tr[:len(Xb)])\\n            loss.backward()\\n            opt.step()\\n\\n        # — validate —\\n        mdl.eval()\\n        preds = []\\n        with torch.no_grad():\\n            for Xb, _ in va_loader:\\n                preds.extend(mdl(Xb.to(device)).cpu().numpy())\\n        preds = np.array(preds)\\n\\n        # compute mean NDCG@5 using the same y_va array\\n        ndcgs = []\\n        for q in np.unique(id_va):\\n            idx = np.where(id_va == q)[0]\\n            if len(idx) > 1:\\n                true = y_va.values[idx]\\n                score = preds[idx]\\n                ndcgs.append(ndcg_score([true], [score], k=5))\\n        mean_ndcg = np.mean(ndcgs)\\n        sched.step(mean_ndcg)\\n\\n        if mean_ndcg > best_ndcg + 1e-4:\\n            best_ndcg, stale = mean_ndcg, 0\\n        else:\\n            stale += 1\\n        if stale >= 5:\\n            break\\n\\n    print(f\"cfg lr={lr}, bs={bs}, drop={drop} → Val NDCG@5: {best_ndcg:.4f}\")\\n    if best_ndcg > best[\\'ndcg\\']:\\n        best.update({\\'ndcg\\': best_ndcg, \\'cfg\\': (lr, bs, drop)})\\n\\nprint(\"🏆 Best config:\", best)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# --- 1) ListNet loss (unchanged) ---\n",
    "def listnet_loss(scores, labels, group_ids):\n",
    "    loss, count = 0.0, 0\n",
    "    for q in np.unique(group_ids):\n",
    "        idx = np.where(group_ids == q)[0]\n",
    "        if len(idx) < 2:\n",
    "            continue\n",
    "        s_q, y_q = scores[idx], labels[idx].float()\n",
    "        P, P_hat = torch.softmax(y_q, 0), torch.softmax(s_q, 0)\n",
    "        loss += -torch.sum(P * torch.log(P_hat + 1e-8))\n",
    "        count += 1\n",
    "    return loss / max(count, 1)\n",
    "\n",
    "param_grid = {\n",
    "    'lr':           [1e-3, 2e-3],\n",
    "    'batch_size':   [512, 1024],\n",
    "    'dropout':      [0.1, 0.2],\n",
    "    'weight_decay': [0.0, 1e-4]\n",
    "}\n",
    "\n",
    "best = {'ndcg': 0.0, 'cfg': None}\n",
    "\n",
    "for lr, bs, drop, wd in itertools.product(*param_grid.values()):\n",
    "    tr_loader = DataLoader(ExpediaDataset(X_tr, y_tr.values),\n",
    "                           batch_size=bs, shuffle=True)\n",
    "    va_loader = DataLoader(ExpediaDataset(X_va, y_va.values),\n",
    "                           batch_size=bs, shuffle=False)\n",
    "\n",
    "    mdl = DeepRecommender(X_tr.shape[1]).to(device)\n",
    "    for m in mdl.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.p = drop\n",
    "\n",
    "    opt = torch.optim.Adam(\n",
    "        mdl.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=wd\n",
    "    )\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt,\n",
    "        max_lr=lr * 10,\n",
    "        steps_per_epoch=len(tr_loader),\n",
    "        epochs=10\n",
    "    )\n",
    "\n",
    "    best_ndcg, stale = 0.0, 0\n",
    "    for epoch in range(1, 8):\n",
    "        # — train —\n",
    "        mdl.train()\n",
    "        for Xb, yb in tr_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = listnet_loss(mdl(Xb), yb, id_tr[:len(Xb)])\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        # — validate —\n",
    "        mdl.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for Xb, _ in va_loader:\n",
    "                preds.extend(mdl(Xb.to(device)).cpu().numpy())\n",
    "        preds = np.array(preds)\n",
    "\n",
    "        # compute mean NDCG@5 using the same y_va array\n",
    "        ndcgs = []\n",
    "        for q in np.unique(id_va):\n",
    "            idx = np.where(id_va == q)[0]\n",
    "            if len(idx) > 1:\n",
    "                true = y_va.values[idx]\n",
    "                score = preds[idx]\n",
    "                ndcgs.append(ndcg_score([true], [score], k=5))\n",
    "        mean_ndcg = np.mean(ndcgs)\n",
    "        sched.step(mean_ndcg)\n",
    "\n",
    "        if mean_ndcg > best_ndcg + 1e-4:\n",
    "            best_ndcg, stale = mean_ndcg, 0\n",
    "        else:\n",
    "            stale += 1\n",
    "        if stale >= 5:\n",
    "            break\n",
    "\n",
    "    print(f\"cfg lr={lr}, bs={bs}, drop={drop} → Val NDCG@5: {best_ndcg:.4f}\")\n",
    "    if best_ndcg > best['ndcg']:\n",
    "        best.update({'ndcg': best_ndcg, 'cfg': (lr, bs, drop)})\n",
    "\n",
    "print(\"🏆 Best config:\", best)\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4855e15-4c6b-492f-a267-979ef406a160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ef09feb-986f-496e-a691-8fedcee3d030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# unpack your best cfg and tweak\\nlr, bs, drop, wd = 1e-3, 128, 0.1, 1e-5\\n\\n# rebuild full-training loader\\nfull_loader = DataLoader(\\n    ExpediaDatasetGrouped(X_full, y_full, id_full),\\n    batch_size=bs, shuffle=True\\n)\\n\\n# 1) Slightly larger network at the top\\nclass BiggerRecommender(nn.Module):\\n    def __init__(self, input_dim):\\n        super().__init__()\\n        self.net = nn.Sequential(\\n            nn.Linear(input_dim, 512), nn.ReLU(), nn.BatchNorm1d(512), nn.Dropout(drop),\\n            nn.Linear(512, 256), nn.ReLU(), nn.BatchNorm1d(256), nn.Dropout(drop),\\n            nn.Linear(256, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(drop),\\n            nn.Linear(128, 64),  nn.ReLU(), nn.Dropout(drop),\\n            nn.Linear(64, 1)\\n        )\\n    def forward(self, x):\\n        return self.net(x).squeeze(1)\\n\\nfinal_nn = BiggerRecommender(X_full.shape[1]).to(device)\\n\\n# 2) Optimizer with very light weight decay\\nopt = torch.optim.Adam(final_nn.parameters(), lr=lr, weight_decay=wd)\\n\\n# 3) Simpler stepLR scheduler (cuts LR by 0.5 every 10 epochs)\\nsched = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.5)\\n\\n# 4) Train for 30 epochs with gradient clipping\\nfor epoch in range(1, 31):\\n    final_nn.train()\\n    total_loss = 0.0\\n    for Xb, yb, gb in full_loader:\\n        Xb, yb = Xb.to(device), yb.to(device)\\n\\n        opt.zero_grad()\\n        logits = final_nn(Xb)\\n        loss   = listnet_loss(logits, yb, gb)  \\n        loss.backward()\\n        torch.nn.utils.clip_grad_norm_(final_nn.parameters(), 5.0)\\n        opt.step()\\n\\n        total_loss += loss.item() * Xb.size(0)\\n\\n    sched.step()\\n    avg_loss = total_loss / len(full_loader.dataset)\\n    print(f\"Epoch {epoch:02d}/30 — Avg ListNet Loss: {avg_loss:.4f} — LR: {opt.param_groups[0][\\'lr\\']:.1e}\")\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# unpack your best cfg and tweak\n",
    "lr, bs, drop, wd = 1e-3, 128, 0.1, 1e-5\n",
    "\n",
    "# rebuild full-training loader\n",
    "full_loader = DataLoader(\n",
    "    ExpediaDatasetGrouped(X_full, y_full, id_full),\n",
    "    batch_size=bs, shuffle=True\n",
    ")\n",
    "\n",
    "# 1) Slightly larger network at the top\n",
    "class BiggerRecommender(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512), nn.ReLU(), nn.BatchNorm1d(512), nn.Dropout(drop),\n",
    "            nn.Linear(512, 256), nn.ReLU(), nn.BatchNorm1d(256), nn.Dropout(drop),\n",
    "            nn.Linear(256, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(drop),\n",
    "            nn.Linear(128, 64),  nn.ReLU(), nn.Dropout(drop),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "final_nn = BiggerRecommender(X_full.shape[1]).to(device)\n",
    "\n",
    "# 2) Optimizer with very light weight decay\n",
    "opt = torch.optim.Adam(final_nn.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "# 3) Simpler stepLR scheduler (cuts LR by 0.5 every 10 epochs)\n",
    "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.5)\n",
    "\n",
    "# 4) Train for 30 epochs with gradient clipping\n",
    "for epoch in range(1, 31):\n",
    "    final_nn.train()\n",
    "    total_loss = 0.0\n",
    "    for Xb, yb, gb in full_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = final_nn(Xb)\n",
    "        loss   = listnet_loss(logits, yb, gb)  \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(final_nn.parameters(), 5.0)\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item() * Xb.size(0)\n",
    "\n",
    "    sched.step()\n",
    "    avg_loss = total_loss / len(full_loader.dataset)\n",
    "    print(f\"Epoch {epoch:02d}/30 — Avg ListNet Loss: {avg_loss:.4f} — LR: {opt.param_groups[0]['lr']:.1e}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5f70ffb-f18d-43e7-a272-cbc58ee1c83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# --- 4) Produce final test preds ---\\ntest_loader = DataLoader(\\n    ExpediaDataset(X_test, np.zeros(len(X_test))),\\n    batch_size=bs,\\n    shuffle=False\\n)\\n\\nnn_test_preds = []\\nfinal_nn.eval()\\nwith torch.no_grad():\\n    for Xb, _ in test_loader:           # <-- unpack both X and dummy y\\n        Xb = Xb.to(device)\\n        nn_test_preds.extend(\\n            torch.sigmoid(final_nn(Xb))\\n                 .cpu()\\n                 .numpy()\\n        )\\nnn_test_preds = np.array(nn_test_preds)\\n\\nprint(\"NN preds:\", nn_test_preds.min(), nn_test_preds.max())\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# --- 4) Produce final test preds ---\n",
    "test_loader = DataLoader(\n",
    "    ExpediaDataset(X_test, np.zeros(len(X_test))),\n",
    "    batch_size=bs,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "nn_test_preds = []\n",
    "final_nn.eval()\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in test_loader:           # <-- unpack both X and dummy y\n",
    "        Xb = Xb.to(device)\n",
    "        nn_test_preds.extend(\n",
    "            torch.sigmoid(final_nn(Xb))\n",
    "                 .cpu()\n",
    "                 .numpy()\n",
    "        )\n",
    "nn_test_preds = np.array(nn_test_preds)\n",
    "\n",
    "print(\"NN preds:\", nn_test_preds.min(), nn_test_preds.max())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e90180b4-66a8-435f-ad08-d1a9af7af2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# 1) Get NN probabilities on the validation fold\\nnn_val_probs = []\\nfinal_nn.eval()\\nwith torch.no_grad():\\n    for Xb, _ in va_loader:\\n        nn_val_probs.extend(\\n            torch.sigmoid(final_nn(Xb.to(device)))\\n            .cpu()\\n            .numpy()\\n        )\\nnn_val_probs = np.array(nn_val_probs)  # shape = (n_val,)\\n\\n# 2) Compute per-session NDCG@5\\nndcgs = []\\nfor q in np.unique(id_va):\\n    idx = np.where(id_va == q)[0]\\n    if len(idx) > 1:\\n        true_rels = y_val_nn[idx]\\n        scores    = nn_val_probs[idx]\\n        ndcgs.append(ndcg_score([true_rels], [scores], k=5))\\n\\nnn_val_ndcg5 = np.mean(ndcgs)\\nprint(f\"NN  Val NDCG@5: {nn_val_ndcg5:.4f}\")\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 1) Get NN probabilities on the validation fold\n",
    "nn_val_probs = []\n",
    "final_nn.eval()\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in va_loader:\n",
    "        nn_val_probs.extend(\n",
    "            torch.sigmoid(final_nn(Xb.to(device)))\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "nn_val_probs = np.array(nn_val_probs)  # shape = (n_val,)\n",
    "\n",
    "# 2) Compute per-session NDCG@5\n",
    "ndcgs = []\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:\n",
    "        true_rels = y_val_nn[idx]\n",
    "        scores    = nn_val_probs[idx]\n",
    "        ndcgs.append(ndcg_score([true_rels], [scores], k=5))\n",
    "\n",
    "nn_val_ndcg5 = np.mean(ndcgs)\n",
    "print(f\"NN  Val NDCG@5: {nn_val_ndcg5:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8af293dc-e382-4a3a-bee5-e767a32048c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# --- Ensemble the predictions ---\\nensemble_final_preds = ensemble_predictions(nn_test_preds, model_lgb_pred, weights=[0.5, 0.5]) # Adjust weights\\n\\n# Predict relevance scores for each test row\\npreds_ens = ensemble_final_preds\\n\\n# Insert those scores into the sample submission DataFrame\\nsample[\\'score\\'] = preds_ens\\n\\n# Sort by search session (ascending) and score (descending)\\n#   so that for each srch_id, the most relevant prop_id comes first\\nsubmission = sample.sort_values(\\n    [\\'srch_id\\', \\'score\\'],\\n    ascending=[True, False]\\n)\\n\\n# keep only the required columns and write to CSV\\n#   Kaggle expects: srch_id, prop_id (in ranked order)\\nsubmission[[\\'srch_id\\', \\'prop_id\\']].to_csv(\\n    \\'submission.csv\\',\\n    index=False\\n)\\nprint(\"Submission.csv adjusted with new scores!\")'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# --- Ensemble the predictions ---\n",
    "ensemble_final_preds = ensemble_predictions(nn_test_preds, model_lgb_pred, weights=[0.5, 0.5]) # Adjust weights\n",
    "\n",
    "# Predict relevance scores for each test row\n",
    "preds_ens = ensemble_final_preds\n",
    "\n",
    "# Insert those scores into the sample submission DataFrame\n",
    "sample['score'] = preds_ens\n",
    "\n",
    "# Sort by search session (ascending) and score (descending)\n",
    "#   so that for each srch_id, the most relevant prop_id comes first\n",
    "submission = sample.sort_values(\n",
    "    ['srch_id', 'score'],\n",
    "    ascending=[True, False]\n",
    ")\n",
    "\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38d3c1e5-a601-4f56-b331-cfbce1e4753a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 1) LightGBM val set predictions\\n# Replace `model_lgb` with whatever variable you named your trained LightGBM model\\nval_preds_lgb = model_lgb.predict(X_va)   # shape = (n_val,)\\n\\n# 2) NN val set predictions\\nfinal_nn.eval()\\nnn_val_preds = []\\nwith torch.no_grad():\\n    for Xb, _ in va_loader:  # va_loader from your NN split on X_va/y_va\\n        nn_val_preds.extend(\\n            torch.sigmoid(final_nn(Xb.to(device))).cpu().numpy()\\n        )\\nnn_val_preds = np.array(nn_val_preds)      # shape = (n_val,)\\n\\n# 3) Blend them\\nw_nn, w_lgb = 0.4, 0.6\\nensemble_val = w_nn * nn_val_preds + w_lgb * val_preds_lgb\\n\\n\\nndcgs = []\\nfor q in np.unique(id_va):\\n    idx = np.where(id_va == q)[0]\\n    if len(idx) > 1:\\n        true_rel  = y_val_nn[idx]    # your val labels array\\n        score_rel = ensemble_val[idx]\\n        ndcgs.append(ndcg_score([true_rel], [score_rel], k=5))\\n\\nmean_ndcg5 = np.mean(ndcgs)\\nprint(f\"Ensembled Val NDCG@5: {mean_ndcg5:.4f}\")\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 1) LightGBM val set predictions\n",
    "# Replace `model_lgb` with whatever variable you named your trained LightGBM model\n",
    "val_preds_lgb = model_lgb.predict(X_va)   # shape = (n_val,)\n",
    "\n",
    "# 2) NN val set predictions\n",
    "final_nn.eval()\n",
    "nn_val_preds = []\n",
    "with torch.no_grad():\n",
    "    for Xb, _ in va_loader:  # va_loader from your NN split on X_va/y_va\n",
    "        nn_val_preds.extend(\n",
    "            torch.sigmoid(final_nn(Xb.to(device))).cpu().numpy()\n",
    "        )\n",
    "nn_val_preds = np.array(nn_val_preds)      # shape = (n_val,)\n",
    "\n",
    "# 3) Blend them\n",
    "w_nn, w_lgb = 0.4, 0.6\n",
    "ensemble_val = w_nn * nn_val_preds + w_lgb * val_preds_lgb\n",
    "\n",
    "\n",
    "ndcgs = []\n",
    "for q in np.unique(id_va):\n",
    "    idx = np.where(id_va == q)[0]\n",
    "    if len(idx) > 1:\n",
    "        true_rel  = y_val_nn[idx]    # your val labels array\n",
    "        score_rel = ensemble_val[idx]\n",
    "        ndcgs.append(ndcg_score([true_rel], [score_rel], k=5))\n",
    "\n",
    "mean_ndcg5 = np.mean(ndcgs)\n",
    "print(f\"Ensembled Val NDCG@5: {mean_ndcg5:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad35a973-a5cc-4f52-afb4-b8ae2f7b9630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# 1) Min–max scale each prediction array into [0,1]\\ndef minmax(arr):\\n    return (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\\n\\nnn_scaled  = minmax(nn_test_preds)\\nlgb_scaled = minmax(model_lgb_pred)   # or whatever your LGB test‐preds variable is\\n\\n# 2) Do the two blends\\nens1 = ensemble_predictions(nn_scaled, lgb_scaled, [0.5, 0.5])\\nens2 = ensemble_predictions(nn_scaled, lgb_scaled, [0.0, 1.0])\\n\\n# 3) Compare their sorted‐order permutations\\norder1 = np.argsort(ens1)\\norder2 = np.argsort(ens2)\\n\\n# 4) Compute fraction of positions that differ\\nfraction_changed = np.mean(order1 != order2)\\nprint(f\"Fraction of test‐rows whose position changes: {fraction_changed:.4%}\")\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 1) Min–max scale each prediction array into [0,1]\n",
    "def minmax(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
    "\n",
    "nn_scaled  = minmax(nn_test_preds)\n",
    "lgb_scaled = minmax(model_lgb_pred)   # or whatever your LGB test‐preds variable is\n",
    "\n",
    "# 2) Do the two blends\n",
    "ens1 = ensemble_predictions(nn_scaled, lgb_scaled, [0.5, 0.5])\n",
    "ens2 = ensemble_predictions(nn_scaled, lgb_scaled, [0.0, 1.0])\n",
    "\n",
    "# 3) Compare their sorted‐order permutations\n",
    "order1 = np.argsort(ens1)\n",
    "order2 = np.argsort(ens2)\n",
    "\n",
    "# 4) Compute fraction of positions that differ\n",
    "fraction_changed = np.mean(order1 != order2)\n",
    "print(f\"Fraction of test‐rows whose position changes: {fraction_changed:.4%}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33d5d100-acc8-4754-9d9b-853cd760f831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# 0) Scale both NN & LGB validation predictions into [0,1]\\nnn_scaled_val  = minmax_scale(nn_val_preds)      # shape = (n_val,)\\nlgb_scaled_val = minmax_scale(val_preds_lgb)     # shape = (n_val,)\\n\\nbest_w, best_score = None, 0.0\\nfor w_nn in np.linspace(0, 1, 11):\\n    w_lgb = 1 - w_nn\\n\\n    # blended on the same [0,1] scale\\n    blended = w_nn * nn_scaled_val + w_lgb * lgb_scaled_val\\n\\n    # compute NDCG@5 per session\\n    ndcgs = []\\n    for q in np.unique(id_va):\\n        idx = np.where(id_va == q)[0]\\n        if len(idx) > 1:\\n            true   = y_val_nn[idx]\\n            scores = blended[idx]\\n            ndcgs.append(ndcg_score([true], [scores], k=5))\\n    mean_ndcg = np.mean(ndcgs)\\n\\n    print(f\"w_nn={w_nn:.1f}, w_lgb={w_lgb:.1f} → Val NDCG@5: {mean_ndcg:.4f}\")\\n    if mean_ndcg > best_score:\\n        best_score, best_w = mean_ndcg, w_nn\\n\\nprint(f\"\\n🏆 Best blend: w_nn={best_w:.2f}, w_lgb={1-best_w:.2f} → NDCG@5={best_score:.4f}\")\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 0) Scale both NN & LGB validation predictions into [0,1]\n",
    "nn_scaled_val  = minmax_scale(nn_val_preds)      # shape = (n_val,)\n",
    "lgb_scaled_val = minmax_scale(val_preds_lgb)     # shape = (n_val,)\n",
    "\n",
    "best_w, best_score = None, 0.0\n",
    "for w_nn in np.linspace(0, 1, 11):\n",
    "    w_lgb = 1 - w_nn\n",
    "\n",
    "    # blended on the same [0,1] scale\n",
    "    blended = w_nn * nn_scaled_val + w_lgb * lgb_scaled_val\n",
    "\n",
    "    # compute NDCG@5 per session\n",
    "    ndcgs = []\n",
    "    for q in np.unique(id_va):\n",
    "        idx = np.where(id_va == q)[0]\n",
    "        if len(idx) > 1:\n",
    "            true   = y_val_nn[idx]\n",
    "            scores = blended[idx]\n",
    "            ndcgs.append(ndcg_score([true], [scores], k=5))\n",
    "    mean_ndcg = np.mean(ndcgs)\n",
    "\n",
    "    print(f\"w_nn={w_nn:.1f}, w_lgb={w_lgb:.1f} → Val NDCG@5: {mean_ndcg:.4f}\")\n",
    "    if mean_ndcg > best_score:\n",
    "        best_score, best_w = mean_ndcg, w_nn\n",
    "\n",
    "print(f\"\\n🏆 Best blend: w_nn={best_w:.2f}, w_lgb={1-best_w:.2f} → NDCG@5={best_score:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb6eb97c-337e-4156-9a0c-0badb3dbabc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df = sample[[\\'srch_id\\']].copy()\\ndf[\\'nn_rank\\']  = pd.DataFrame({\\'score\\': nn_test_preds,  \\'srch\\': sample[\\'srch_id\\']})                     .groupby(\\'srch\\')[\\'score\\']                     .rank(method=\\'dense\\', ascending=False)\\ndf[\\'lgb_rank\\'] = pd.DataFrame({\\'score\\': model_lgb_pred,\\'srch\\': sample[\\'srch_id\\']})                     .groupby(\\'srch\\')[\\'score\\']                     .rank(method=\\'dense\\', ascending=False)\\n\\n# weighted rank\\nw_nn, w_lgb = best_w, (1-best_w)\\ndf[\\'ensemble_rank\\'] = w_nn * df[\\'nn_rank\\'] + w_lgb * df[\\'lgb_rank\\']\\n\\n# use that to sort\\nsubmission = sample.assign(_rank=df[\\'ensemble_rank\\'])     .sort_values([\\'srch_id\\',\\'_rank\\'], ascending=[True,True])     [[\\'srch_id\\',\\'prop_id\\']]\\n\\n# keep only the required columns and write to CSV\\n#   Kaggle expects: srch_id, prop_id (in ranked order)\\nsubmission[[\\'srch_id\\', \\'prop_id\\']].to_csv(\\n    \\'submission.csv\\',\\n    index=False\\n)\\nprint(\"Submission.csv adjusted with new scores!\")'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df = sample[['srch_id']].copy()\n",
    "df['nn_rank']  = pd.DataFrame({'score': nn_test_preds,  'srch': sample['srch_id']}) \\\n",
    "                    .groupby('srch')['score'] \\\n",
    "                    .rank(method='dense', ascending=False)\n",
    "df['lgb_rank'] = pd.DataFrame({'score': model_lgb_pred,'srch': sample['srch_id']}) \\\n",
    "                    .groupby('srch')['score'] \\\n",
    "                    .rank(method='dense', ascending=False)\n",
    "\n",
    "# weighted rank\n",
    "w_nn, w_lgb = best_w, (1-best_w)\n",
    "df['ensemble_rank'] = w_nn * df['nn_rank'] + w_lgb * df['lgb_rank']\n",
    "\n",
    "# use that to sort\n",
    "submission = sample.assign(_rank=df['ensemble_rank']) \\\n",
    "    .sort_values(['srch_id','_rank'], ascending=[True,True]) \\\n",
    "    [['srch_id','prop_id']]\n",
    "\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa7bccc1-01c7-405a-8e9f-913dc53fd5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_sub = sample[[\\'srch_id\\']].copy()\\ndf_sub[\\'nn_rank\\']  = pd.Series(nn_test_preds).groupby(sample[\\'srch_id\\']).rank(\"dense\", ascending=False)\\ndf_sub[\\'lgb_rank\\'] = pd.Series(model_lgb_pred).groupby(sample[\\'srch_id\\']).rank(\"dense\", ascending=False)\\n\\n# weighted rank blend\\ndf_sub[\\'ensemble_rank\\'] = 0.2*df_sub[\\'nn_rank\\'] + 0.8*df_sub[\\'lgb_rank\\']\\n\\nsubmission = (\\n    sample.assign(_rank=df_sub[\\'ensemble_rank\\'])\\n          .sort_values([\\'srch_id\\',\\'_rank\\'], ascending=[True,True])\\n          [[\\'srch_id\\',\\'prop_id\\']]\\n)\\n# keep only the required columns and write to CSV\\n#   Kaggle expects: srch_id, prop_id (in ranked order)\\nsubmission[[\\'srch_id\\', \\'prop_id\\']].to_csv(\\n    \\'submission.csv\\',\\n    index=False\\n)\\nprint(\"Submission.csv adjusted with new scores!\")'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_sub = sample[['srch_id']].copy()\n",
    "df_sub['nn_rank']  = pd.Series(nn_test_preds).groupby(sample['srch_id']).rank(\"dense\", ascending=False)\n",
    "df_sub['lgb_rank'] = pd.Series(model_lgb_pred).groupby(sample['srch_id']).rank(\"dense\", ascending=False)\n",
    "\n",
    "# weighted rank blend\n",
    "df_sub['ensemble_rank'] = 0.2*df_sub['nn_rank'] + 0.8*df_sub['lgb_rank']\n",
    "\n",
    "submission = (\n",
    "    sample.assign(_rank=df_sub['ensemble_rank'])\n",
    "          .sort_values(['srch_id','_rank'], ascending=[True,True])\n",
    "          [['srch_id','prop_id']]\n",
    ")\n",
    "# keep only the required columns and write to CSV\n",
    "#   Kaggle expects: srch_id, prop_id (in ranked order)\n",
    "submission[['srch_id', 'prop_id']].to_csv(\n",
    "    'submission.csv',\n",
    "    index=False\n",
    ")\n",
    "print(\"Submission.csv adjusted with new scores!\")\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
